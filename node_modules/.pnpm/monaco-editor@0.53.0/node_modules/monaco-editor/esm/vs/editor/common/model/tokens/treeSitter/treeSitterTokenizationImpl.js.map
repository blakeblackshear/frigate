{"version":3,"sources":["file:///mnt/vss/_work/1/s/dependencies/vscode/out-editor-src/vs/editor/common/model/tokens/treeSitter/treeSitterTokenizationImpl.ts","vs/editor/common/model/tokens/treeSitter/treeSitterTokenizationImpl.ts"],"names":[],"mappings":"AAAA;;;gGAGgG;;;;;;;;;;AAEhG,OAAO,EAAE,OAAO,EAAS,MAAM,qCAAqC,CAAC;AACrE,OAAO,EAAE,UAAU,EAAE,MAAM,yCAAyC,CAAC;AACrE,OAAO,EAAE,WAAW,EAAE,MAAM,wCAAwC,CAAC;AACrE,OAAO,EAAE,SAAS,EAAE,MAAM,yCAAyC,CAAC;AAIpE,OAAO,EAAE,uBAAuB,EAAE,MAAM,0BAA0B,CAAC;AACnE,OAAO,EAAE,UAAU,EAAe,YAAY,EAAE,MAAM,iBAAiB,CAAC;AAGxE,OAAO,EAAE,OAAO,EAAE,oBAAoB,EAAe,aAAa,EAAE,WAAW,EAAE,MAAM,0CAA0C,CAAC;AAElI,OAAO,EAAE,UAAU,EAAE,MAAM,+BAA+B,CAAC;AAC3D,OAAO,EAAE,QAAQ,EAAE,MAAM,2BAA2B,CAAC;AACrD,OAAO,EAAE,KAAK,EAAE,MAAM,wBAAwB,CAAC;AAC/C,OAAO,EAAE,SAAS,EAAE,MAAM,qCAAqC,CAAC;AAChE,OAAO,EAAE,uBAAuB,EAAE,MAAM,wDAAwD,CAAC;AACjG,OAAO,EAAE,kBAAkB,EAAE,MAAM,sCAAsC,CAAC;AAEnE,IAAM,0BAA0B,GAAhC,MAAM,0BAA2B,SAAQ,UAAU;IAYzD,IAAY,UAAU;QACrB,OAAO,IAAI,CAAC,KAAK,CAAC,SAAS,CAAC;IAC7B,CAAC;IAED,YACkB,KAAqB,EACrB,oBAAsC,EACtC,gBAAkC,EAClC,kBAAqD,EAE7C,uBAAiE;QAE1F,KAAK,EAAE,CAAC;QAPS,UAAK,GAAL,KAAK,CAAgB;QACrB,yBAAoB,GAApB,oBAAoB,CAAkB;QACtC,qBAAgB,GAAhB,gBAAgB,CAAkB;QAClC,uBAAkB,GAAlB,kBAAkB,CAAmC;QAE5B,4BAAuB,GAAvB,uBAAuB,CAAyB;QAjB1E,uBAAkB,GAAmD,IAAI,CAAC,SAAS,CAAC,IAAI,OAAO,EAAE,CAAC,CAAC;QACpG,sBAAiB,GAAiD,IAAI,CAAC,kBAAkB,CAAC,KAAK,CAAC;QAC/F,yCAAoC,GAAkB,IAAI,CAAC,SAAS,CAAC,IAAI,OAAO,EAAE,CAAC,CAAC;QACrF,sCAAiC,GAAgB,IAAI,CAAC,oCAAoC,CAAC,KAAK,CAAC;QAkBhH,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC,gBAAgB,CAAC,gBAAgB,CAAC,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,CAAC;QAExF,IAAI,CAAC,SAAS,CAAC,WAAW,CAAC,IAAI,CAAC,uBAAuB,CAAC,QAAQ,EAAE,GAAG,EAAE;YACtE,IAAI,CAAC,YAAY,EAAE,CAAC;QACrB,CAAC,CAAC,CAAC,CAAC;QAEJ,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,UAAU,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC;QACnE,IAAI,CAAC,gBAAgB,GAAG,IAAI,CAAC,UAAU,CAAC,YAAY,EAAE,CAAC;QACvD,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,YAAY,EAAE,CAAC;QACpD,IAAI,CAAC,WAAW,CAAC,UAAU,CAAC,IAAI,CAAC,kBAAkB,EAAE,EAAE,YAAY,CAAC,IAAI,CAAC,CAAC;QAE1E,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;YAC/B,MAAM,iBAAiB,GAAG,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YAC/D,IAAI,CAAC,yBAAyB,CAAC,iBAAiB,CAAC,CAAC;QACnD,CAAC,CAAC,CAAC,CAAC;QAEJ,IAAI,CAAC,SAAS,CAAC,oBAAoB,CAAC;YACnC,KAAK,EAAE,IAAI;YACX,aAAa,EAAE,aAAa,CAAC,EAAE,IAAI,EAAE,IAAI,CAAC,KAAK,CAAC,IAAI,EAAE,CAAC;SACvD,EAAE,CAAC,MAAM,EAAE,GAAG,EAAE,EAAE;YAClB,MAAM,WAAW,GAAG,GAAG,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC;YAC9C,IAAI,GAAG,CAAC,OAAO,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;gBAC5B,MAAM,IAAI,kBAAkB,CAAC,mGAAmG,CAAC,CAAC;YACnI,CAAC;YAED,IAAI,CAAC,WAAW,EAAE,CAAC;gBAClB,IAAI,GAAG,CAAC,IAAI,EAAE,CAAC;oBACd,IAAI,CAAC,gBAAgB,CAAC,IAAI,CAAC,KAAK,CAAC,qBAAqB,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC;gBACtE,CAAC;YACF,CAAC;iBAAM,CAAC;gBACP,IAAI,IAAI,CAAC,SAAS,EAAE,EAAE,CAAC;oBACtB,yCAAyC;oBAEzC,KAAK,MAAM,KAAK,IAAI,WAAW,CAAC,MAAM,EAAE,CAAC;wBACxC,IAAI,CAAC,eAAe,CAAC,KAAK,CAAC,QAAQ,CAAC,CAAC;oBACtC,CAAC;gBACF,CAAC;gBAED,2DAA2D;gBAC3D,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,EAAE,CAAC;oBACvB,IAAI,CAAC,gBAAgB,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;gBAC9C,CAAC;qBAAM,CAAC;oBACP,IAAI,CAAC,iBAAiB,CAAC,WAAW,CAAC,MAAM,EAAE,WAAW,CAAC,SAAS,CAAC,CAAC;gBACnE,CAAC;YACF,CAAC;QACF,CAAC,CAAC,CAAC,CAAC;IACL,CAAC;IAEM,oBAAoB,CAAC,CAA4B;QACvD,IAAI,CAAC,aAAa,GAAG,CAAC,CAAC,SAAS,CAAC;QACjC,KAAK,MAAM,MAAM,IAAI,CAAC,CAAC,OAAO,EAAE,CAAC;YAChC,IAAI,MAAM,CAAC,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC,WAAW,EAAE,CAAC;gBAC7C,wFAAwF;gBACxF,8GAA8G;gBAC9G,MAAM,MAAM,GAAG,MAAM,CAAC,WAAW,GAAG,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,WAAW,GAAG,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,WAAW,CAAC;gBACpF,MAAM,QAAQ,GAAG,IAAI,CAAC,WAAW,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC;gBACrD,IAAI,QAAqB,CAAC;gBAC1B,IAAI,QAAQ,EAAE,CAAC;oBACd,sEAAsE;oBACtE,QAAQ,GAAG,EAAE,oBAAoB,EAAE,QAAQ,CAAC,oBAAoB,EAAE,MAAM,EAAE,QAAQ,CAAC,MAAM,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC,WAAW,EAAE,KAAK,EAAE,QAAQ,CAAC,KAAK,EAAE,CAAC;oBAC7J,6EAA6E;oBAC7E,IAAI,CAAC,WAAW,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,WAAW,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC,WAAW,CAAC,CAAC,CAAC;gBACnJ,CAAC;qBAAM,CAAC;oBACP,wEAAwE;oBACxE,QAAQ,GAAG,EAAE,oBAAoB,EAAE,MAAM,EAAE,MAAM,EAAE,MAAM,CAAC,IAAI,CAAC,MAAM,EAAE,KAAK,EAAE,CAAC,EAAE,CAAC;gBACnF,CAAC;gBACD,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,QAAQ,EAAE,MAAM,IAAI,CAAC,EAAE,CAAC,QAAQ,CAAC,EAAE,YAAY,CAAC,SAAS,CAAC,CAAC;YACpF,CAAC;iBAAM,IAAI,MAAM,CAAC,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC,WAAW,EAAE,CAAC;gBACpD,wDAAwD;gBACxD,MAAM,gBAAgB,GAAG,MAAM,CAAC,WAAW,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC;gBACjE,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,gBAAgB,EAAE,MAAM,CAAC,WAAW,CAAC,CAAC;YAC/D,CAAC;QACF,CAAC;IACF,CAAC;IAEM,aAAa,CAAC,UAAkB;QACtC,MAAM,OAAO,GAAG,IAAI,CAAC,UAAU,CAAC,cAAc,CAAC,UAAU,CAAC,CAAC;QAC3D,MAAM,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC,UAAU,CAAC,CAAC;QAC7C,OAAO,IAAI,UAAU,CAAC,SAAS,EAAE,OAAO,EAAE,IAAI,CAAC,gBAAgB,CAAC,CAAC;IAClE,CAAC;IAEO,kBAAkB;QACzB,MAAM,UAAU,GAAG,IAAI,CAAC,WAAW,EAAE,CAAC;QACtC,MAAM,cAAc,GAAG,IAAI,CAAC,UAAU,CAAC,cAAc,EAAE,CAAC;QAExD,MAAM,WAAW,GAAkB,CAAC,IAAI,CAAC,8BAA8B,CAAC,CAAC,EAAE,cAAc,EAAE,UAAU,CAAC,CAAC,CAAC;QACxG,OAAO,WAAW,CAAC;IACpB,CAAC;IAEO,WAAW;QAClB,OAAO,IAAI,CAAC,uBAAuB,CAAC,YAAY,CAAC,EAAE,EAAE,IAAI,CAAC,kBAAkB,EAAE,KAAK,EAAE,SAAS,CAAC,CAAC;IACjG,CAAC;IAEO,8BAA8B,CAAC,MAAc,EAAE,MAAc,EAAE,UAAkB;QACxF,OAAO,EAAE,KAAK,EAAE,UAAU,EAAE,MAAM,EAAE,MAAM,GAAG,MAAM,EAAE,oBAAoB,EAAE,CAAC,EAAE,CAAC;IAChF,CAAC;IAEM,wBAAwB,CAAC,UAAkB;QACjD,OAAO,IAAI,CAAC,SAAS,CAAC,IAAI,KAAK,CAAC,UAAU,EAAE,CAAC,EAAE,UAAU,EAAE,IAAI,CAAC,UAAU,CAAC,gBAAgB,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;IAC3G,CAAC;IAEM,eAAe,CAAC,UAAkB,EAAE,KAAe;QACzD,MAAM,aAAa,GAAG,IAAI,CAAC,2BAA2B,CAAC,UAAU,EAAE,KAAK,CAAC,CAAC;QAC1E,MAAM,UAAU,GAAiB,EAAE,CAAC;QACpC,IAAI,CAAC,aAAa,EAAE,CAAC;YACpB,OAAO,IAAI,CAAC;QACb,CAAC;QACD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,aAAa,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YAC/C,UAAU,CAAC,IAAI,CAAC,IAAI,UAAU,CAAC,aAAa,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,gBAAgB,CAAC,CAAC,CAAC;QACpF,CAAC;QACD,OAAO,UAAU,CAAC;IACnB,CAAC;IAEO,eAAe,CAAC,KAAY,EAAE,mBAAiC;QACtE,OAAO,IAAI,CAAC,WAAW,CAAC,cAAc,CAAC,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,KAAK,CAAC,gBAAgB,EAAE,CAAC,EAAE,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,KAAK,CAAC,cAAc,EAAE,CAAC,EAAE,mBAAmB,CAAC,CAAC;IACzK,CAAC;IAEM,SAAS,CAAC,gBAAwB;QACxC,IAAI,CAAC,gBAAgB,IAAI,CAAC,IAAI,CAAC,aAAa,KAAK,IAAI,CAAC,gBAAgB,CAAC,EAAE,CAAC;YACzE,OAAO,IAAI,CAAC;QACb,CAAC;QAED,OAAO,CAAC,IAAI,CAAC,WAAW,CAAC,iBAAiB,CAAC,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,gBAAgB,CAAC,gBAAgB,EAAE,CAAC,EAAE,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,gBAAgB,CAAC,cAAc,EAAE,CAAC,CAAC,CAAC;IAC9K,CAAC;IAEM,SAAS,CAAC,IAAY;QAC5B,MAAM,eAAe,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,EAAE,UAAU,EAAE,IAAI,EAAE,MAAM,EAAE,CAAC,EAAE,CAAC,CAAC;QACrF,MAAM,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,EAAE,UAAU,EAAE,IAAI,EAAE,MAAM,EAAE,IAAI,CAAC,UAAU,CAAC,aAAa,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC;QACzH,MAAM,UAAU,GAAG,IAAI,CAAC,WAAW,CAAC,gBAAgB,CAAC,eAAe,EAAE,aAAa,CAAC,CAAC;QACrF,MAAM,MAAM,GAAG,IAAI,WAAW,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QACtD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YAC5C,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC,oBAAoB,GAAG,eAAe,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC;YAC5F,MAAM,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;QACzC,CAAC;QACD,OAAO,MAAM,CAAC;IACf,CAAC;IAED,gBAAgB,CAAC,KAAY,EAAE,gBAAwB,EAAE,cAAsB,EAAE,QAAyB;QACzG,MAAM,MAAM,GAAG,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,6BAA6B,CAAC,QAAQ,EAAE,gBAAgB,EAAE,cAAc,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,SAAS,CAAC,KAAK,EAAE,gBAAgB,EAAE,cAAc,CAAC,CAAC;QACnK,IAAI,MAAM,EAAE,qBAAqB,EAAE,CAAC;YACnC,OAAO,IAAI,CAAC,qBAAqB,CAAC,gBAAgB,EAAE,MAAM,CAAC,qBAAqB,CAAC,CAAC;QACnF,CAAC;QACD,OAAO,SAAS,CAAC;IAClB,CAAC;IAEO,oBAAoB,CAAC,OAAe,EAAE,OAAgE,EAAE,YAA0B;QACzI,IAAI,CAAC,gBAAgB,GAAG,OAAO,CAAC;QAChC,KAAK,MAAM,MAAM,IAAI,OAAO,EAAE,CAAC;YAC9B,MAAM,SAAS,GAAG,MAAM,CAAC,SAAS,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,SAAS,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC;YAC1G,IAAI,cAAsB,CAAC;YAC3B,IAAI,SAAS,IAAI,CAAC,IAAI,CAAC,aAAa,IAAI,OAAO,CAAC,EAAE,CAAC;gBAClD,cAAc,GAAG,SAAS,CAAC,oBAAoB,GAAG,SAAS,CAAC,MAAM,GAAG,MAAM,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,oBAAoB,CAAC;YAC/G,CAAC;iBAAM,IAAI,MAAM,CAAC,cAAc,EAAE,CAAC;gBAClC,cAAc,GAAG,MAAM,CAAC,cAAc,CAAC;YACxC,CAAC;iBAAM,CAAC;gBACP,cAAc,GAAG,CAAC,CAAC;YACpB,CAAC;YACD,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,cAAc,EAAE,MAAM,CAAC,SAAS,EAAE,YAAY,CAAC,CAAC;QACzE,CAAC;IACF,CAAC;IAEO,eAAe,CAAC,KAAY;QACnC,IAAI,CAAC,WAAW,CAAC,cAAc,CAAC,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,KAAK,CAAC,gBAAgB,EAAE,CAAC,EAAE,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,KAAK,CAAC,cAAc,EAAE,CAAC,CAAC,CAAC;IAC7I,CAAC;IAEO,gBAAgB;QACvB,MAAM,wBAAwB,GAAG,IAAI,CAAC,WAAW,CAAC,eAAe,EAAE,CAAC;QACpE,IAAI,CAAC,wBAAwB,EAAE,CAAC;YAC/B,OAAO,EAAE,CAAC;QACX,CAAC;QACD,OAAO,wBAAwB,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;YAC7C,KAAK,EAAE,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,UAAU,CAAC,aAAa,CAAC,KAAK,CAAC,WAAW,CAAC,EAAE,IAAI,CAAC,UAAU,CAAC,aAAa,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC;YAC5H,WAAW,EAAE,KAAK,CAAC,WAAW;YAC9B,SAAS,EAAE,KAAK,CAAC,SAAS;SAC1B,CAAC,CAAC,CAAC;IACL,CAAC;IAGO,yBAAyB,CAAC,UAAgC;QACjE,MAAM,cAAc,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,gBAAgB,EAAE,CAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;QACnF,KAAK,MAAM,KAAK,IAAI,cAAc,EAAE,CAAC;YACpC,MAAM,4BAA4B,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,KAAK,CAAC,gBAAgB,EAAE,CAAC,CAAC;YAC3F,MAAM,0BAA0B,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,KAAK,CAAC,cAAc,EAAE,CAAC,CAAC;YACvF,MAAM,OAAO,GAAG,IAAI,CAAC,UAAU,CAAC,YAAY,EAAE,CAAC;YAC/C,IAAI,IAAI,CAAC,eAAe,CAAC,KAAK,EAAE,YAAY,CAAC,aAAa,CAAC,EAAE,CAAC;gBAC7D,SAAS;YACV,CAAC;YACD,MAAM,OAAO,GAAG,IAAI,CAAC,UAAU,CAAC,eAAe,CAAC,KAAK,CAAC,CAAC;YACvD,MAAM,YAAY,GAAG,IAAI,CAAC,6BAA6B,CAAC,KAAK,EAAE,4BAA4B,EAAE,0BAA0B,EAAE,OAAO,EAAE,IAAI,CAAC,CAAC;YACxI,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,eAAe,CAAC,KAAK,EAAE,YAAY,CAAC,aAAa,CAAC,EAAE,CAAC;gBAC9E,SAAS;YACV,CAAC;YACD,IAAI,YAAY,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;gBAC/B,SAAS;YACV,CAAC;YACD,MAAM,SAAS,GAAG,YAAY,CAAC,YAAY,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;YACxD,MAAM,cAAc,GAAG,SAAS,CAAC,oBAAoB,GAAG,SAAS,CAAC,MAAM,GAAG,YAAY,CAAC,CAAC,CAAC,CAAC,oBAAoB,CAAC;YAChH,IAAI,CAAC,oBAAoB,CAAC,OAAO,EAAE,CAAC,EAAE,SAAS,EAAE,YAAY,EAAE,cAAc,EAAE,CAAC,EAAE,YAAY,CAAC,aAAa,CAAC,CAAC;YAC9G,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC,EAAE,OAAO,EAAE,EAAE,qBAAqB,EAAE,KAAK,EAAE,MAAM,EAAE,CAAC,EAAE,cAAc,EAAE,KAAK,CAAC,eAAe,EAAE,YAAY,EAAE,KAAK,CAAC,aAAa,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC;QACrK,CAAC;IACF,CAAC;IAEO,2BAA2B,CAAC,UAAkB,EAAE,KAAe;QACtE,IAAI,KAAK,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;YACxB,OAAO,SAAS,CAAC;QAClB,CAAC;QACD,MAAM,WAAW,GAAG,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,MAAM,EAAE,CAAC,CAAC;QACzD,MAAM,KAAK,GAAG,IAAI,KAAK,CAAC,CAAC,EAAE,CAAC,EAAE,UAAU,GAAG,KAAK,CAAC,MAAM,EAAE,KAAK,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAC7F,MAAM,WAAW,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,CAAC,CAAC;QAC3E,MAAM,MAAM,GAAG,IAAI,CAAC,6BAA6B,CAAC,KAAK,EAAE,WAAW,EAAE,WAAW,GAAG,WAAW,CAAC,MAAM,EAAE,WAAW,EAAE,KAAK,CAAC,CAAC;QAC5H,IAAI,CAAC,MAAM,EAAE,CAAC;YACb,OAAO,SAAS,CAAC;QAClB,CAAC;QACD,MAAM,YAAY,GAAkB,IAAI,KAAK,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;QAC5D,IAAI,WAAW,GAAW,CAAC,CAAC;QAC5B,IAAI,gBAAgB,GAAG,CAAC,CAAC;QACzB,IAAI,eAAe,GAAG,CAAC,CAAC;QACxB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YACvC,MAAM,aAAa,GAAqB,EAAE,CAAC;YAC3C,IAAI,cAAc,GAAG,KAAK,CAAC;YAC3B,KAAK,IAAI,CAAC,GAAG,WAAW,EAAE,CAAC,CAAC,cAAc,IAAI,CAAC,CAAC,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC;gBACzE,MAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;gBACxB,MAAM,qBAAqB,GAAG,KAAK,CAAC,SAAS,GAAG,eAAe,CAAC;gBAChE,MAAM,uBAAuB,GAAG,gBAAgB,GAAG,eAAe,CAAC;gBACnE,IAAI,qBAAqB,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC,MAAM,EAAE,CAAC;oBAC9C,aAAa,CAAC,IAAI,CAAC,EAAE,SAAS,EAAE,qBAAqB,EAAE,QAAQ,EAAE,KAAK,CAAC,QAAQ,EAAE,CAAC,CAAC;oBACnF,WAAW,EAAE,CAAC;gBACf,CAAC;qBAAM,IAAI,uBAAuB,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC,MAAM,EAAE,CAAC;oBACtD,MAAM,YAAY,GAAmB,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC,MAAM,EAAE,QAAQ,EAAE,KAAK,CAAC,QAAQ,EAAE,CAAC;oBAC9F,aAAa,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;oBACjC,cAAc,GAAG,IAAI,CAAC;gBACvB,CAAC;qBAAM,CAAC;oBACP,cAAc,GAAG,IAAI,CAAC;gBACvB,CAAC;gBACD,gBAAgB,GAAG,KAAK,CAAC,SAAS,CAAC;YACpC,CAAC;YAED,YAAY,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,6BAA6B,CAAC,aAAa,CAAC,CAAC;YACpE,eAAe,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC,MAAM,GAAG,IAAI,CAAC,UAAU,CAAC,MAAM,EAAE,CAAC,MAAM,CAAC;QACtE,CAAC;QAED,OAAO,YAAY,CAAC;IACrB,CAAC;IAIO,6BAA6B,CAAC,KAAY,EAAE,4BAAoC,EAAE,0BAAkC,EAAE,OAAe,EAAE,QAAiB;QAC/J,MAAM,mBAAmB,GAAG,uBAAuB,CAAC,IAAI,CAAC,UAAU,EAAE,KAAK,CAAC,eAAe,CAAC,CAAC,mBAAmB,CAAC;QAChH,MAAM,oBAAoB,GAAG,mBAAmB,CAAC,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,MAAM,EAAE,CAAC,CAAC;QAEhF,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,oBAAoB,CAAC,GAAG,oBAAoB,GAAG,OAAO,EAAE,CAAC,CAAC;QAClF,IAAI,CAAC,IAAI,EAAE,CAAC;YACX,OAAO;QACR,CAAC;QAED,MAAM,SAAS,GAAG,IAAI,KAAK,CAAC,CAAC,EAAE,CAAC,EAAE,KAAK,CAAC,aAAa,GAAG,KAAK,CAAC,eAAe,GAAG,CAAC,GAAG,mBAAmB,CAAC,MAAM,EAAE,KAAK,CAAC,SAAS,CAAC,CAAC;QACjI,MAAM,QAAQ,GAAG,IAAI,CAAC,cAAc,CAAC,SAAS,CAAC,CAAC;QAChD,MAAM,MAAM,GAAG,IAAI,CAAC,6BAA6B,CAAC,QAAQ,EAAE,oBAAoB,CAAC,MAAM,EAAE,0BAA0B,GAAG,4BAA4B,GAAG,oBAAoB,CAAC,MAAM,CAAC,CAAC;QAClL,IAAI,CAAC,MAAM,EAAE,CAAC;QAEd,IAAI,CAAC,MAAM,EAAE,CAAC;YACb,OAAO;QACR,CAAC;QAED,IAAI,QAAQ,EAAE,CAAC;YACd,OAAO,IAAI,CAAC,qBAAqB,CAAC,4BAA4B,EAAE,MAAM,CAAC,qBAAqB,EAAE,oBAAoB,CAAC,MAAM,CAAC,CAAC;QAC5H,CAAC;aAAM,CAAC;YACP,OAAO,MAAM,CAAC,qBAAqB,CAAC;QACrC,CAAC;IACF,CAAC;IAGO,gBAAgB,CAAC,SAAiB;QACzC,OAAO,IAAI,CAAC,kBAAkB,CAAC,SAAS,CAAC,CAAC;IAC3C,CAAC;IAEO,kBAAkB,CAAC,SAAiB;QAC3C,MAAM,YAAY,GAAG,IAAI,CAAC,kBAAkB,CAAC,GAAG,EAAE,CAAC,GAAG,CAA0B,SAAS,CAAC,EAAE;YAC3F,MAAM,KAAK,GAAG,SAAS,CAAC,gBAAgB,EAAE,CAAC;YAC3C,IAAI,CAAC,KAAK,EAAE,CAAC;gBAAC,OAAO,SAAS,CAAC;YAAC,CAAC;YACjC,MAAM,mBAAmB,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,KAAK,CAAC,gBAAgB,EAAE,CAAC,CAAC;YAClF,MAAM,iBAAiB,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,KAAK,CAAC,cAAc,EAAE,CAAC,CAAC;YAC9E,OAAO;gBACN,QAAQ,EAAE,KAAK;gBACf,iBAAiB;gBACjB,mBAAmB;aACnB,CAAC;QACH,CAAC,CAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;QAErB,OAAO,IAAI,CAAC,iBAAiB,CAAC,YAAY,EAAE,SAAS,CAAC,CAAC;IACxD,CAAC;IAED;;OAEG;IACK,iBAAiB,CAAC,MAAqB,EAAE,SAAiB;QACjE,MAAM,YAAY,GAAuB,EAAE,CAAC;QAC5C,MAAM,SAAS,GAAG,IAAI,CAAC;QAEvB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YACxC,MAAM,gBAAgB,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,aAAa,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,eAAe,CAAC;YAC/F,IAAI,gBAAgB,GAAG,SAAS,EAAE,CAAC;gBAClC,uDAAuD;gBACvD,MAAM,sBAAsB,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,aAAa,CAAC;gBAChE,IAAI,cAAc,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,eAAe,CAAC;gBACxD,IAAI,gBAAgB,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,WAAW,CAAC;gBACtD,IAAI,YAAY,GAAG,cAAc,GAAG,SAAS,CAAC;gBAC9C,GAAG,CAAC;oBACH,MAAM,qBAAqB,GAAG,IAAI,QAAQ,CAAC,cAAc,EAAE,gBAAgB,CAAC,CAAC;oBAC7E,MAAM,cAAc,GAAG,CAAC,CAAC,YAAY,KAAK,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,gBAAgB,CAAC,YAAY,CAAC,CAAC,CAAC;oBAC7J,MAAM,gBAAgB,GAAG,IAAI,QAAQ,CAAC,YAAY,EAAE,cAAc,CAAC,CAAC;oBACpE,MAAM,UAAU,GAAG,KAAK,CAAC,aAAa,CAAC,qBAAqB,EAAE,gBAAgB,CAAC,CAAC;oBAEhF,YAAY,CAAC,IAAI,CAAC;wBACjB,KAAK,EAAE,UAAU;wBACjB,WAAW,EAAE,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,UAAU,CAAC,gBAAgB,EAAE,CAAC;wBACvE,SAAS,EAAE,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,UAAU,CAAC,cAAc,EAAE,CAAC;qBACnE,CAAC,CAAC;oBAEH,cAAc,GAAG,YAAY,GAAG,CAAC,CAAC;oBAClC,gBAAgB,GAAG,CAAC,CAAC;oBACrB,IAAI,YAAY,GAAG,sBAAsB,IAAI,YAAY,GAAG,SAAS,GAAG,sBAAsB,EAAE,CAAC;wBAChG,YAAY,GAAG,sBAAsB,CAAC;oBACvC,CAAC;yBAAM,CAAC;wBACP,YAAY,GAAG,YAAY,GAAG,SAAS,CAAC;oBACzC,CAAC;gBACF,CAAC,QAAQ,YAAY,IAAI,sBAAsB,EAAE;YAClD,CAAC;iBAAM,CAAC;gBACP,gDAAgD;gBAChD,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,SAAS,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,mBAAmB,CAAC,EAAE,CAAC;oBAClF,YAAY,CAAC,IAAI,CAAC;wBACjB,KAAK,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ;wBACzB,WAAW,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,mBAAmB;wBAC1C,SAAS,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,iBAAiB;qBACtC,CAAC,CAAC;gBACJ,CAAC;qBAAM,IAAI,YAAY,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,SAAS,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,iBAAiB,EAAE,CAAC;oBACxE,uCAAuC;oBACvC,MAAM,aAAa,GAAG,IAAI,CAAC,UAAU,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;oBACvF,MAAM,KAAK,GAAG,IAAI,KAAK,CAAC,aAAa,CAAC,UAAU,EAAE,aAAa,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,aAAa,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC;oBACxI,YAAY,CAAC,IAAI,CAAC;wBACjB,KAAK;wBACL,WAAW,EAAE,YAAY,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,SAAS,GAAG,CAAC;wBAC9C,SAAS,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,iBAAiB;qBACtC,CAAC,CAAC;gBACJ,CAAC;YACF,CAAC;QACF,CAAC;QAED,+DAA+D;QAC/D,MAAM,QAAQ,GAAG,YAAY,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,IAAI,CAAC,YAAY,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;QAC3E,cAAc;QACd,OAAO,IAAI,CAAC,oBAAoB,CAAC,YAAY,EAAE,SAAS,EAAE,QAAQ,CAAC,CAAC,IAAI,CAAC,GAAG,EAAE;YAC7E,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,UAAU,EAAE,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,qBAAqB,CAAC,GAAG,EAAE,KAAK,IAAI,CAAC,UAAU,CAAC,YAAY,EAAE,CAAC,EAAE,CAAC;gBAClH,IAAI,CAAC,oBAAoB,CAAC,SAAS,CAAC,CAAC;YACtC,CAAC;QACF,CAAC,CAAC,CAAC;IACJ,CAAC;IAEO,KAAK,CAAC,oBAAoB,CAAC,YAAgC,EAAE,SAAiB,EAAE,QAA0B;QACjH,IAAI,WAAqD,CAAC;QAE1D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YAC9C,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,UAAU,EAAE,IAAI,SAAS,KAAK,IAAI,CAAC,UAAU,CAAC,YAAY,EAAE,EAAE,CAAC;gBACnF,6DAA6D;gBAC7D,MAAM;YACP,CAAC;YACD,MAAM,OAAO,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;YAC5B,MAAM,KAAK,GAAG,YAAY,CAAC,CAAC,CAAC,CAAC;YAE9B,MAAM,OAAO,GAAG,IAAI,CAAC,gBAAgB,CAAC,KAAK,CAAC,KAAK,EAAE,KAAK,CAAC,WAAW,EAAE,KAAK,CAAC,SAAS,EAAE,OAAO,CAAC,CAAC;YAChG,IAAI,OAAO,EAAE,CAAC;gBACb,WAAW,GAAG,EAAE,SAAS,EAAE,OAAO,EAAE,CAAC;YACtC,CAAC;iBAAM,CAAC;gBACP,WAAW,GAAG,EAAE,SAAS,EAAE,EAAE,EAAE,CAAC;YACjC,CAAC;YACD,IAAI,CAAC,oBAAoB,CAAC,SAAS,EAAE,CAAC,WAAW,CAAC,EAAE,YAAY,CAAC,QAAQ,CAAC,CAAC;YAC3E,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC;gBAC5B,OAAO,EAAE;oBACR,qBAAqB,EAAE,KAAK;oBAC5B,MAAM,EAAE,CAAC,EAAE,cAAc,EAAE,KAAK,CAAC,KAAK,CAAC,gBAAgB,EAAE,CAAC,UAAU,EAAE,YAAY,EAAE,KAAK,CAAC,KAAK,CAAC,cAAc,EAAE,CAAC,UAAU,EAAE,CAAC;iBAC9H;aACD,CAAC,CAAC;YACH,MAAM,IAAI,OAAO,CAAO,OAAO,CAAC,EAAE,CAAC,WAAW,CAAC,OAAO,CAAC,CAAC,CAAC;QAC1D,CAAC;QACD,IAAI,CAAC,oCAAoC,CAAC,IAAI,EAAE,CAAC;IAClD,CAAC;IAEO,oBAAoB,CAAC,SAAiB;QAC7C,MAAM,eAAe,GAAG,IAAI,CAAC,gBAAgB,EAAE,CAAC;QAChD,IAAI,eAAe,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;YAClC,OAAO;QACR,CAAC;QACD,MAAM,YAAY,GAAkB,IAAI,KAAK,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC;QAEtE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,eAAe,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YACjD,MAAM,KAAK,GAAG,eAAe,CAAC,CAAC,CAAC,CAAC;YACjC,YAAY,CAAC,CAAC,CAAC,GAAG;gBACjB,QAAQ,EAAE,KAAK,CAAC,KAAK;gBACrB,mBAAmB,EAAE,KAAK,CAAC,WAAW;gBACtC,iBAAiB,EAAE,KAAK,CAAC,SAAS;aAClC,CAAC;QACH,CAAC;QAED,IAAI,CAAC,iBAAiB,CAAC,YAAY,EAAE,SAAS,CAAC,CAAC;IACjD,CAAC;IAEO,qBAAqB,CAAC,WAAmB,EAAE,cAAgC,EAAE,qBAA8B;QAClH,MAAM,OAAO,GAAkB,EAAE,CAAC;QAClC,IAAI,OAAO,GAAG,CAAC,CAAC;QAChB,KAAK,MAAM,KAAK,IAAI,cAAc,EAAE,CAAC;YACpC,IAAI,KAAK,CAAC,SAAS,IAAI,OAAO,IAAI,CAAC,qBAAqB,IAAI,CAAC,KAAK,CAAC,SAAS,GAAG,qBAAqB,CAAC,CAAC,EAAE,CAAC;gBACxG,SAAS;YACV,CAAC;YACD,IAAI,WAAwB,CAAC;YAC7B,IAAI,qBAAqB,IAAI,CAAC,OAAO,GAAG,qBAAqB,CAAC,EAAE,CAAC;gBAChE,WAAW,GAAG,EAAE,oBAAoB,EAAE,WAAW,GAAG,qBAAqB,EAAE,MAAM,EAAE,KAAK,CAAC,SAAS,GAAG,qBAAqB,EAAE,KAAK,EAAE,KAAK,CAAC,QAAQ,EAAE,CAAC;YACrJ,CAAC;iBAAM,CAAC;gBACP,WAAW,GAAG,EAAE,oBAAoB,EAAE,WAAW,GAAG,OAAO,EAAE,MAAM,EAAE,KAAK,CAAC,SAAS,GAAG,OAAO,EAAE,KAAK,EAAE,KAAK,CAAC,QAAQ,EAAE,CAAC;YACzH,CAAC;YACD,OAAO,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;YAC1B,OAAO,GAAG,KAAK,CAAC,SAAS,CAAC;QAC3B,CAAC;QACD,OAAO,OAAO,CAAC;IAChB,CAAC;IAEO,YAAY;QACnB,MAAM,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC,iBAAiB,EAAE,CAAC;QACvD,IAAI,CAAC,eAAe,CAAC,UAAU,CAAC,CAAC;QACjC,IAAI,CAAC,yBAAyB,CAAC,IAAI,CAAC,kBAAkB,CAAC,GAAG,EAAE,CAAC,CAAC;IAC/D,CAAC;IAEO,cAAc,CAAC,KAAY;QAClC,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC;QACnC,IAAI,CAAC,IAAI,EAAE,CAAC;YACX,OAAO,EAAE,CAAC;QACX,CAAC;QACD,gDAAgD;QAChD,OAAO,IAAI,CAAC,oBAAoB,CAAC,QAAQ,CAAC,IAAI,CAAC,QAAQ,EAAE,EAAE,aAAa,EAAE,EAAE,GAAG,EAAE,KAAK,CAAC,eAAe,GAAG,CAAC,EAAE,MAAM,EAAE,KAAK,CAAC,WAAW,GAAG,CAAC,EAAE,EAAE,WAAW,EAAE,EAAE,GAAG,EAAE,KAAK,CAAC,aAAa,GAAG,CAAC,EAAE,MAAM,EAAE,KAAK,CAAC,SAAS,GAAG,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,EAAE,CAAC,CACzO;YACC,IAAI,EAAE,OAAO,CAAC,IAAI;YAClB,IAAI,EAAE,OAAO,CAAC,IAAI,CAAC,IAAI;YACvB,IAAI,EAAE;gBACL,UAAU,EAAE,OAAO,CAAC,IAAI,CAAC,UAAU;gBACnC,QAAQ,EAAE,OAAO,CAAC,IAAI,CAAC,QAAQ;gBAC/B,aAAa,EAAE;oBACd,UAAU,EAAE,OAAO,CAAC,IAAI,CAAC,aAAa,CAAC,GAAG,GAAG,CAAC;oBAC9C,MAAM,EAAE,OAAO,CAAC,IAAI,CAAC,aAAa,CAAC,MAAM,GAAG,CAAC;iBAC7C;gBACD,WAAW,EAAE;oBACZ,UAAU,EAAE,OAAO,CAAC,IAAI,CAAC,WAAW,CAAC,GAAG,GAAG,CAAC;oBAC5C,MAAM,EAAE,OAAO,CAAC,IAAI,CAAC,WAAW,CAAC,MAAM,GAAG,CAAC;iBAC3C;aACD;YACD,iBAAiB,EAAE,IAAI,CAAC,kBAAkB;SAC1C,CACD,CAAC,CAAC;IACJ,CAAC;IAEO,4BAA4B,CAAC,KAAY;QAChD,MAAM,QAAQ,GAAmB,IAAI,CAAC,cAAc,CAAC,KAAK,CAAC,CAAC;QAC5D,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YAC1C,MAAM,OAAO,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;YAE5B,MAAM,YAAY,GAAG,OAAO,CAAC,IAAI,CAAC,aAAa,CAAC,UAAU,CAAC;YAC3D,MAAM,UAAU,GAAG,OAAO,CAAC,IAAI,CAAC,WAAW,CAAC,UAAU,CAAC;YACvD,MAAM,cAAc,GAAG,OAAO,CAAC,IAAI,CAAC,aAAa,CAAC,MAAM,CAAC;YACzD,MAAM,YAAY,GAAG,OAAO,CAAC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YAErD,MAAM,SAAS,GAAG,CAAC,CAAC,YAAY,GAAG,KAAK,CAAC,eAAe,CAAC,IAAI,CAAC,YAAY,GAAG,KAAK,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,CAAC,CAAC,KAAK,CAAC,eAAe,CAAC;YAC1I,MAAM,OAAO,GAAG,CAAC,CAAC,UAAU,GAAG,KAAK,CAAC,eAAe,CAAC,IAAI,CAAC,UAAU,GAAG,KAAK,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,KAAK,CAAC,aAAa,CAAC;YAChI,MAAM,WAAW,GAAG,CAAC,YAAY,KAAK,KAAK,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,YAAY,GAAG,KAAK,CAAC,eAAe,CAAC,CAAC,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,cAAc,CAAC,CAAC;YACvN,MAAM,SAAS,GAAG,CAAC,UAAU,KAAK,KAAK,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC,CAAC,YAAY,GAAG,KAAK,CAAC,SAAS,CAAC,CAAC,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU,GAAG,KAAK,CAAC,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC,CAAC,YAAY,CAAC,CAAC;YACjM,MAAM,cAAc,GAAG,IAAI,KAAK,CAAC,SAAS,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,CAAC,CAAC;YAE7E,MAAM,SAAS,GAAG,IAAI,CAAC,qBAAqB,CAAC,OAAO,EAAE,cAAc,CAAC,CAAC;YACtE,IAAI,SAAS,IAAI,SAAS,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;gBACvC,QAAQ,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,GAAG,SAAS,CAAC,CAAC;gBACxC,CAAC,IAAI,SAAS,CAAC,MAAM,CAAC;YACvB,CAAC;QACF,CAAC;QACD,OAAO,QAAQ,CAAC;IACjB,CAAC;IAED;;;;;;OAMG;IACI,eAAe,CAAC,UAAkB;QACxC,MAAM,MAAM,GAAG,IAAI,CAAC,gBAAgB,CAAC,UAAU,CAAC,CAAC;QACjD,IAAI,CAAC,MAAM,EAAE,CAAC;YACb,OAAO,SAAS,CAAC;QAClB,CAAC;QACD,MAAM,OAAO,GAAG,IAAI,CAAC,qBAAqB,CAAC,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,CAAC,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;QAClH,IAAI,MAAM,CAAC,SAAS,KAAK,IAAI,CAAC,UAAU,CAAC,YAAY,EAAE,EAAE,CAAC;YACzD,IAAI,CAAC,oBAAoB,CAAC,MAAM,CAAC,SAAS,EAAE,CAAC,EAAE,SAAS,EAAE,OAAO,EAAE,cAAc,EAAE,IAAI,CAAC,UAAU,CAAC,aAAa,CAAC,UAAU,CAAC,EAAE,CAAC,EAAE,YAAY,CAAC,QAAQ,CAAC,CAAC;QACzJ,CAAC;IACF,CAAC;IAEO,YAAY,CAAC,KAAY;QAChC,MAAM,QAAQ,GAAG,IAAI,CAAC,4BAA4B,CAAC,KAAK,CAAC,CAAC;QAC1D,OAAO,QAAQ,CAAC;IACjB,CAAC;IAEO,SAAS,CAAC,KAAY,EAAE,gBAAwB,EAAE,cAAsB;QAC/E,MAAM,QAAQ,GAAG,IAAI,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC;QAC1C,MAAM,MAAM,GAAG,IAAI,CAAC,6BAA6B,CAAC,QAAQ,EAAE,gBAAgB,EAAE,cAAc,CAAC,CAAC;QAC9F,IAAI,CAAC,MAAM,EAAE,CAAC;YACb,OAAO,SAAS,CAAC;QAClB,CAAC;QACD,OAAO,EAAE,GAAG,MAAM,EAAE,SAAS,EAAE,IAAI,CAAC,KAAK,CAAC,qBAAqB,CAAC,GAAG,EAAE,EAAE,CAAC;IACzE,CAAC;IAEO,yBAAyB,CAAC,QAAwB,EAAE,gBAAwB,EAAE,cAAsB;QAC3G,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC;QACnC,MAAM,SAAS,GAAG,SAAS,CAAC,MAAM,EAAE,CAAC;QACrC,MAAM,WAAW,GAAG,cAAc,GAAG,gBAAgB,CAAC;QACtD,MAAM,iBAAiB,GAAG,IAAI,CAAC,gBAAgB,CAAC,gBAAgB,CAAC,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,CAAC;QACxF,MAAM,SAAS,GAAW,sBAAsB,CAAC,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,IAAI,QAAQ,CAAC;QAEpF,IAAI,QAAQ,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;YAC3B,IAAI,IAAI,EAAE,CAAC;gBACV,SAAS,CAAC,IAAI,EAAE,CAAC;gBACjB,MAAM,qBAAqB,GAAG,CAAC,EAAE,SAAS,EAAE,WAAW,EAAE,MAAM,EAAE,EAAE,EAAE,iBAAiB,EAAE,CAAC,CAAC;gBAC1F,OAAO,EAAE,UAAU,EAAE,qBAAqB,EAAE,WAAW,EAAE,SAAS,CAAC,OAAO,EAAE,EAAE,CAAC;YAChF,CAAC;YACD,OAAO,SAAS,CAAC;QAClB,CAAC;QAED,MAAM,mBAAmB,GAAyB,KAAK,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;QACzE,mBAAmB,CAAC,IAAI,CAAC,EAAE,SAAS,EAAE,CAAC,EAAE,MAAM,EAAE,CAAC,SAAS,CAAC,EAAE,iBAAiB,EAAE,CAAC,CAAC;QACnF,IAAI,UAAU,GAAG,CAAC,CAAC;QAEnB,MAAM,8BAA8B,GAAG,GAAG,EAAE;YAC3C,mBAAmB,CAAC,IAAI,CAAC,EAAE,SAAS,EAAE,CAAC,EAAE,MAAM,EAAE,CAAC,SAAS,CAAC,EAAE,iBAAiB,EAAE,CAAC,CAAC;QACpF,CAAC,CAAC;QAEF,MAAM,QAAQ,GAAG,CAAC,OAAqB,EAAE,WAAmB,EAAwB,EAAE;YACrF,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,aAAa,CAAC,IAAI,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,WAAW,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC;QACjK,CAAC,CAAC;QAEF,MAAM,sBAAsB,GAAG,CAAC,OAAqB,EAAE,WAAmB,EAAE,SAAiB,EAAE,QAAiB,EAAE,EAAE;YACnH,IAAI,QAAQ,KAAK,SAAS,EAAE,CAAC;gBAC5B,MAAM,SAAS,GAAG,mBAAmB,CAAC,QAAQ,CAAC,CAAC,MAAM,CAAC;gBACvD,IAAI,UAAU,GAAG,mBAAmB,CAAC,QAAQ,CAAC,CAAC,OAAO,CAAC;gBACvD,qFAAqF;gBACrF,MAAM,aAAa,GAAG,QAAQ,GAAG,CAAC,CAAC,CAAC,CAAC,mBAAmB,CAAC,QAAQ,GAAG,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;gBACrF,IAAI,aAAa,KAAK,WAAW,EAAE,CAAC;oBACnC,IAAI,gBAAgB,GAAyB,SAAS,CAAC;oBACvD,IAAI,UAAU,IAAI,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;wBACzC,gBAAgB,GAAG,EAAE,CAAC;wBACtB,MAAM,iBAAiB,GAAa,EAAE,CAAC;wBACvC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;4BAC5C,MAAM,OAAO,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;4BAC9B,IAAI,OAAO,GAAG,WAAW,EAAE,CAAC;gCAC3B,gBAAgB,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;4BAChC,CAAC;iCAAM,IAAI,OAAO,GAAG,SAAS,EAAE,CAAC;gCAChC,iBAAiB,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;4BACjC,CAAC;wBACF,CAAC;wBACD,IAAI,gBAAgB,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;4BACnC,gBAAgB,GAAG,SAAS,CAAC;wBAC9B,CAAC;wBACD,IAAI,iBAAiB,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;4BACpC,UAAU,GAAG,SAAS,CAAC;wBACxB,CAAC;6BAAM,CAAC;4BACP,UAAU,GAAG,iBAAiB,CAAC;wBAChC,CAAC;oBACF,CAAC;oBACD,+DAA+D;oBAC/D,mBAAmB,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAC,EAAE,EAAE,SAAS,EAAE,WAAW,EAAE,MAAM,EAAE,CAAC,GAAG,SAAS,CAAC,EAAE,OAAO,EAAE,gBAAgB,EAAE,iBAAiB,EAAE,OAAO,CAAC,iBAAiB,EAAE,CAAC,CAAC;oBACrK,QAAQ,EAAE,CAAC;oBACX,8BAA8B,EAAE,CAAC;oBACjC,UAAU,EAAE,CAAC;gBACd,CAAC;gBAED,mBAAmB,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAC,EAAE,EAAE,SAAS,EAAE,SAAS,EAAE,MAAM,EAAE,CAAC,GAAG,SAAS,EAAE,OAAO,CAAC,IAAI,CAAC,EAAE,OAAO,EAAE,QAAQ,CAAC,OAAO,EAAE,WAAW,CAAC,EAAE,iBAAiB,EAAE,OAAO,CAAC,iBAAiB,EAAE,CAAC,CAAC;gBAC/L,mBAAmB,CAAC,UAAU,CAAC,CAAC,OAAO,GAAG,UAAU,CAAC;YACtD,CAAC;iBAAM,CAAC;gBACP,mBAAmB,CAAC,UAAU,CAAC,GAAG,EAAE,SAAS,EAAE,SAAS,EAAE,MAAM,EAAE,CAAC,SAAS,EAAE,OAAO,CAAC,IAAI,CAAC,EAAE,OAAO,EAAE,QAAQ,CAAC,OAAO,EAAE,WAAW,CAAC,EAAE,iBAAiB,EAAE,OAAO,CAAC,iBAAiB,EAAE,CAAC;YACtL,CAAC;YACD,UAAU,EAAE,CAAC;QACd,CAAC,CAAC;QAEF,KAAK,IAAI,YAAY,GAAG,CAAC,EAAE,YAAY,GAAG,QAAQ,CAAC,MAAM,EAAE,YAAY,EAAE,EAAE,CAAC;YAC3E,MAAM,OAAO,GAAG,QAAQ,CAAC,YAAY,CAAC,CAAC;YACvC,MAAM,aAAa,GAAG,OAAO,CAAC,IAAI,CAAC,QAAQ,GAAG,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC,gBAAgB,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,cAAc,CAAC;YACxK,MAAM,eAAe,GAAG,OAAO,CAAC,IAAI,CAAC,UAAU,GAAG,gBAAgB,CAAC,CAAC,CAAC,gBAAgB,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,UAAU,CAAC;YAEhH,MAAM,SAAS,GAAG,aAAa,GAAG,gBAAgB,CAAC;YAEnD,oLAAoL;YACpL,8GAA8G;YAC9G,IAAI,iBAAyB,CAAC;YAC9B,MAAM,kBAAkB,GAAG,aAAa,GAAG,eAAe,CAAC;YAC3D,IAAI,YAAY,GAAG,CAAC,EAAE,CAAC;gBACtB,iBAAiB,GAAG,mBAAmB,CAAC,CAAC,UAAU,GAAG,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC;YACrE,CAAC;iBAAM,CAAC;gBACP,iBAAiB,GAAG,eAAe,GAAG,gBAAgB,GAAG,CAAC,CAAC;YAC5D,CAAC;YACD,MAAM,WAAW,GAAG,SAAS,GAAG,kBAAkB,CAAC;YACnD,IAAI,CAAC,iBAAiB,IAAI,CAAC,CAAC,IAAI,CAAC,iBAAiB,GAAG,WAAW,CAAC,EAAE,CAAC;gBACnE,qEAAqE;gBACrE,mBAAmB,CAAC,UAAU,CAAC,GAAG,EAAE,SAAS,EAAE,WAAW,EAAE,MAAM,EAAE,CAAC,SAAS,CAAC,EAAE,iBAAiB,EAAE,IAAI,CAAC,kBAAkB,EAAE,CAAC;gBAC9H,UAAU,EAAE,CAAC;gBAEb,8BAA8B,EAAE,CAAC;YAClC,CAAC;YAED,IAAI,kBAAkB,GAAG,CAAC,EAAE,CAAC;gBAC5B,mKAAmK;gBACnK,SAAS;YACV,CAAC;YAED,IAAI,iBAAiB,IAAI,SAAS,EAAE,CAAC;gBACpC,qFAAqF;gBACrF,IAAI,gBAAgB,GAAG,UAAU,GAAG,CAAC,CAAC;gBACtC,IAAI,sBAAsB,GAAG,mBAAmB,CAAC,gBAAgB,CAAC,CAAC,SAAS,CAAC;gBAE7E,IAAI,wBAAwB,GAAG,CAAC,CAAC,gBAAgB,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,mBAAmB,CAAC,gBAAgB,GAAG,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gBACnH,GAAG,CAAC;oBAEH,mEAAmE;oBACnE,IAAI,CAAC,wBAAwB,GAAG,kBAAkB,CAAC,KAAK,sBAAsB,EAAE,CAAC;wBAChF,IAAI,wBAAwB,KAAK,WAAW,EAAE,CAAC;4BAC9C,wGAAwG;4BACxG,mBAAmB,CAAC,gBAAgB,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;4BAChE,MAAM,UAAU,GAAG,mBAAmB,CAAC,gBAAgB,CAAC,CAAC,OAAO,CAAC;4BACjE,mBAAmB,CAAC,gBAAgB,CAAC,CAAC,OAAO,GAAG,CAAC,CAAC,UAAU,IAAI,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,QAAQ,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC,CAAC;wBACzI,CAAC;oBACF,CAAC;yBAAM,IAAI,wBAAwB,IAAI,WAAW,EAAE,CAAC;wBACpD,sBAAsB,CAAC,OAAO,EAAE,WAAW,EAAE,SAAS,EAAE,gBAAgB,CAAC,CAAC;wBAC1E,MAAM;oBACP,CAAC;oBACD,gBAAgB,EAAE,CAAC;oBACnB,wBAAwB,GAAG,CAAC,CAAC,gBAAgB,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,mBAAmB,CAAC,gBAAgB,GAAG,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;oBAC/G,sBAAsB,GAAG,CAAC,CAAC,gBAAgB,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,mBAAmB,CAAC,gBAAgB,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;gBAC1G,CAAC,QAAQ,sBAAsB,GAAG,WAAW,EAAE;YAChD,CAAC;iBAAM,CAAC;gBACP,kCAAkC;gBAClC,sBAAsB,CAAC,OAAO,EAAE,WAAW,EAAE,SAAS,CAAC,CAAC;YACzD,CAAC;QACF,CAAC;QAED,2DAA2D;QAC3D,IAAI,CAAC,mBAAmB,CAAC,UAAU,GAAG,CAAC,CAAC,CAAC,SAAS,GAAG,WAAW,CAAC,EAAE,CAAC;YACnE,IAAI,WAAW,GAAG,mBAAmB,CAAC,UAAU,GAAG,CAAC,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,CAAC;gBACrE,8BAA8B,EAAE,CAAC;gBACjC,mBAAmB,CAAC,UAAU,CAAC,GAAG,EAAE,SAAS,EAAE,WAAW,EAAE,MAAM,EAAE,mBAAmB,CAAC,UAAU,CAAC,CAAC,MAAM,EAAE,iBAAiB,EAAE,IAAI,CAAC,kBAAkB,EAAE,CAAC;gBACzJ,UAAU,EAAE,CAAC;YACd,CAAC;QACF,CAAC;QACD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,mBAAmB,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YACrD,MAAM,KAAK,GAAG,mBAAmB,CAAC,CAAC,CAAC,CAAC;YACrC,IAAI,KAAK,CAAC,SAAS,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,CAAC;gBACtC,mBAAmB,CAAC,MAAM,CAAC,CAAC,EAAE,mBAAmB,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;gBAC9D,MAAM;YACP,CAAC;QACF,CAAC;QACD,MAAM,WAAW,GAAG,SAAS,CAAC,OAAO,EAAE,CAAC;QACxC,OAAO,EAAE,UAAU,EAAE,mBAA+F,EAAE,WAAW,EAAE,CAAC;IACrI,CAAC;IAEO,qBAAqB,CAAC,aAA2B,EAAE,KAAY;QACtE;;;;;;;;;;2GAU6F;QAC7F,OAAO,EAAE,CAAC;IACX,CAAC;IAEO,6BAA6B,CAAC,QAAwB,EAAE,gBAAwB,EAAE,cAAsB;QAC/G,MAAM,SAAS,GAAG,SAAS,CAAC,MAAM,EAAE,CAAC;QACrC,MAAM,WAAW,GAAG,IAAI,CAAC,yBAAyB,CAAC,QAAQ,EAAE,gBAAgB,EAAE,cAAc,CAAC,CAAC;QAC/F,IAAI,CAAC,WAAW,EAAE,CAAC;YAClB,OAAO,SAAS,CAAC;QAClB,CAAC;QACD,MAAM,mBAAmB,GAAwB,WAAW,CAAC,UAAU,CAAC;QACxE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,mBAAmB,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YACrD,MAAM,KAAK,GAAG,mBAAmB,CAAC,CAAC,CAAC,CAAC;YACrC,KAAK,CAAC,QAAQ,GAAG,IAAI,CAAC,uBAAuB,CAAC,YAAY,CAAC,KAAK,CAAC,MAAM,EAAE,KAAK,CAAC,iBAAiB,EAAE,CAAC,CAAC,KAAK,CAAC,OAAO,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,MAAM,GAAG,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;QAC7J,CAAC;QAED,MAAM,YAAY,GAAG,SAAS,CAAC,OAAO,EAAE,CAAC;QACzC,OAAO,EAAE,qBAAqB,EAAE,mBAAkF,EAAE,WAAW,EAAE,WAAW,CAAC,WAAW,EAAE,YAAY,EAAE,CAAC;IAC1K,CAAC;IAEO,gBAAgB,CAAC,UAAkB;QAC1C,MAAM,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,EAAE,UAAU,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,CAAC,CAAC;QACtF,MAAM,OAAO,GAAG,IAAI,CAAC,UAAU,CAAC,YAAY,EAAE,CAAC;QAC/C,MAAM,aAAa,GAAG,CAAC,UAAU,GAAG,CAAC,IAAI,OAAO,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,EAAE,UAAU,EAAE,UAAU,GAAG,CAAC,EAAE,MAAM,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,cAAc,EAAE,CAAC;QAC9J,MAAM,UAAU,GAAG,aAAa,GAAG,UAAU,CAAC;QAE9C,MAAM,MAAM,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,KAAK,CAAC,UAAU,EAAE,CAAC,EAAE,UAAU,EAAE,UAAU,GAAG,CAAC,CAAC,EAAE,UAAU,EAAE,aAAa,CAAC,CAAC;QAC/G,IAAI,CAAC,MAAM,EAAE,CAAC;YACb,OAAO,SAAS,CAAC;QAClB,CAAC;QACD,OAAO,EAAE,MAAM,EAAE,MAAM,CAAC,qBAAqB,EAAE,WAAW,EAAE,MAAM,CAAC,WAAW,EAAE,YAAY,EAAE,MAAM,CAAC,YAAY,EAAE,SAAS,EAAE,MAAM,CAAC,SAAS,EAAE,CAAC;IAClJ,CAAC;IAEO,6BAA6B,CAAC,qBAAuC;QAE5E,MAAM,WAAW,GAAG,IAAI,WAAW,CAAC,qBAAqB,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QACtE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,qBAAqB,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YACvD,WAAW,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,qBAAqB,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC;YACxD,WAAW,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,qBAAqB,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC;QAC5D,CAAC;QACD,OAAO,WAAW,CAAC;IACpB,CAAC;CACD,CAAA;AAxuBY,0BAA0B;IAsBpC,WAAA,uBAAuB,CAAA;GAtBb,0BAA0B,CAwuBtC;;AAkBD,MAAM,CAAC,MAAM,sBAAsB,GAA2B;IAC7D,KAAK,EAAE,YAAY;IACnB,YAAY,EAAE,WAAW;IACzB,KAAK,EAAE,YAAY;IACnB,OAAO,EAAE,cAAc;CACvB,CAAC;AAEF,MAAM,QAAQ,GAAG,qBAAqB,CAAC","file":"treeSitterTokenizationImpl.js","sourceRoot":"file:///mnt/vss/_work/1/s/dependencies/vscode/out-editor-src","sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport { Emitter, Event } from '../../../../../base/common/event.js';\nimport { Disposable } from '../../../../../base/common/lifecycle.js';\nimport { setTimeout0 } from '../../../../../base/common/platform.js';\nimport { StopWatch } from '../../../../../base/common/stopwatch.js';\nimport { LanguageId } from '../../../encodedTokenAttributes.js';\nimport { ILanguageIdCodec, QueryCapture } from '../../../languages.js';\nimport { IModelContentChangedEvent, IModelTokensChangedEvent } from '../../../textModelEvents.js';\nimport { findLikelyRelevantLines } from '../../textModelTokens.js';\nimport { TokenStore, TokenUpdate, TokenQuality } from './tokenStore.js';\nimport { TreeSitterTree, RangeChange, RangeWithOffsets } from './treeSitterTree.js';\nimport type * as TreeSitter from '@vscode/tree-sitter-wasm';\nimport { autorun, autorunHandleChanges, IObservable, recordChanges, runOnChange } from '../../../../../base/common/observable.js';\nimport { LineRange } from '../../../core/ranges/lineRange.js';\nimport { LineTokens } from '../../../tokens/lineTokens.js';\nimport { Position } from '../../../core/position.js';\nimport { Range } from '../../../core/range.js';\nimport { isDefined } from '../../../../../base/common/types.js';\nimport { ITreeSitterThemeService } from '../../../services/treeSitter/treeSitterThemeService.js';\nimport { BugIndicatingError } from '../../../../../base/common/errors.js';\n\nexport class TreeSitterTokenizationImpl extends Disposable {\n\tprivate readonly _tokenStore: TokenStore;\n\tprivate _accurateVersion: number;\n\tprivate _guessVersion: number;\n\n\tprivate readonly _onDidChangeTokens: Emitter<{ changes: IModelTokensChangedEvent }> = this._register(new Emitter());\n\tpublic readonly onDidChangeTokens: Event<{ changes: IModelTokensChangedEvent }> = this._onDidChangeTokens.event;\n\tprivate readonly _onDidCompleteBackgroundTokenization: Emitter<void> = this._register(new Emitter());\n\tpublic readonly onDidChangeBackgroundTokenization: Event<void> = this._onDidCompleteBackgroundTokenization.event;\n\n\tprivate _encodedLanguageId: LanguageId;\n\n\tprivate get _textModel() {\n\t\treturn this._tree.textModel;\n\t}\n\n\tconstructor(\n\t\tprivate readonly _tree: TreeSitterTree,\n\t\tprivate readonly _highlightingQueries: TreeSitter.Query,\n\t\tprivate readonly _languageIdCodec: ILanguageIdCodec,\n\t\tprivate readonly _visibleLineRanges: IObservable<readonly LineRange[]>,\n\n\t\t@ITreeSitterThemeService private readonly _treeSitterThemeService: ITreeSitterThemeService,\n\t) {\n\t\tsuper();\n\n\t\tthis._encodedLanguageId = this._languageIdCodec.encodeLanguageId(this._tree.languageId);\n\n\t\tthis._register(runOnChange(this._treeSitterThemeService.onChange, () => {\n\t\t\tthis._updateTheme();\n\t\t}));\n\n\t\tthis._tokenStore = this._register(new TokenStore(this._textModel));\n\t\tthis._accurateVersion = this._textModel.getVersionId();\n\t\tthis._guessVersion = this._textModel.getVersionId();\n\t\tthis._tokenStore.buildStore(this._createEmptyTokens(), TokenQuality.None);\n\n\t\tthis._register(autorun(reader => {\n\t\t\tconst visibleLineRanges = this._visibleLineRanges.read(reader);\n\t\t\tthis._parseAndTokenizeViewPort(visibleLineRanges);\n\t\t}));\n\n\t\tthis._register(autorunHandleChanges({\n\t\t\towner: this,\n\t\t\tchangeTracker: recordChanges({ tree: this._tree.tree }),\n\t\t}, (reader, ctx) => {\n\t\t\tconst changeEvent = ctx.changes.at(0)?.change;\n\t\t\tif (ctx.changes.length > 1) {\n\t\t\t\tthrow new BugIndicatingError('The tree changed twice in one transaction. This is currently not supported and should not happen.');\n\t\t\t}\n\n\t\t\tif (!changeEvent) {\n\t\t\t\tif (ctx.tree) {\n\t\t\t\t\tthis._firstTreeUpdate(this._tree.treeLastParsedVersion.read(reader));\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (this.hasTokens()) {\n\t\t\t\t\t// Mark the range for refresh immediately\n\n\t\t\t\t\tfor (const range of changeEvent.ranges) {\n\t\t\t\t\t\tthis._markForRefresh(range.newRange);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// First time we see a tree we need to build a token store.\n\t\t\t\tif (!this.hasTokens()) {\n\t\t\t\t\tthis._firstTreeUpdate(changeEvent.versionId);\n\t\t\t\t} else {\n\t\t\t\t\tthis._handleTreeUpdate(changeEvent.ranges, changeEvent.versionId);\n\t\t\t\t}\n\t\t\t}\n\t\t}));\n\t}\n\n\tpublic handleContentChanged(e: IModelContentChangedEvent): void {\n\t\tthis._guessVersion = e.versionId;\n\t\tfor (const change of e.changes) {\n\t\t\tif (change.text.length > change.rangeLength) {\n\t\t\t\t// If possible, use the token before the change as the starting point for the new token.\n\t\t\t\t// This is more likely to let the new text be the correct color as typeing is usually at the end of the token.\n\t\t\t\tconst offset = change.rangeOffset > 0 ? change.rangeOffset - 1 : change.rangeOffset;\n\t\t\t\tconst oldToken = this._tokenStore.getTokenAt(offset);\n\t\t\t\tlet newToken: TokenUpdate;\n\t\t\t\tif (oldToken) {\n\t\t\t\t\t// Insert. Just grow the token at this position to include the insert.\n\t\t\t\t\tnewToken = { startOffsetInclusive: oldToken.startOffsetInclusive, length: oldToken.length + change.text.length - change.rangeLength, token: oldToken.token };\n\t\t\t\t\t// Also mark tokens that are in the range of the change as needing a refresh.\n\t\t\t\t\tthis._tokenStore.markForRefresh(offset, change.rangeOffset + (change.text.length > change.rangeLength ? change.text.length : change.rangeLength));\n\t\t\t\t} else {\n\t\t\t\t\t// The document got larger and the change is at the end of the document.\n\t\t\t\t\tnewToken = { startOffsetInclusive: offset, length: change.text.length, token: 0 };\n\t\t\t\t}\n\t\t\t\tthis._tokenStore.update(oldToken?.length ?? 0, [newToken], TokenQuality.EditGuess);\n\t\t\t} else if (change.text.length < change.rangeLength) {\n\t\t\t\t// Delete. Delete the tokens at the corresponding range.\n\t\t\t\tconst deletedCharCount = change.rangeLength - change.text.length;\n\t\t\t\tthis._tokenStore.delete(deletedCharCount, change.rangeOffset);\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic getLineTokens(lineNumber: number) {\n\t\tconst content = this._textModel.getLineContent(lineNumber);\n\t\tconst rawTokens = this.getTokens(lineNumber);\n\t\treturn new LineTokens(rawTokens, content, this._languageIdCodec);\n\t}\n\n\tprivate _createEmptyTokens() {\n\t\tconst emptyToken = this._emptyToken();\n\t\tconst modelEndOffset = this._textModel.getValueLength();\n\n\t\tconst emptyTokens: TokenUpdate[] = [this._emptyTokensForOffsetAndLength(0, modelEndOffset, emptyToken)];\n\t\treturn emptyTokens;\n\t}\n\n\tprivate _emptyToken() {\n\t\treturn this._treeSitterThemeService.findMetadata([], this._encodedLanguageId, false, undefined);\n\t}\n\n\tprivate _emptyTokensForOffsetAndLength(offset: number, length: number, emptyToken: number): TokenUpdate {\n\t\treturn { token: emptyToken, length: offset + length, startOffsetInclusive: 0 };\n\t}\n\n\tpublic hasAccurateTokensForLine(lineNumber: number): boolean {\n\t\treturn this.hasTokens(new Range(lineNumber, 1, lineNumber, this._textModel.getLineMaxColumn(lineNumber)));\n\t}\n\n\tpublic tokenizeLinesAt(lineNumber: number, lines: string[]): LineTokens[] | null {\n\t\tconst rawLineTokens = this._guessTokensForLinesContent(lineNumber, lines);\n\t\tconst lineTokens: LineTokens[] = [];\n\t\tif (!rawLineTokens) {\n\t\t\treturn null;\n\t\t}\n\t\tfor (let i = 0; i < rawLineTokens.length; i++) {\n\t\t\tlineTokens.push(new LineTokens(rawLineTokens[i], lines[i], this._languageIdCodec));\n\t\t}\n\t\treturn lineTokens;\n\t}\n\n\tprivate _rangeHasTokens(range: Range, minimumTokenQuality: TokenQuality): boolean {\n\t\treturn this._tokenStore.rangeHasTokens(this._textModel.getOffsetAt(range.getStartPosition()), this._textModel.getOffsetAt(range.getEndPosition()), minimumTokenQuality);\n\t}\n\n\tpublic hasTokens(accurateForRange?: Range): boolean {\n\t\tif (!accurateForRange || (this._guessVersion === this._accurateVersion)) {\n\t\t\treturn true;\n\t\t}\n\n\t\treturn !this._tokenStore.rangeNeedsRefresh(this._textModel.getOffsetAt(accurateForRange.getStartPosition()), this._textModel.getOffsetAt(accurateForRange.getEndPosition()));\n\t}\n\n\tpublic getTokens(line: number): Uint32Array {\n\t\tconst lineStartOffset = this._textModel.getOffsetAt({ lineNumber: line, column: 1 });\n\t\tconst lineEndOffset = this._textModel.getOffsetAt({ lineNumber: line, column: this._textModel.getLineLength(line) + 1 });\n\t\tconst lineTokens = this._tokenStore.getTokensInRange(lineStartOffset, lineEndOffset);\n\t\tconst result = new Uint32Array(lineTokens.length * 2);\n\t\tfor (let i = 0; i < lineTokens.length; i++) {\n\t\t\tresult[i * 2] = lineTokens[i].startOffsetInclusive - lineStartOffset + lineTokens[i].length;\n\t\t\tresult[i * 2 + 1] = lineTokens[i].token;\n\t\t}\n\t\treturn result;\n\t}\n\n\tgetTokensInRange(range: Range, rangeStartOffset: number, rangeEndOffset: number, captures?: QueryCapture[]): TokenUpdate[] | undefined {\n\t\tconst tokens = captures ? this._tokenizeCapturesWithMetadata(captures, rangeStartOffset, rangeEndOffset) : this._tokenize(range, rangeStartOffset, rangeEndOffset);\n\t\tif (tokens?.endOffsetsAndMetadata) {\n\t\t\treturn this._rangeTokensAsUpdates(rangeStartOffset, tokens.endOffsetsAndMetadata);\n\t\t}\n\t\treturn undefined;\n\t}\n\n\tprivate _updateTokensInStore(version: number, updates: { oldRangeLength?: number; newTokens: TokenUpdate[] }[], tokenQuality: TokenQuality): void {\n\t\tthis._accurateVersion = version;\n\t\tfor (const update of updates) {\n\t\t\tconst lastToken = update.newTokens.length > 0 ? update.newTokens[update.newTokens.length - 1] : undefined;\n\t\t\tlet oldRangeLength: number;\n\t\t\tif (lastToken && (this._guessVersion >= version)) {\n\t\t\t\toldRangeLength = lastToken.startOffsetInclusive + lastToken.length - update.newTokens[0].startOffsetInclusive;\n\t\t\t} else if (update.oldRangeLength) {\n\t\t\t\toldRangeLength = update.oldRangeLength;\n\t\t\t} else {\n\t\t\t\toldRangeLength = 0;\n\t\t\t}\n\t\t\tthis._tokenStore.update(oldRangeLength, update.newTokens, tokenQuality);\n\t\t}\n\t}\n\n\tprivate _markForRefresh(range: Range): void {\n\t\tthis._tokenStore.markForRefresh(this._textModel.getOffsetAt(range.getStartPosition()), this._textModel.getOffsetAt(range.getEndPosition()));\n\t}\n\n\tprivate _getNeedsRefresh(): { range: Range; startOffset: number; endOffset: number }[] {\n\t\tconst needsRefreshOffsetRanges = this._tokenStore.getNeedsRefresh();\n\t\tif (!needsRefreshOffsetRanges) {\n\t\t\treturn [];\n\t\t}\n\t\treturn needsRefreshOffsetRanges.map(range => ({\n\t\t\trange: Range.fromPositions(this._textModel.getPositionAt(range.startOffset), this._textModel.getPositionAt(range.endOffset)),\n\t\t\tstartOffset: range.startOffset,\n\t\t\tendOffset: range.endOffset\n\t\t}));\n\t}\n\n\n\tprivate _parseAndTokenizeViewPort(lineRanges: readonly LineRange[]) {\n\t\tconst viewportRanges = lineRanges.map(r => r.toInclusiveRange()).filter(isDefined);\n\t\tfor (const range of viewportRanges) {\n\t\t\tconst startOffsetOfRangeInDocument = this._textModel.getOffsetAt(range.getStartPosition());\n\t\t\tconst endOffsetOfRangeInDocument = this._textModel.getOffsetAt(range.getEndPosition());\n\t\t\tconst version = this._textModel.getVersionId();\n\t\t\tif (this._rangeHasTokens(range, TokenQuality.ViewportGuess)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tconst content = this._textModel.getValueInRange(range);\n\t\t\tconst tokenUpdates = this._forceParseAndTokenizeContent(range, startOffsetOfRangeInDocument, endOffsetOfRangeInDocument, content, true);\n\t\t\tif (!tokenUpdates || this._rangeHasTokens(range, TokenQuality.ViewportGuess)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (tokenUpdates.length === 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tconst lastToken = tokenUpdates[tokenUpdates.length - 1];\n\t\t\tconst oldRangeLength = lastToken.startOffsetInclusive + lastToken.length - tokenUpdates[0].startOffsetInclusive;\n\t\t\tthis._updateTokensInStore(version, [{ newTokens: tokenUpdates, oldRangeLength }], TokenQuality.ViewportGuess);\n\t\t\tthis._onDidChangeTokens.fire({ changes: { semanticTokensApplied: false, ranges: [{ fromLineNumber: range.startLineNumber, toLineNumber: range.endLineNumber }] } });\n\t\t}\n\t}\n\n\tprivate _guessTokensForLinesContent(lineNumber: number, lines: string[]): Uint32Array[] | undefined {\n\t\tif (lines.length === 0) {\n\t\t\treturn undefined;\n\t\t}\n\t\tconst lineContent = lines.join(this._textModel.getEOL());\n\t\tconst range = new Range(1, 1, lineNumber + lines.length, lines[lines.length - 1].length + 1);\n\t\tconst startOffset = this._textModel.getOffsetAt({ lineNumber, column: 1 });\n\t\tconst tokens = this._forceParseAndTokenizeContent(range, startOffset, startOffset + lineContent.length, lineContent, false);\n\t\tif (!tokens) {\n\t\t\treturn undefined;\n\t\t}\n\t\tconst tokensByLine: Uint32Array[] = new Array(lines.length);\n\t\tlet tokensIndex: number = 0;\n\t\tlet tokenStartOffset = 0;\n\t\tlet lineStartOffset = 0;\n\t\tfor (let i = 0; i < lines.length; i++) {\n\t\t\tconst tokensForLine: EndOffsetToken[] = [];\n\t\t\tlet moveToNextLine = false;\n\t\t\tfor (let j = tokensIndex; (!moveToNextLine && (j < tokens.length)); j++) {\n\t\t\t\tconst token = tokens[j];\n\t\t\t\tconst lineAdjustedEndOffset = token.endOffset - lineStartOffset;\n\t\t\t\tconst lineAdjustedStartOffset = tokenStartOffset - lineStartOffset;\n\t\t\t\tif (lineAdjustedEndOffset <= lines[i].length) {\n\t\t\t\t\ttokensForLine.push({ endOffset: lineAdjustedEndOffset, metadata: token.metadata });\n\t\t\t\t\ttokensIndex++;\n\t\t\t\t} else if (lineAdjustedStartOffset < lines[i].length) {\n\t\t\t\t\tconst partialToken: EndOffsetToken = { endOffset: lines[i].length, metadata: token.metadata };\n\t\t\t\t\ttokensForLine.push(partialToken);\n\t\t\t\t\tmoveToNextLine = true;\n\t\t\t\t} else {\n\t\t\t\t\tmoveToNextLine = true;\n\t\t\t\t}\n\t\t\t\ttokenStartOffset = token.endOffset;\n\t\t\t}\n\n\t\t\ttokensByLine[i] = this._endOffsetTokensToUint32Array(tokensForLine);\n\t\t\tlineStartOffset += lines[i].length + this._textModel.getEOL().length;\n\t\t}\n\n\t\treturn tokensByLine;\n\t}\n\n\tprivate _forceParseAndTokenizeContent(range: Range, startOffsetOfRangeInDocument: number, endOffsetOfRangeInDocument: number, content: string, asUpdate: true): TokenUpdate[] | undefined;\n\tprivate _forceParseAndTokenizeContent(range: Range, startOffsetOfRangeInDocument: number, endOffsetOfRangeInDocument: number, content: string, asUpdate: false): EndOffsetToken[] | undefined;\n\tprivate _forceParseAndTokenizeContent(range: Range, startOffsetOfRangeInDocument: number, endOffsetOfRangeInDocument: number, content: string, asUpdate: boolean): EndOffsetToken[] | TokenUpdate[] | undefined {\n\t\tconst likelyRelevantLines = findLikelyRelevantLines(this._textModel, range.startLineNumber).likelyRelevantLines;\n\t\tconst likelyRelevantPrefix = likelyRelevantLines.join(this._textModel.getEOL());\n\n\t\tconst tree = this._tree.createParsedTreeSync(`${likelyRelevantPrefix}${content}`);\n\t\tif (!tree) {\n\t\t\treturn;\n\t\t}\n\n\t\tconst treeRange = new Range(1, 1, range.endLineNumber - range.startLineNumber + 1 + likelyRelevantLines.length, range.endColumn);\n\t\tconst captures = this.captureAtRange(treeRange);\n\t\tconst tokens = this._tokenizeCapturesWithMetadata(captures, likelyRelevantPrefix.length, endOffsetOfRangeInDocument - startOffsetOfRangeInDocument + likelyRelevantPrefix.length);\n\t\ttree.delete();\n\n\t\tif (!tokens) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (asUpdate) {\n\t\t\treturn this._rangeTokensAsUpdates(startOffsetOfRangeInDocument, tokens.endOffsetsAndMetadata, likelyRelevantPrefix.length);\n\t\t} else {\n\t\t\treturn tokens.endOffsetsAndMetadata;\n\t\t}\n\t}\n\n\n\tprivate _firstTreeUpdate(versionId: number) {\n\t\treturn this._setViewPortTokens(versionId);\n\t}\n\n\tprivate _setViewPortTokens(versionId: number) {\n\t\tconst rangeChanges = this._visibleLineRanges.get().map<RangeChange | undefined>(lineRange => {\n\t\t\tconst range = lineRange.toInclusiveRange();\n\t\t\tif (!range) { return undefined; }\n\t\t\tconst newRangeStartOffset = this._textModel.getOffsetAt(range.getStartPosition());\n\t\t\tconst newRangeEndOffset = this._textModel.getOffsetAt(range.getEndPosition());\n\t\t\treturn {\n\t\t\t\tnewRange: range,\n\t\t\t\tnewRangeEndOffset,\n\t\t\t\tnewRangeStartOffset,\n\t\t\t};\n\t\t}).filter(isDefined);\n\n\t\treturn this._handleTreeUpdate(rangeChanges, versionId);\n\t}\n\n\t/**\n\t * Do not await in this method, it will cause a race\n\t */\n\tprivate _handleTreeUpdate(ranges: RangeChange[], versionId: number) {\n\t\tconst rangeChanges: RangeWithOffsets[] = [];\n\t\tconst chunkSize = 1000;\n\n\t\tfor (let i = 0; i < ranges.length; i++) {\n\t\t\tconst rangeLinesLength = ranges[i].newRange.endLineNumber - ranges[i].newRange.startLineNumber;\n\t\t\tif (rangeLinesLength > chunkSize) {\n\t\t\t\t// Split the range into chunks to avoid long operations\n\t\t\t\tconst fullRangeEndLineNumber = ranges[i].newRange.endLineNumber;\n\t\t\t\tlet chunkLineStart = ranges[i].newRange.startLineNumber;\n\t\t\t\tlet chunkColumnStart = ranges[i].newRange.startColumn;\n\t\t\t\tlet chunkLineEnd = chunkLineStart + chunkSize;\n\t\t\t\tdo {\n\t\t\t\t\tconst chunkStartingPosition = new Position(chunkLineStart, chunkColumnStart);\n\t\t\t\t\tconst chunkEndColumn = ((chunkLineEnd === ranges[i].newRange.endLineNumber) ? ranges[i].newRange.endColumn : this._textModel.getLineMaxColumn(chunkLineEnd));\n\t\t\t\t\tconst chunkEndPosition = new Position(chunkLineEnd, chunkEndColumn);\n\t\t\t\t\tconst chunkRange = Range.fromPositions(chunkStartingPosition, chunkEndPosition);\n\n\t\t\t\t\trangeChanges.push({\n\t\t\t\t\t\trange: chunkRange,\n\t\t\t\t\t\tstartOffset: this._textModel.getOffsetAt(chunkRange.getStartPosition()),\n\t\t\t\t\t\tendOffset: this._textModel.getOffsetAt(chunkRange.getEndPosition())\n\t\t\t\t\t});\n\n\t\t\t\t\tchunkLineStart = chunkLineEnd + 1;\n\t\t\t\t\tchunkColumnStart = 1;\n\t\t\t\t\tif (chunkLineEnd < fullRangeEndLineNumber && chunkLineEnd + chunkSize > fullRangeEndLineNumber) {\n\t\t\t\t\t\tchunkLineEnd = fullRangeEndLineNumber;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tchunkLineEnd = chunkLineEnd + chunkSize;\n\t\t\t\t\t}\n\t\t\t\t} while (chunkLineEnd <= fullRangeEndLineNumber);\n\t\t\t} else {\n\t\t\t\t// Check that the previous range doesn't overlap\n\t\t\t\tif ((i === 0) || (rangeChanges[i - 1].endOffset < ranges[i].newRangeStartOffset)) {\n\t\t\t\t\trangeChanges.push({\n\t\t\t\t\t\trange: ranges[i].newRange,\n\t\t\t\t\t\tstartOffset: ranges[i].newRangeStartOffset,\n\t\t\t\t\t\tendOffset: ranges[i].newRangeEndOffset\n\t\t\t\t\t});\n\t\t\t\t} else if (rangeChanges[i - 1].endOffset < ranges[i].newRangeEndOffset) {\n\t\t\t\t\t// clip the range to the previous range\n\t\t\t\t\tconst startPosition = this._textModel.getPositionAt(rangeChanges[i - 1].endOffset + 1);\n\t\t\t\t\tconst range = new Range(startPosition.lineNumber, startPosition.column, ranges[i].newRange.endLineNumber, ranges[i].newRange.endColumn);\n\t\t\t\t\trangeChanges.push({\n\t\t\t\t\t\trange,\n\t\t\t\t\t\tstartOffset: rangeChanges[i - 1].endOffset + 1,\n\t\t\t\t\t\tendOffset: ranges[i].newRangeEndOffset\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Get the captures immediately while the text model is correct\n\t\tconst captures = rangeChanges.map(range => this._getCaptures(range.range));\n\t\t// Don't block\n\t\treturn this._updateTreeForRanges(rangeChanges, versionId, captures).then(() => {\n\t\t\tif (!this._textModel.isDisposed() && (this._tree.treeLastParsedVersion.get() === this._textModel.getVersionId())) {\n\t\t\t\tthis._refreshNeedsRefresh(versionId);\n\t\t\t}\n\t\t});\n\t}\n\n\tprivate async _updateTreeForRanges(rangeChanges: RangeWithOffsets[], versionId: number, captures: QueryCapture[][]) {\n\t\tlet tokenUpdate: { newTokens: TokenUpdate[] } | undefined;\n\n\t\tfor (let i = 0; i < rangeChanges.length; i++) {\n\t\t\tif (!this._textModel.isDisposed() && versionId !== this._textModel.getVersionId()) {\n\t\t\t\t// Our captures have become invalid and we need to re-capture\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tconst capture = captures[i];\n\t\t\tconst range = rangeChanges[i];\n\n\t\t\tconst updates = this.getTokensInRange(range.range, range.startOffset, range.endOffset, capture);\n\t\t\tif (updates) {\n\t\t\t\ttokenUpdate = { newTokens: updates };\n\t\t\t} else {\n\t\t\t\ttokenUpdate = { newTokens: [] };\n\t\t\t}\n\t\t\tthis._updateTokensInStore(versionId, [tokenUpdate], TokenQuality.Accurate);\n\t\t\tthis._onDidChangeTokens.fire({\n\t\t\t\tchanges: {\n\t\t\t\t\tsemanticTokensApplied: false,\n\t\t\t\t\tranges: [{ fromLineNumber: range.range.getStartPosition().lineNumber, toLineNumber: range.range.getEndPosition().lineNumber }]\n\t\t\t\t}\n\t\t\t});\n\t\t\tawait new Promise<void>(resolve => setTimeout0(resolve));\n\t\t}\n\t\tthis._onDidCompleteBackgroundTokenization.fire();\n\t}\n\n\tprivate _refreshNeedsRefresh(versionId: number) {\n\t\tconst rangesToRefresh = this._getNeedsRefresh();\n\t\tif (rangesToRefresh.length === 0) {\n\t\t\treturn;\n\t\t}\n\t\tconst rangeChanges: RangeChange[] = new Array(rangesToRefresh.length);\n\n\t\tfor (let i = 0; i < rangesToRefresh.length; i++) {\n\t\t\tconst range = rangesToRefresh[i];\n\t\t\trangeChanges[i] = {\n\t\t\t\tnewRange: range.range,\n\t\t\t\tnewRangeStartOffset: range.startOffset,\n\t\t\t\tnewRangeEndOffset: range.endOffset\n\t\t\t};\n\t\t}\n\n\t\tthis._handleTreeUpdate(rangeChanges, versionId);\n\t}\n\n\tprivate _rangeTokensAsUpdates(rangeOffset: number, endOffsetToken: EndOffsetToken[], startingOffsetInArray?: number) {\n\t\tconst updates: TokenUpdate[] = [];\n\t\tlet lastEnd = 0;\n\t\tfor (const token of endOffsetToken) {\n\t\t\tif (token.endOffset <= lastEnd || (startingOffsetInArray && (token.endOffset < startingOffsetInArray))) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tlet tokenUpdate: TokenUpdate;\n\t\t\tif (startingOffsetInArray && (lastEnd < startingOffsetInArray)) {\n\t\t\t\ttokenUpdate = { startOffsetInclusive: rangeOffset + startingOffsetInArray, length: token.endOffset - startingOffsetInArray, token: token.metadata };\n\t\t\t} else {\n\t\t\t\ttokenUpdate = { startOffsetInclusive: rangeOffset + lastEnd, length: token.endOffset - lastEnd, token: token.metadata };\n\t\t\t}\n\t\t\tupdates.push(tokenUpdate);\n\t\t\tlastEnd = token.endOffset;\n\t\t}\n\t\treturn updates;\n\t}\n\n\tprivate _updateTheme() {\n\t\tconst modelRange = this._textModel.getFullModelRange();\n\t\tthis._markForRefresh(modelRange);\n\t\tthis._parseAndTokenizeViewPort(this._visibleLineRanges.get());\n\t}\n\n\tprivate captureAtRange(range: Range): QueryCapture[] {\n\t\tconst tree = this._tree.tree.get();\n\t\tif (!tree) {\n\t\t\treturn [];\n\t\t}\n\t\t// Tree sitter row is 0 based, column is 0 based\n\t\treturn this._highlightingQueries.captures(tree.rootNode, { startPosition: { row: range.startLineNumber - 1, column: range.startColumn - 1 }, endPosition: { row: range.endLineNumber - 1, column: range.endColumn - 1 } }).map(capture => (\n\t\t\t{\n\t\t\t\tname: capture.name,\n\t\t\t\ttext: capture.node.text,\n\t\t\t\tnode: {\n\t\t\t\t\tstartIndex: capture.node.startIndex,\n\t\t\t\t\tendIndex: capture.node.endIndex,\n\t\t\t\t\tstartPosition: {\n\t\t\t\t\t\tlineNumber: capture.node.startPosition.row + 1,\n\t\t\t\t\t\tcolumn: capture.node.startPosition.column + 1\n\t\t\t\t\t},\n\t\t\t\t\tendPosition: {\n\t\t\t\t\t\tlineNumber: capture.node.endPosition.row + 1,\n\t\t\t\t\t\tcolumn: capture.node.endPosition.column + 1\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tencodedLanguageId: this._encodedLanguageId\n\t\t\t}\n\t\t));\n\t}\n\n\tprivate captureAtRangeWithInjections(range: Range): QueryCapture[] {\n\t\tconst captures: QueryCapture[] = this.captureAtRange(range);\n\t\tfor (let i = 0; i < captures.length; i++) {\n\t\t\tconst capture = captures[i];\n\n\t\t\tconst capStartLine = capture.node.startPosition.lineNumber;\n\t\t\tconst capEndLine = capture.node.endPosition.lineNumber;\n\t\t\tconst capStartColumn = capture.node.startPosition.column;\n\t\t\tconst capEndColumn = capture.node.endPosition.column;\n\n\t\t\tconst startLine = ((capStartLine > range.startLineNumber) && (capStartLine < range.endLineNumber)) ? capStartLine : range.startLineNumber;\n\t\t\tconst endLine = ((capEndLine > range.startLineNumber) && (capEndLine < range.endLineNumber)) ? capEndLine : range.endLineNumber;\n\t\t\tconst startColumn = (capStartLine === range.startLineNumber) ? (capStartColumn < range.startColumn ? range.startColumn : capStartColumn) : (capStartLine < range.startLineNumber ? range.startColumn : capStartColumn);\n\t\t\tconst endColumn = (capEndLine === range.endLineNumber) ? (capEndColumn > range.endColumn ? range.endColumn : capEndColumn) : (capEndLine > range.endLineNumber ? range.endColumn : capEndColumn);\n\t\t\tconst injectionRange = new Range(startLine, startColumn, endLine, endColumn);\n\n\t\t\tconst injection = this._getInjectionCaptures(capture, injectionRange);\n\t\t\tif (injection && injection.length > 0) {\n\t\t\t\tcaptures.splice(i + 1, 0, ...injection);\n\t\t\t\ti += injection.length;\n\t\t\t}\n\t\t}\n\t\treturn captures;\n\t}\n\n\t/**\n\t * Gets the tokens for a given line.\n\t * Each token takes 2 elements in the array. The first element is the offset of the end of the token *in the line, not in the document*, and the second element is the metadata.\n\t *\n\t * @param lineNumber\n\t * @returns\n\t */\n\tpublic tokenizeEncoded(lineNumber: number) {\n\t\tconst tokens = this._tokenizeEncoded(lineNumber);\n\t\tif (!tokens) {\n\t\t\treturn undefined;\n\t\t}\n\t\tconst updates = this._rangeTokensAsUpdates(this._textModel.getOffsetAt({ lineNumber, column: 1 }), tokens.result);\n\t\tif (tokens.versionId === this._textModel.getVersionId()) {\n\t\t\tthis._updateTokensInStore(tokens.versionId, [{ newTokens: updates, oldRangeLength: this._textModel.getLineLength(lineNumber) }], TokenQuality.Accurate);\n\t\t}\n\t}\n\n\tprivate _getCaptures(range: Range): QueryCapture[] {\n\t\tconst captures = this.captureAtRangeWithInjections(range);\n\t\treturn captures;\n\t}\n\n\tprivate _tokenize(range: Range, rangeStartOffset: number, rangeEndOffset: number): { endOffsetsAndMetadata: { endOffset: number; metadata: number }[]; versionId: number; captureTime: number; metadataTime: number } | undefined {\n\t\tconst captures = this._getCaptures(range);\n\t\tconst result = this._tokenizeCapturesWithMetadata(captures, rangeStartOffset, rangeEndOffset);\n\t\tif (!result) {\n\t\t\treturn undefined;\n\t\t}\n\t\treturn { ...result, versionId: this._tree.treeLastParsedVersion.get() };\n\t}\n\n\tprivate _createTokensFromCaptures(captures: QueryCapture[], rangeStartOffset: number, rangeEndOffset: number): { endOffsets: EndOffsetAndScopes[]; captureTime: number } | undefined {\n\t\tconst tree = this._tree.tree.get();\n\t\tconst stopwatch = StopWatch.create();\n\t\tconst rangeLength = rangeEndOffset - rangeStartOffset;\n\t\tconst encodedLanguageId = this._languageIdCodec.encodeLanguageId(this._tree.languageId);\n\t\tconst baseScope: string = TREESITTER_BASE_SCOPES[this._tree.languageId] || 'source';\n\n\t\tif (captures.length === 0) {\n\t\t\tif (tree) {\n\t\t\t\tstopwatch.stop();\n\t\t\t\tconst endOffsetsAndMetadata = [{ endOffset: rangeLength, scopes: [], encodedLanguageId }];\n\t\t\t\treturn { endOffsets: endOffsetsAndMetadata, captureTime: stopwatch.elapsed() };\n\t\t\t}\n\t\t\treturn undefined;\n\t\t}\n\n\t\tconst endOffsetsAndScopes: EndOffsetAndScopes[] = Array(captures.length);\n\t\tendOffsetsAndScopes.fill({ endOffset: 0, scopes: [baseScope], encodedLanguageId });\n\t\tlet tokenIndex = 0;\n\n\t\tconst increaseSizeOfTokensByOneToken = () => {\n\t\t\tendOffsetsAndScopes.push({ endOffset: 0, scopes: [baseScope], encodedLanguageId });\n\t\t};\n\n\t\tconst brackets = (capture: QueryCapture, startOffset: number): number[] | undefined => {\n\t\t\treturn (capture.name.includes('punctuation') && capture.text) ? Array.from(capture.text.matchAll(BRACKETS)).map(match => startOffset + match.index) : undefined;\n\t\t};\n\n\t\tconst addCurrentTokenToArray = (capture: QueryCapture, startOffset: number, endOffset: number, position?: number) => {\n\t\t\tif (position !== undefined) {\n\t\t\t\tconst oldScopes = endOffsetsAndScopes[position].scopes;\n\t\t\t\tlet oldBracket = endOffsetsAndScopes[position].bracket;\n\t\t\t\t// Check that the previous token ends at the same point that the current token starts\n\t\t\t\tconst prevEndOffset = position > 0 ? endOffsetsAndScopes[position - 1].endOffset : 0;\n\t\t\t\tif (prevEndOffset !== startOffset) {\n\t\t\t\t\tlet preInsertBracket: number[] | undefined = undefined;\n\t\t\t\t\tif (oldBracket && oldBracket.length > 0) {\n\t\t\t\t\t\tpreInsertBracket = [];\n\t\t\t\t\t\tconst postInsertBracket: number[] = [];\n\t\t\t\t\t\tfor (let i = 0; i < oldBracket.length; i++) {\n\t\t\t\t\t\t\tconst bracket = oldBracket[i];\n\t\t\t\t\t\t\tif (bracket < startOffset) {\n\t\t\t\t\t\t\t\tpreInsertBracket.push(bracket);\n\t\t\t\t\t\t\t} else if (bracket > endOffset) {\n\t\t\t\t\t\t\t\tpostInsertBracket.push(bracket);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (preInsertBracket.length === 0) {\n\t\t\t\t\t\t\tpreInsertBracket = undefined;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (postInsertBracket.length === 0) {\n\t\t\t\t\t\t\toldBracket = undefined;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\toldBracket = postInsertBracket;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// We need to add some of the position token to cover the space\n\t\t\t\t\tendOffsetsAndScopes.splice(position, 0, { endOffset: startOffset, scopes: [...oldScopes], bracket: preInsertBracket, encodedLanguageId: capture.encodedLanguageId });\n\t\t\t\t\tposition++;\n\t\t\t\t\tincreaseSizeOfTokensByOneToken();\n\t\t\t\t\ttokenIndex++;\n\t\t\t\t}\n\n\t\t\t\tendOffsetsAndScopes.splice(position, 0, { endOffset: endOffset, scopes: [...oldScopes, capture.name], bracket: brackets(capture, startOffset), encodedLanguageId: capture.encodedLanguageId });\n\t\t\t\tendOffsetsAndScopes[tokenIndex].bracket = oldBracket;\n\t\t\t} else {\n\t\t\t\tendOffsetsAndScopes[tokenIndex] = { endOffset: endOffset, scopes: [baseScope, capture.name], bracket: brackets(capture, startOffset), encodedLanguageId: capture.encodedLanguageId };\n\t\t\t}\n\t\t\ttokenIndex++;\n\t\t};\n\n\t\tfor (let captureIndex = 0; captureIndex < captures.length; captureIndex++) {\n\t\t\tconst capture = captures[captureIndex];\n\t\t\tconst tokenEndIndex = capture.node.endIndex < rangeEndOffset ? ((capture.node.endIndex < rangeStartOffset) ? rangeStartOffset : capture.node.endIndex) : rangeEndOffset;\n\t\t\tconst tokenStartIndex = capture.node.startIndex < rangeStartOffset ? rangeStartOffset : capture.node.startIndex;\n\n\t\t\tconst endOffset = tokenEndIndex - rangeStartOffset;\n\n\t\t\t// Not every character will get captured, so we need to make sure that our current capture doesn't bleed toward the start of the line and cover characters that it doesn't apply to.\n\t\t\t// We do this by creating a new token in the array if the previous token ends before the current token starts.\n\t\t\tlet previousEndOffset: number;\n\t\t\tconst currentTokenLength = tokenEndIndex - tokenStartIndex;\n\t\t\tif (captureIndex > 0) {\n\t\t\t\tpreviousEndOffset = endOffsetsAndScopes[(tokenIndex - 1)].endOffset;\n\t\t\t} else {\n\t\t\t\tpreviousEndOffset = tokenStartIndex - rangeStartOffset - 1;\n\t\t\t}\n\t\t\tconst startOffset = endOffset - currentTokenLength;\n\t\t\tif ((previousEndOffset >= 0) && (previousEndOffset < startOffset)) {\n\t\t\t\t// Add en empty token to cover the space where there were no captures\n\t\t\t\tendOffsetsAndScopes[tokenIndex] = { endOffset: startOffset, scopes: [baseScope], encodedLanguageId: this._encodedLanguageId };\n\t\t\t\ttokenIndex++;\n\n\t\t\t\tincreaseSizeOfTokensByOneToken();\n\t\t\t}\n\n\t\t\tif (currentTokenLength < 0) {\n\t\t\t\t// This happens when we have a token \"gap\" right at the end of the capture range. The last capture isn't used because it's start index isn't included in the range.\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (previousEndOffset >= endOffset) {\n\t\t\t\t// walk back through the tokens until we find the one that contains the current token\n\t\t\t\tlet withinTokenIndex = tokenIndex - 1;\n\t\t\t\tlet previousTokenEndOffset = endOffsetsAndScopes[withinTokenIndex].endOffset;\n\n\t\t\t\tlet previousTokenStartOffset = ((withinTokenIndex >= 2) ? endOffsetsAndScopes[withinTokenIndex - 1].endOffset : 0);\n\t\t\t\tdo {\n\n\t\t\t\t\t// Check that the current token doesn't just replace the last token\n\t\t\t\t\tif ((previousTokenStartOffset + currentTokenLength) === previousTokenEndOffset) {\n\t\t\t\t\t\tif (previousTokenStartOffset === startOffset) {\n\t\t\t\t\t\t\t// Current token and previous token span the exact same characters, add the scopes to the previous token\n\t\t\t\t\t\t\tendOffsetsAndScopes[withinTokenIndex].scopes.push(capture.name);\n\t\t\t\t\t\t\tconst oldBracket = endOffsetsAndScopes[withinTokenIndex].bracket;\n\t\t\t\t\t\t\tendOffsetsAndScopes[withinTokenIndex].bracket = ((oldBracket && (oldBracket.length > 0)) ? oldBracket : brackets(capture, startOffset));\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (previousTokenStartOffset <= startOffset) {\n\t\t\t\t\t\taddCurrentTokenToArray(capture, startOffset, endOffset, withinTokenIndex);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\twithinTokenIndex--;\n\t\t\t\t\tpreviousTokenStartOffset = ((withinTokenIndex >= 1) ? endOffsetsAndScopes[withinTokenIndex - 1].endOffset : 0);\n\t\t\t\t\tpreviousTokenEndOffset = ((withinTokenIndex >= 0) ? endOffsetsAndScopes[withinTokenIndex].endOffset : 0);\n\t\t\t\t} while (previousTokenEndOffset > startOffset);\n\t\t\t} else {\n\t\t\t\t// Just add the token to the array\n\t\t\t\taddCurrentTokenToArray(capture, startOffset, endOffset);\n\t\t\t}\n\t\t}\n\n\t\t// Account for uncaptured characters at the end of the line\n\t\tif ((endOffsetsAndScopes[tokenIndex - 1].endOffset < rangeLength)) {\n\t\t\tif (rangeLength - endOffsetsAndScopes[tokenIndex - 1].endOffset > 0) {\n\t\t\t\tincreaseSizeOfTokensByOneToken();\n\t\t\t\tendOffsetsAndScopes[tokenIndex] = { endOffset: rangeLength, scopes: endOffsetsAndScopes[tokenIndex].scopes, encodedLanguageId: this._encodedLanguageId };\n\t\t\t\ttokenIndex++;\n\t\t\t}\n\t\t}\n\t\tfor (let i = 0; i < endOffsetsAndScopes.length; i++) {\n\t\t\tconst token = endOffsetsAndScopes[i];\n\t\t\tif (token.endOffset === 0 && i !== 0) {\n\t\t\t\tendOffsetsAndScopes.splice(i, endOffsetsAndScopes.length - i);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tconst captureTime = stopwatch.elapsed();\n\t\treturn { endOffsets: endOffsetsAndScopes as { endOffset: number; scopes: string[]; encodedLanguageId: LanguageId }[], captureTime };\n\t}\n\n\tprivate _getInjectionCaptures(parentCapture: QueryCapture, range: Range): QueryCapture[] {\n\t\t/*\n\t\t\t\tconst injection = textModelTreeSitter.getInjection(parentCapture.node.startIndex, this._treeSitterModel.languageId);\n\t\t\t\tif (!injection?.tree || injection.versionId !== textModelTreeSitter.parseResult?.versionId) {\n\t\t\t\t\treturn undefined;\n\t\t\t\t}\n\n\t\t\t\tconst feature = TreeSitterTokenizationRegistry.get(injection.languageId);\n\t\t\t\tif (!feature) {\n\t\t\t\t\treturn undefined;\n\t\t\t\t}\n\t\t\t\treturn feature.tokSupport_captureAtRangeTree(range, injection.tree, textModelTreeSitter);*/\n\t\treturn [];\n\t}\n\n\tprivate _tokenizeCapturesWithMetadata(captures: QueryCapture[], rangeStartOffset: number, rangeEndOffset: number): { endOffsetsAndMetadata: EndOffsetToken[]; captureTime: number; metadataTime: number } | undefined {\n\t\tconst stopwatch = StopWatch.create();\n\t\tconst emptyTokens = this._createTokensFromCaptures(captures, rangeStartOffset, rangeEndOffset);\n\t\tif (!emptyTokens) {\n\t\t\treturn undefined;\n\t\t}\n\t\tconst endOffsetsAndScopes: EndOffsetWithMeta[] = emptyTokens.endOffsets;\n\t\tfor (let i = 0; i < endOffsetsAndScopes.length; i++) {\n\t\t\tconst token = endOffsetsAndScopes[i];\n\t\t\ttoken.metadata = this._treeSitterThemeService.findMetadata(token.scopes, token.encodedLanguageId, !!token.bracket && (token.bracket.length > 0), undefined);\n\t\t}\n\n\t\tconst metadataTime = stopwatch.elapsed();\n\t\treturn { endOffsetsAndMetadata: endOffsetsAndScopes as { endOffset: number; scopes: string[]; metadata: number }[], captureTime: emptyTokens.captureTime, metadataTime };\n\t}\n\n\tprivate _tokenizeEncoded(lineNumber: number): { result: EndOffsetToken[]; captureTime: number; metadataTime: number; versionId: number } | undefined {\n\t\tconst lineOffset = this._textModel.getOffsetAt({ lineNumber: lineNumber, column: 1 });\n\t\tconst maxLine = this._textModel.getLineCount();\n\t\tconst lineEndOffset = (lineNumber + 1 <= maxLine) ? this._textModel.getOffsetAt({ lineNumber: lineNumber + 1, column: 1 }) : this._textModel.getValueLength();\n\t\tconst lineLength = lineEndOffset - lineOffset;\n\n\t\tconst result = this._tokenize(new Range(lineNumber, 1, lineNumber, lineLength + 1), lineOffset, lineEndOffset);\n\t\tif (!result) {\n\t\t\treturn undefined;\n\t\t}\n\t\treturn { result: result.endOffsetsAndMetadata, captureTime: result.captureTime, metadataTime: result.metadataTime, versionId: result.versionId };\n\t}\n\n\tprivate _endOffsetTokensToUint32Array(endOffsetsAndMetadata: EndOffsetToken[]): Uint32Array {\n\n\t\tconst uint32Array = new Uint32Array(endOffsetsAndMetadata.length * 2);\n\t\tfor (let i = 0; i < endOffsetsAndMetadata.length; i++) {\n\t\t\tuint32Array[i * 2] = endOffsetsAndMetadata[i].endOffset;\n\t\t\tuint32Array[i * 2 + 1] = endOffsetsAndMetadata[i].metadata;\n\t\t}\n\t\treturn uint32Array;\n\t}\n}\n\n\ninterface EndOffsetToken {\n\tendOffset: number;\n\tmetadata: number;\n}\n\ninterface EndOffsetAndScopes {\n\tendOffset: number;\n\tscopes: string[];\n\tbracket?: number[];\n\tencodedLanguageId: LanguageId;\n}\n\ninterface EndOffsetWithMeta extends EndOffsetAndScopes {\n\tmetadata?: number;\n}\nexport const TREESITTER_BASE_SCOPES: Record<string, string> = {\n\t'css': 'source.css',\n\t'typescript': 'source.ts',\n\t'ini': 'source.ini',\n\t'regex': 'source.regex',\n};\n\nconst BRACKETS = /[\\{\\}\\[\\]\\<\\>\\(\\)]/g;\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport { Emitter, Event } from '../../../../../base/common/event.js';\nimport { Disposable } from '../../../../../base/common/lifecycle.js';\nimport { setTimeout0 } from '../../../../../base/common/platform.js';\nimport { StopWatch } from '../../../../../base/common/stopwatch.js';\nimport { LanguageId } from '../../../encodedTokenAttributes.js';\nimport { ILanguageIdCodec, QueryCapture } from '../../../languages.js';\nimport { IModelContentChangedEvent, IModelTokensChangedEvent } from '../../../textModelEvents.js';\nimport { findLikelyRelevantLines } from '../../textModelTokens.js';\nimport { TokenStore, TokenUpdate, TokenQuality } from './tokenStore.js';\nimport { TreeSitterTree, RangeChange, RangeWithOffsets } from './treeSitterTree.js';\nimport type * as TreeSitter from '@vscode/tree-sitter-wasm';\nimport { autorun, autorunHandleChanges, IObservable, recordChanges, runOnChange } from '../../../../../base/common/observable.js';\nimport { LineRange } from '../../../core/ranges/lineRange.js';\nimport { LineTokens } from '../../../tokens/lineTokens.js';\nimport { Position } from '../../../core/position.js';\nimport { Range } from '../../../core/range.js';\nimport { isDefined } from '../../../../../base/common/types.js';\nimport { ITreeSitterThemeService } from '../../../services/treeSitter/treeSitterThemeService.js';\nimport { BugIndicatingError } from '../../../../../base/common/errors.js';\n\nexport class TreeSitterTokenizationImpl extends Disposable {\n\tprivate readonly _tokenStore: TokenStore;\n\tprivate _accurateVersion: number;\n\tprivate _guessVersion: number;\n\n\tprivate readonly _onDidChangeTokens: Emitter<{ changes: IModelTokensChangedEvent }> = this._register(new Emitter());\n\tpublic readonly onDidChangeTokens: Event<{ changes: IModelTokensChangedEvent }> = this._onDidChangeTokens.event;\n\tprivate readonly _onDidCompleteBackgroundTokenization: Emitter<void> = this._register(new Emitter());\n\tpublic readonly onDidChangeBackgroundTokenization: Event<void> = this._onDidCompleteBackgroundTokenization.event;\n\n\tprivate _encodedLanguageId: LanguageId;\n\n\tprivate get _textModel() {\n\t\treturn this._tree.textModel;\n\t}\n\n\tconstructor(\n\t\tprivate readonly _tree: TreeSitterTree,\n\t\tprivate readonly _highlightingQueries: TreeSitter.Query,\n\t\tprivate readonly _languageIdCodec: ILanguageIdCodec,\n\t\tprivate readonly _visibleLineRanges: IObservable<readonly LineRange[]>,\n\n\t\t@ITreeSitterThemeService private readonly _treeSitterThemeService: ITreeSitterThemeService,\n\t) {\n\t\tsuper();\n\n\t\tthis._encodedLanguageId = this._languageIdCodec.encodeLanguageId(this._tree.languageId);\n\n\t\tthis._register(runOnChange(this._treeSitterThemeService.onChange, () => {\n\t\t\tthis._updateTheme();\n\t\t}));\n\n\t\tthis._tokenStore = this._register(new TokenStore(this._textModel));\n\t\tthis._accurateVersion = this._textModel.getVersionId();\n\t\tthis._guessVersion = this._textModel.getVersionId();\n\t\tthis._tokenStore.buildStore(this._createEmptyTokens(), TokenQuality.None);\n\n\t\tthis._register(autorun(reader => {\n\t\t\tconst visibleLineRanges = this._visibleLineRanges.read(reader);\n\t\t\tthis._parseAndTokenizeViewPort(visibleLineRanges);\n\t\t}));\n\n\t\tthis._register(autorunHandleChanges({\n\t\t\towner: this,\n\t\t\tchangeTracker: recordChanges({ tree: this._tree.tree }),\n\t\t}, (reader, ctx) => {\n\t\t\tconst changeEvent = ctx.changes.at(0)?.change;\n\t\t\tif (ctx.changes.length > 1) {\n\t\t\t\tthrow new BugIndicatingError('The tree changed twice in one transaction. This is currently not supported and should not happen.');\n\t\t\t}\n\n\t\t\tif (!changeEvent) {\n\t\t\t\tif (ctx.tree) {\n\t\t\t\t\tthis._firstTreeUpdate(this._tree.treeLastParsedVersion.read(reader));\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (this.hasTokens()) {\n\t\t\t\t\t// Mark the range for refresh immediately\n\n\t\t\t\t\tfor (const range of changeEvent.ranges) {\n\t\t\t\t\t\tthis._markForRefresh(range.newRange);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// First time we see a tree we need to build a token store.\n\t\t\t\tif (!this.hasTokens()) {\n\t\t\t\t\tthis._firstTreeUpdate(changeEvent.versionId);\n\t\t\t\t} else {\n\t\t\t\t\tthis._handleTreeUpdate(changeEvent.ranges, changeEvent.versionId);\n\t\t\t\t}\n\t\t\t}\n\t\t}));\n\t}\n\n\tpublic handleContentChanged(e: IModelContentChangedEvent): void {\n\t\tthis._guessVersion = e.versionId;\n\t\tfor (const change of e.changes) {\n\t\t\tif (change.text.length > change.rangeLength) {\n\t\t\t\t// If possible, use the token before the change as the starting point for the new token.\n\t\t\t\t// This is more likely to let the new text be the correct color as typeing is usually at the end of the token.\n\t\t\t\tconst offset = change.rangeOffset > 0 ? change.rangeOffset - 1 : change.rangeOffset;\n\t\t\t\tconst oldToken = this._tokenStore.getTokenAt(offset);\n\t\t\t\tlet newToken: TokenUpdate;\n\t\t\t\tif (oldToken) {\n\t\t\t\t\t// Insert. Just grow the token at this position to include the insert.\n\t\t\t\t\tnewToken = { startOffsetInclusive: oldToken.startOffsetInclusive, length: oldToken.length + change.text.length - change.rangeLength, token: oldToken.token };\n\t\t\t\t\t// Also mark tokens that are in the range of the change as needing a refresh.\n\t\t\t\t\tthis._tokenStore.markForRefresh(offset, change.rangeOffset + (change.text.length > change.rangeLength ? change.text.length : change.rangeLength));\n\t\t\t\t} else {\n\t\t\t\t\t// The document got larger and the change is at the end of the document.\n\t\t\t\t\tnewToken = { startOffsetInclusive: offset, length: change.text.length, token: 0 };\n\t\t\t\t}\n\t\t\t\tthis._tokenStore.update(oldToken?.length ?? 0, [newToken], TokenQuality.EditGuess);\n\t\t\t} else if (change.text.length < change.rangeLength) {\n\t\t\t\t// Delete. Delete the tokens at the corresponding range.\n\t\t\t\tconst deletedCharCount = change.rangeLength - change.text.length;\n\t\t\t\tthis._tokenStore.delete(deletedCharCount, change.rangeOffset);\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic getLineTokens(lineNumber: number) {\n\t\tconst content = this._textModel.getLineContent(lineNumber);\n\t\tconst rawTokens = this.getTokens(lineNumber);\n\t\treturn new LineTokens(rawTokens, content, this._languageIdCodec);\n\t}\n\n\tprivate _createEmptyTokens() {\n\t\tconst emptyToken = this._emptyToken();\n\t\tconst modelEndOffset = this._textModel.getValueLength();\n\n\t\tconst emptyTokens: TokenUpdate[] = [this._emptyTokensForOffsetAndLength(0, modelEndOffset, emptyToken)];\n\t\treturn emptyTokens;\n\t}\n\n\tprivate _emptyToken() {\n\t\treturn this._treeSitterThemeService.findMetadata([], this._encodedLanguageId, false, undefined);\n\t}\n\n\tprivate _emptyTokensForOffsetAndLength(offset: number, length: number, emptyToken: number): TokenUpdate {\n\t\treturn { token: emptyToken, length: offset + length, startOffsetInclusive: 0 };\n\t}\n\n\tpublic hasAccurateTokensForLine(lineNumber: number): boolean {\n\t\treturn this.hasTokens(new Range(lineNumber, 1, lineNumber, this._textModel.getLineMaxColumn(lineNumber)));\n\t}\n\n\tpublic tokenizeLinesAt(lineNumber: number, lines: string[]): LineTokens[] | null {\n\t\tconst rawLineTokens = this._guessTokensForLinesContent(lineNumber, lines);\n\t\tconst lineTokens: LineTokens[] = [];\n\t\tif (!rawLineTokens) {\n\t\t\treturn null;\n\t\t}\n\t\tfor (let i = 0; i < rawLineTokens.length; i++) {\n\t\t\tlineTokens.push(new LineTokens(rawLineTokens[i], lines[i], this._languageIdCodec));\n\t\t}\n\t\treturn lineTokens;\n\t}\n\n\tprivate _rangeHasTokens(range: Range, minimumTokenQuality: TokenQuality): boolean {\n\t\treturn this._tokenStore.rangeHasTokens(this._textModel.getOffsetAt(range.getStartPosition()), this._textModel.getOffsetAt(range.getEndPosition()), minimumTokenQuality);\n\t}\n\n\tpublic hasTokens(accurateForRange?: Range): boolean {\n\t\tif (!accurateForRange || (this._guessVersion === this._accurateVersion)) {\n\t\t\treturn true;\n\t\t}\n\n\t\treturn !this._tokenStore.rangeNeedsRefresh(this._textModel.getOffsetAt(accurateForRange.getStartPosition()), this._textModel.getOffsetAt(accurateForRange.getEndPosition()));\n\t}\n\n\tpublic getTokens(line: number): Uint32Array {\n\t\tconst lineStartOffset = this._textModel.getOffsetAt({ lineNumber: line, column: 1 });\n\t\tconst lineEndOffset = this._textModel.getOffsetAt({ lineNumber: line, column: this._textModel.getLineLength(line) + 1 });\n\t\tconst lineTokens = this._tokenStore.getTokensInRange(lineStartOffset, lineEndOffset);\n\t\tconst result = new Uint32Array(lineTokens.length * 2);\n\t\tfor (let i = 0; i < lineTokens.length; i++) {\n\t\t\tresult[i * 2] = lineTokens[i].startOffsetInclusive - lineStartOffset + lineTokens[i].length;\n\t\t\tresult[i * 2 + 1] = lineTokens[i].token;\n\t\t}\n\t\treturn result;\n\t}\n\n\tgetTokensInRange(range: Range, rangeStartOffset: number, rangeEndOffset: number, captures?: QueryCapture[]): TokenUpdate[] | undefined {\n\t\tconst tokens = captures ? this._tokenizeCapturesWithMetadata(captures, rangeStartOffset, rangeEndOffset) : this._tokenize(range, rangeStartOffset, rangeEndOffset);\n\t\tif (tokens?.endOffsetsAndMetadata) {\n\t\t\treturn this._rangeTokensAsUpdates(rangeStartOffset, tokens.endOffsetsAndMetadata);\n\t\t}\n\t\treturn undefined;\n\t}\n\n\tprivate _updateTokensInStore(version: number, updates: { oldRangeLength?: number; newTokens: TokenUpdate[] }[], tokenQuality: TokenQuality): void {\n\t\tthis._accurateVersion = version;\n\t\tfor (const update of updates) {\n\t\t\tconst lastToken = update.newTokens.length > 0 ? update.newTokens[update.newTokens.length - 1] : undefined;\n\t\t\tlet oldRangeLength: number;\n\t\t\tif (lastToken && (this._guessVersion >= version)) {\n\t\t\t\toldRangeLength = lastToken.startOffsetInclusive + lastToken.length - update.newTokens[0].startOffsetInclusive;\n\t\t\t} else if (update.oldRangeLength) {\n\t\t\t\toldRangeLength = update.oldRangeLength;\n\t\t\t} else {\n\t\t\t\toldRangeLength = 0;\n\t\t\t}\n\t\t\tthis._tokenStore.update(oldRangeLength, update.newTokens, tokenQuality);\n\t\t}\n\t}\n\n\tprivate _markForRefresh(range: Range): void {\n\t\tthis._tokenStore.markForRefresh(this._textModel.getOffsetAt(range.getStartPosition()), this._textModel.getOffsetAt(range.getEndPosition()));\n\t}\n\n\tprivate _getNeedsRefresh(): { range: Range; startOffset: number; endOffset: number }[] {\n\t\tconst needsRefreshOffsetRanges = this._tokenStore.getNeedsRefresh();\n\t\tif (!needsRefreshOffsetRanges) {\n\t\t\treturn [];\n\t\t}\n\t\treturn needsRefreshOffsetRanges.map(range => ({\n\t\t\trange: Range.fromPositions(this._textModel.getPositionAt(range.startOffset), this._textModel.getPositionAt(range.endOffset)),\n\t\t\tstartOffset: range.startOffset,\n\t\t\tendOffset: range.endOffset\n\t\t}));\n\t}\n\n\n\tprivate _parseAndTokenizeViewPort(lineRanges: readonly LineRange[]) {\n\t\tconst viewportRanges = lineRanges.map(r => r.toInclusiveRange()).filter(isDefined);\n\t\tfor (const range of viewportRanges) {\n\t\t\tconst startOffsetOfRangeInDocument = this._textModel.getOffsetAt(range.getStartPosition());\n\t\t\tconst endOffsetOfRangeInDocument = this._textModel.getOffsetAt(range.getEndPosition());\n\t\t\tconst version = this._textModel.getVersionId();\n\t\t\tif (this._rangeHasTokens(range, TokenQuality.ViewportGuess)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tconst content = this._textModel.getValueInRange(range);\n\t\t\tconst tokenUpdates = this._forceParseAndTokenizeContent(range, startOffsetOfRangeInDocument, endOffsetOfRangeInDocument, content, true);\n\t\t\tif (!tokenUpdates || this._rangeHasTokens(range, TokenQuality.ViewportGuess)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (tokenUpdates.length === 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tconst lastToken = tokenUpdates[tokenUpdates.length - 1];\n\t\t\tconst oldRangeLength = lastToken.startOffsetInclusive + lastToken.length - tokenUpdates[0].startOffsetInclusive;\n\t\t\tthis._updateTokensInStore(version, [{ newTokens: tokenUpdates, oldRangeLength }], TokenQuality.ViewportGuess);\n\t\t\tthis._onDidChangeTokens.fire({ changes: { semanticTokensApplied: false, ranges: [{ fromLineNumber: range.startLineNumber, toLineNumber: range.endLineNumber }] } });\n\t\t}\n\t}\n\n\tprivate _guessTokensForLinesContent(lineNumber: number, lines: string[]): Uint32Array[] | undefined {\n\t\tif (lines.length === 0) {\n\t\t\treturn undefined;\n\t\t}\n\t\tconst lineContent = lines.join(this._textModel.getEOL());\n\t\tconst range = new Range(1, 1, lineNumber + lines.length, lines[lines.length - 1].length + 1);\n\t\tconst startOffset = this._textModel.getOffsetAt({ lineNumber, column: 1 });\n\t\tconst tokens = this._forceParseAndTokenizeContent(range, startOffset, startOffset + lineContent.length, lineContent, false);\n\t\tif (!tokens) {\n\t\t\treturn undefined;\n\t\t}\n\t\tconst tokensByLine: Uint32Array[] = new Array(lines.length);\n\t\tlet tokensIndex: number = 0;\n\t\tlet tokenStartOffset = 0;\n\t\tlet lineStartOffset = 0;\n\t\tfor (let i = 0; i < lines.length; i++) {\n\t\t\tconst tokensForLine: EndOffsetToken[] = [];\n\t\t\tlet moveToNextLine = false;\n\t\t\tfor (let j = tokensIndex; (!moveToNextLine && (j < tokens.length)); j++) {\n\t\t\t\tconst token = tokens[j];\n\t\t\t\tconst lineAdjustedEndOffset = token.endOffset - lineStartOffset;\n\t\t\t\tconst lineAdjustedStartOffset = tokenStartOffset - lineStartOffset;\n\t\t\t\tif (lineAdjustedEndOffset <= lines[i].length) {\n\t\t\t\t\ttokensForLine.push({ endOffset: lineAdjustedEndOffset, metadata: token.metadata });\n\t\t\t\t\ttokensIndex++;\n\t\t\t\t} else if (lineAdjustedStartOffset < lines[i].length) {\n\t\t\t\t\tconst partialToken: EndOffsetToken = { endOffset: lines[i].length, metadata: token.metadata };\n\t\t\t\t\ttokensForLine.push(partialToken);\n\t\t\t\t\tmoveToNextLine = true;\n\t\t\t\t} else {\n\t\t\t\t\tmoveToNextLine = true;\n\t\t\t\t}\n\t\t\t\ttokenStartOffset = token.endOffset;\n\t\t\t}\n\n\t\t\ttokensByLine[i] = this._endOffsetTokensToUint32Array(tokensForLine);\n\t\t\tlineStartOffset += lines[i].length + this._textModel.getEOL().length;\n\t\t}\n\n\t\treturn tokensByLine;\n\t}\n\n\tprivate _forceParseAndTokenizeContent(range: Range, startOffsetOfRangeInDocument: number, endOffsetOfRangeInDocument: number, content: string, asUpdate: true): TokenUpdate[] | undefined;\n\tprivate _forceParseAndTokenizeContent(range: Range, startOffsetOfRangeInDocument: number, endOffsetOfRangeInDocument: number, content: string, asUpdate: false): EndOffsetToken[] | undefined;\n\tprivate _forceParseAndTokenizeContent(range: Range, startOffsetOfRangeInDocument: number, endOffsetOfRangeInDocument: number, content: string, asUpdate: boolean): EndOffsetToken[] | TokenUpdate[] | undefined {\n\t\tconst likelyRelevantLines = findLikelyRelevantLines(this._textModel, range.startLineNumber).likelyRelevantLines;\n\t\tconst likelyRelevantPrefix = likelyRelevantLines.join(this._textModel.getEOL());\n\n\t\tconst tree = this._tree.createParsedTreeSync(`${likelyRelevantPrefix}${content}`);\n\t\tif (!tree) {\n\t\t\treturn;\n\t\t}\n\n\t\tconst treeRange = new Range(1, 1, range.endLineNumber - range.startLineNumber + 1 + likelyRelevantLines.length, range.endColumn);\n\t\tconst captures = this.captureAtRange(treeRange);\n\t\tconst tokens = this._tokenizeCapturesWithMetadata(captures, likelyRelevantPrefix.length, endOffsetOfRangeInDocument - startOffsetOfRangeInDocument + likelyRelevantPrefix.length);\n\t\ttree.delete();\n\n\t\tif (!tokens) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (asUpdate) {\n\t\t\treturn this._rangeTokensAsUpdates(startOffsetOfRangeInDocument, tokens.endOffsetsAndMetadata, likelyRelevantPrefix.length);\n\t\t} else {\n\t\t\treturn tokens.endOffsetsAndMetadata;\n\t\t}\n\t}\n\n\n\tprivate _firstTreeUpdate(versionId: number) {\n\t\treturn this._setViewPortTokens(versionId);\n\t}\n\n\tprivate _setViewPortTokens(versionId: number) {\n\t\tconst rangeChanges = this._visibleLineRanges.get().map<RangeChange | undefined>(lineRange => {\n\t\t\tconst range = lineRange.toInclusiveRange();\n\t\t\tif (!range) { return undefined; }\n\t\t\tconst newRangeStartOffset = this._textModel.getOffsetAt(range.getStartPosition());\n\t\t\tconst newRangeEndOffset = this._textModel.getOffsetAt(range.getEndPosition());\n\t\t\treturn {\n\t\t\t\tnewRange: range,\n\t\t\t\tnewRangeEndOffset,\n\t\t\t\tnewRangeStartOffset,\n\t\t\t};\n\t\t}).filter(isDefined);\n\n\t\treturn this._handleTreeUpdate(rangeChanges, versionId);\n\t}\n\n\t/**\n\t * Do not await in this method, it will cause a race\n\t */\n\tprivate _handleTreeUpdate(ranges: RangeChange[], versionId: number) {\n\t\tconst rangeChanges: RangeWithOffsets[] = [];\n\t\tconst chunkSize = 1000;\n\n\t\tfor (let i = 0; i < ranges.length; i++) {\n\t\t\tconst rangeLinesLength = ranges[i].newRange.endLineNumber - ranges[i].newRange.startLineNumber;\n\t\t\tif (rangeLinesLength > chunkSize) {\n\t\t\t\t// Split the range into chunks to avoid long operations\n\t\t\t\tconst fullRangeEndLineNumber = ranges[i].newRange.endLineNumber;\n\t\t\t\tlet chunkLineStart = ranges[i].newRange.startLineNumber;\n\t\t\t\tlet chunkColumnStart = ranges[i].newRange.startColumn;\n\t\t\t\tlet chunkLineEnd = chunkLineStart + chunkSize;\n\t\t\t\tdo {\n\t\t\t\t\tconst chunkStartingPosition = new Position(chunkLineStart, chunkColumnStart);\n\t\t\t\t\tconst chunkEndColumn = ((chunkLineEnd === ranges[i].newRange.endLineNumber) ? ranges[i].newRange.endColumn : this._textModel.getLineMaxColumn(chunkLineEnd));\n\t\t\t\t\tconst chunkEndPosition = new Position(chunkLineEnd, chunkEndColumn);\n\t\t\t\t\tconst chunkRange = Range.fromPositions(chunkStartingPosition, chunkEndPosition);\n\n\t\t\t\t\trangeChanges.push({\n\t\t\t\t\t\trange: chunkRange,\n\t\t\t\t\t\tstartOffset: this._textModel.getOffsetAt(chunkRange.getStartPosition()),\n\t\t\t\t\t\tendOffset: this._textModel.getOffsetAt(chunkRange.getEndPosition())\n\t\t\t\t\t});\n\n\t\t\t\t\tchunkLineStart = chunkLineEnd + 1;\n\t\t\t\t\tchunkColumnStart = 1;\n\t\t\t\t\tif (chunkLineEnd < fullRangeEndLineNumber && chunkLineEnd + chunkSize > fullRangeEndLineNumber) {\n\t\t\t\t\t\tchunkLineEnd = fullRangeEndLineNumber;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tchunkLineEnd = chunkLineEnd + chunkSize;\n\t\t\t\t\t}\n\t\t\t\t} while (chunkLineEnd <= fullRangeEndLineNumber);\n\t\t\t} else {\n\t\t\t\t// Check that the previous range doesn't overlap\n\t\t\t\tif ((i === 0) || (rangeChanges[i - 1].endOffset < ranges[i].newRangeStartOffset)) {\n\t\t\t\t\trangeChanges.push({\n\t\t\t\t\t\trange: ranges[i].newRange,\n\t\t\t\t\t\tstartOffset: ranges[i].newRangeStartOffset,\n\t\t\t\t\t\tendOffset: ranges[i].newRangeEndOffset\n\t\t\t\t\t});\n\t\t\t\t} else if (rangeChanges[i - 1].endOffset < ranges[i].newRangeEndOffset) {\n\t\t\t\t\t// clip the range to the previous range\n\t\t\t\t\tconst startPosition = this._textModel.getPositionAt(rangeChanges[i - 1].endOffset + 1);\n\t\t\t\t\tconst range = new Range(startPosition.lineNumber, startPosition.column, ranges[i].newRange.endLineNumber, ranges[i].newRange.endColumn);\n\t\t\t\t\trangeChanges.push({\n\t\t\t\t\t\trange,\n\t\t\t\t\t\tstartOffset: rangeChanges[i - 1].endOffset + 1,\n\t\t\t\t\t\tendOffset: ranges[i].newRangeEndOffset\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Get the captures immediately while the text model is correct\n\t\tconst captures = rangeChanges.map(range => this._getCaptures(range.range));\n\t\t// Don't block\n\t\treturn this._updateTreeForRanges(rangeChanges, versionId, captures).then(() => {\n\t\t\tif (!this._textModel.isDisposed() && (this._tree.treeLastParsedVersion.get() === this._textModel.getVersionId())) {\n\t\t\t\tthis._refreshNeedsRefresh(versionId);\n\t\t\t}\n\t\t});\n\t}\n\n\tprivate async _updateTreeForRanges(rangeChanges: RangeWithOffsets[], versionId: number, captures: QueryCapture[][]) {\n\t\tlet tokenUpdate: { newTokens: TokenUpdate[] } | undefined;\n\n\t\tfor (let i = 0; i < rangeChanges.length; i++) {\n\t\t\tif (!this._textModel.isDisposed() && versionId !== this._textModel.getVersionId()) {\n\t\t\t\t// Our captures have become invalid and we need to re-capture\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tconst capture = captures[i];\n\t\t\tconst range = rangeChanges[i];\n\n\t\t\tconst updates = this.getTokensInRange(range.range, range.startOffset, range.endOffset, capture);\n\t\t\tif (updates) {\n\t\t\t\ttokenUpdate = { newTokens: updates };\n\t\t\t} else {\n\t\t\t\ttokenUpdate = { newTokens: [] };\n\t\t\t}\n\t\t\tthis._updateTokensInStore(versionId, [tokenUpdate], TokenQuality.Accurate);\n\t\t\tthis._onDidChangeTokens.fire({\n\t\t\t\tchanges: {\n\t\t\t\t\tsemanticTokensApplied: false,\n\t\t\t\t\tranges: [{ fromLineNumber: range.range.getStartPosition().lineNumber, toLineNumber: range.range.getEndPosition().lineNumber }]\n\t\t\t\t}\n\t\t\t});\n\t\t\tawait new Promise<void>(resolve => setTimeout0(resolve));\n\t\t}\n\t\tthis._onDidCompleteBackgroundTokenization.fire();\n\t}\n\n\tprivate _refreshNeedsRefresh(versionId: number) {\n\t\tconst rangesToRefresh = this._getNeedsRefresh();\n\t\tif (rangesToRefresh.length === 0) {\n\t\t\treturn;\n\t\t}\n\t\tconst rangeChanges: RangeChange[] = new Array(rangesToRefresh.length);\n\n\t\tfor (let i = 0; i < rangesToRefresh.length; i++) {\n\t\t\tconst range = rangesToRefresh[i];\n\t\t\trangeChanges[i] = {\n\t\t\t\tnewRange: range.range,\n\t\t\t\tnewRangeStartOffset: range.startOffset,\n\t\t\t\tnewRangeEndOffset: range.endOffset\n\t\t\t};\n\t\t}\n\n\t\tthis._handleTreeUpdate(rangeChanges, versionId);\n\t}\n\n\tprivate _rangeTokensAsUpdates(rangeOffset: number, endOffsetToken: EndOffsetToken[], startingOffsetInArray?: number) {\n\t\tconst updates: TokenUpdate[] = [];\n\t\tlet lastEnd = 0;\n\t\tfor (const token of endOffsetToken) {\n\t\t\tif (token.endOffset <= lastEnd || (startingOffsetInArray && (token.endOffset < startingOffsetInArray))) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tlet tokenUpdate: TokenUpdate;\n\t\t\tif (startingOffsetInArray && (lastEnd < startingOffsetInArray)) {\n\t\t\t\ttokenUpdate = { startOffsetInclusive: rangeOffset + startingOffsetInArray, length: token.endOffset - startingOffsetInArray, token: token.metadata };\n\t\t\t} else {\n\t\t\t\ttokenUpdate = { startOffsetInclusive: rangeOffset + lastEnd, length: token.endOffset - lastEnd, token: token.metadata };\n\t\t\t}\n\t\t\tupdates.push(tokenUpdate);\n\t\t\tlastEnd = token.endOffset;\n\t\t}\n\t\treturn updates;\n\t}\n\n\tprivate _updateTheme() {\n\t\tconst modelRange = this._textModel.getFullModelRange();\n\t\tthis._markForRefresh(modelRange);\n\t\tthis._parseAndTokenizeViewPort(this._visibleLineRanges.get());\n\t}\n\n\tprivate captureAtRange(range: Range): QueryCapture[] {\n\t\tconst tree = this._tree.tree.get();\n\t\tif (!tree) {\n\t\t\treturn [];\n\t\t}\n\t\t// Tree sitter row is 0 based, column is 0 based\n\t\treturn this._highlightingQueries.captures(tree.rootNode, { startPosition: { row: range.startLineNumber - 1, column: range.startColumn - 1 }, endPosition: { row: range.endLineNumber - 1, column: range.endColumn - 1 } }).map(capture => (\n\t\t\t{\n\t\t\t\tname: capture.name,\n\t\t\t\ttext: capture.node.text,\n\t\t\t\tnode: {\n\t\t\t\t\tstartIndex: capture.node.startIndex,\n\t\t\t\t\tendIndex: capture.node.endIndex,\n\t\t\t\t\tstartPosition: {\n\t\t\t\t\t\tlineNumber: capture.node.startPosition.row + 1,\n\t\t\t\t\t\tcolumn: capture.node.startPosition.column + 1\n\t\t\t\t\t},\n\t\t\t\t\tendPosition: {\n\t\t\t\t\t\tlineNumber: capture.node.endPosition.row + 1,\n\t\t\t\t\t\tcolumn: capture.node.endPosition.column + 1\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tencodedLanguageId: this._encodedLanguageId\n\t\t\t}\n\t\t));\n\t}\n\n\tprivate captureAtRangeWithInjections(range: Range): QueryCapture[] {\n\t\tconst captures: QueryCapture[] = this.captureAtRange(range);\n\t\tfor (let i = 0; i < captures.length; i++) {\n\t\t\tconst capture = captures[i];\n\n\t\t\tconst capStartLine = capture.node.startPosition.lineNumber;\n\t\t\tconst capEndLine = capture.node.endPosition.lineNumber;\n\t\t\tconst capStartColumn = capture.node.startPosition.column;\n\t\t\tconst capEndColumn = capture.node.endPosition.column;\n\n\t\t\tconst startLine = ((capStartLine > range.startLineNumber) && (capStartLine < range.endLineNumber)) ? capStartLine : range.startLineNumber;\n\t\t\tconst endLine = ((capEndLine > range.startLineNumber) && (capEndLine < range.endLineNumber)) ? capEndLine : range.endLineNumber;\n\t\t\tconst startColumn = (capStartLine === range.startLineNumber) ? (capStartColumn < range.startColumn ? range.startColumn : capStartColumn) : (capStartLine < range.startLineNumber ? range.startColumn : capStartColumn);\n\t\t\tconst endColumn = (capEndLine === range.endLineNumber) ? (capEndColumn > range.endColumn ? range.endColumn : capEndColumn) : (capEndLine > range.endLineNumber ? range.endColumn : capEndColumn);\n\t\t\tconst injectionRange = new Range(startLine, startColumn, endLine, endColumn);\n\n\t\t\tconst injection = this._getInjectionCaptures(capture, injectionRange);\n\t\t\tif (injection && injection.length > 0) {\n\t\t\t\tcaptures.splice(i + 1, 0, ...injection);\n\t\t\t\ti += injection.length;\n\t\t\t}\n\t\t}\n\t\treturn captures;\n\t}\n\n\t/**\n\t * Gets the tokens for a given line.\n\t * Each token takes 2 elements in the array. The first element is the offset of the end of the token *in the line, not in the document*, and the second element is the metadata.\n\t *\n\t * @param lineNumber\n\t * @returns\n\t */\n\tpublic tokenizeEncoded(lineNumber: number) {\n\t\tconst tokens = this._tokenizeEncoded(lineNumber);\n\t\tif (!tokens) {\n\t\t\treturn undefined;\n\t\t}\n\t\tconst updates = this._rangeTokensAsUpdates(this._textModel.getOffsetAt({ lineNumber, column: 1 }), tokens.result);\n\t\tif (tokens.versionId === this._textModel.getVersionId()) {\n\t\t\tthis._updateTokensInStore(tokens.versionId, [{ newTokens: updates, oldRangeLength: this._textModel.getLineLength(lineNumber) }], TokenQuality.Accurate);\n\t\t}\n\t}\n\n\tprivate _getCaptures(range: Range): QueryCapture[] {\n\t\tconst captures = this.captureAtRangeWithInjections(range);\n\t\treturn captures;\n\t}\n\n\tprivate _tokenize(range: Range, rangeStartOffset: number, rangeEndOffset: number): { endOffsetsAndMetadata: { endOffset: number; metadata: number }[]; versionId: number; captureTime: number; metadataTime: number } | undefined {\n\t\tconst captures = this._getCaptures(range);\n\t\tconst result = this._tokenizeCapturesWithMetadata(captures, rangeStartOffset, rangeEndOffset);\n\t\tif (!result) {\n\t\t\treturn undefined;\n\t\t}\n\t\treturn { ...result, versionId: this._tree.treeLastParsedVersion.get() };\n\t}\n\n\tprivate _createTokensFromCaptures(captures: QueryCapture[], rangeStartOffset: number, rangeEndOffset: number): { endOffsets: EndOffsetAndScopes[]; captureTime: number } | undefined {\n\t\tconst tree = this._tree.tree.get();\n\t\tconst stopwatch = StopWatch.create();\n\t\tconst rangeLength = rangeEndOffset - rangeStartOffset;\n\t\tconst encodedLanguageId = this._languageIdCodec.encodeLanguageId(this._tree.languageId);\n\t\tconst baseScope: string = TREESITTER_BASE_SCOPES[this._tree.languageId] || 'source';\n\n\t\tif (captures.length === 0) {\n\t\t\tif (tree) {\n\t\t\t\tstopwatch.stop();\n\t\t\t\tconst endOffsetsAndMetadata = [{ endOffset: rangeLength, scopes: [], encodedLanguageId }];\n\t\t\t\treturn { endOffsets: endOffsetsAndMetadata, captureTime: stopwatch.elapsed() };\n\t\t\t}\n\t\t\treturn undefined;\n\t\t}\n\n\t\tconst endOffsetsAndScopes: EndOffsetAndScopes[] = Array(captures.length);\n\t\tendOffsetsAndScopes.fill({ endOffset: 0, scopes: [baseScope], encodedLanguageId });\n\t\tlet tokenIndex = 0;\n\n\t\tconst increaseSizeOfTokensByOneToken = () => {\n\t\t\tendOffsetsAndScopes.push({ endOffset: 0, scopes: [baseScope], encodedLanguageId });\n\t\t};\n\n\t\tconst brackets = (capture: QueryCapture, startOffset: number): number[] | undefined => {\n\t\t\treturn (capture.name.includes('punctuation') && capture.text) ? Array.from(capture.text.matchAll(BRACKETS)).map(match => startOffset + match.index) : undefined;\n\t\t};\n\n\t\tconst addCurrentTokenToArray = (capture: QueryCapture, startOffset: number, endOffset: number, position?: number) => {\n\t\t\tif (position !== undefined) {\n\t\t\t\tconst oldScopes = endOffsetsAndScopes[position].scopes;\n\t\t\t\tlet oldBracket = endOffsetsAndScopes[position].bracket;\n\t\t\t\t// Check that the previous token ends at the same point that the current token starts\n\t\t\t\tconst prevEndOffset = position > 0 ? endOffsetsAndScopes[position - 1].endOffset : 0;\n\t\t\t\tif (prevEndOffset !== startOffset) {\n\t\t\t\t\tlet preInsertBracket: number[] | undefined = undefined;\n\t\t\t\t\tif (oldBracket && oldBracket.length > 0) {\n\t\t\t\t\t\tpreInsertBracket = [];\n\t\t\t\t\t\tconst postInsertBracket: number[] = [];\n\t\t\t\t\t\tfor (let i = 0; i < oldBracket.length; i++) {\n\t\t\t\t\t\t\tconst bracket = oldBracket[i];\n\t\t\t\t\t\t\tif (bracket < startOffset) {\n\t\t\t\t\t\t\t\tpreInsertBracket.push(bracket);\n\t\t\t\t\t\t\t} else if (bracket > endOffset) {\n\t\t\t\t\t\t\t\tpostInsertBracket.push(bracket);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (preInsertBracket.length === 0) {\n\t\t\t\t\t\t\tpreInsertBracket = undefined;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (postInsertBracket.length === 0) {\n\t\t\t\t\t\t\toldBracket = undefined;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\toldBracket = postInsertBracket;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t// We need to add some of the position token to cover the space\n\t\t\t\t\tendOffsetsAndScopes.splice(position, 0, { endOffset: startOffset, scopes: [...oldScopes], bracket: preInsertBracket, encodedLanguageId: capture.encodedLanguageId });\n\t\t\t\t\tposition++;\n\t\t\t\t\tincreaseSizeOfTokensByOneToken();\n\t\t\t\t\ttokenIndex++;\n\t\t\t\t}\n\n\t\t\t\tendOffsetsAndScopes.splice(position, 0, { endOffset: endOffset, scopes: [...oldScopes, capture.name], bracket: brackets(capture, startOffset), encodedLanguageId: capture.encodedLanguageId });\n\t\t\t\tendOffsetsAndScopes[tokenIndex].bracket = oldBracket;\n\t\t\t} else {\n\t\t\t\tendOffsetsAndScopes[tokenIndex] = { endOffset: endOffset, scopes: [baseScope, capture.name], bracket: brackets(capture, startOffset), encodedLanguageId: capture.encodedLanguageId };\n\t\t\t}\n\t\t\ttokenIndex++;\n\t\t};\n\n\t\tfor (let captureIndex = 0; captureIndex < captures.length; captureIndex++) {\n\t\t\tconst capture = captures[captureIndex];\n\t\t\tconst tokenEndIndex = capture.node.endIndex < rangeEndOffset ? ((capture.node.endIndex < rangeStartOffset) ? rangeStartOffset : capture.node.endIndex) : rangeEndOffset;\n\t\t\tconst tokenStartIndex = capture.node.startIndex < rangeStartOffset ? rangeStartOffset : capture.node.startIndex;\n\n\t\t\tconst endOffset = tokenEndIndex - rangeStartOffset;\n\n\t\t\t// Not every character will get captured, so we need to make sure that our current capture doesn't bleed toward the start of the line and cover characters that it doesn't apply to.\n\t\t\t// We do this by creating a new token in the array if the previous token ends before the current token starts.\n\t\t\tlet previousEndOffset: number;\n\t\t\tconst currentTokenLength = tokenEndIndex - tokenStartIndex;\n\t\t\tif (captureIndex > 0) {\n\t\t\t\tpreviousEndOffset = endOffsetsAndScopes[(tokenIndex - 1)].endOffset;\n\t\t\t} else {\n\t\t\t\tpreviousEndOffset = tokenStartIndex - rangeStartOffset - 1;\n\t\t\t}\n\t\t\tconst startOffset = endOffset - currentTokenLength;\n\t\t\tif ((previousEndOffset >= 0) && (previousEndOffset < startOffset)) {\n\t\t\t\t// Add en empty token to cover the space where there were no captures\n\t\t\t\tendOffsetsAndScopes[tokenIndex] = { endOffset: startOffset, scopes: [baseScope], encodedLanguageId: this._encodedLanguageId };\n\t\t\t\ttokenIndex++;\n\n\t\t\t\tincreaseSizeOfTokensByOneToken();\n\t\t\t}\n\n\t\t\tif (currentTokenLength < 0) {\n\t\t\t\t// This happens when we have a token \"gap\" right at the end of the capture range. The last capture isn't used because it's start index isn't included in the range.\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (previousEndOffset >= endOffset) {\n\t\t\t\t// walk back through the tokens until we find the one that contains the current token\n\t\t\t\tlet withinTokenIndex = tokenIndex - 1;\n\t\t\t\tlet previousTokenEndOffset = endOffsetsAndScopes[withinTokenIndex].endOffset;\n\n\t\t\t\tlet previousTokenStartOffset = ((withinTokenIndex >= 2) ? endOffsetsAndScopes[withinTokenIndex - 1].endOffset : 0);\n\t\t\t\tdo {\n\n\t\t\t\t\t// Check that the current token doesn't just replace the last token\n\t\t\t\t\tif ((previousTokenStartOffset + currentTokenLength) === previousTokenEndOffset) {\n\t\t\t\t\t\tif (previousTokenStartOffset === startOffset) {\n\t\t\t\t\t\t\t// Current token and previous token span the exact same characters, add the scopes to the previous token\n\t\t\t\t\t\t\tendOffsetsAndScopes[withinTokenIndex].scopes.push(capture.name);\n\t\t\t\t\t\t\tconst oldBracket = endOffsetsAndScopes[withinTokenIndex].bracket;\n\t\t\t\t\t\t\tendOffsetsAndScopes[withinTokenIndex].bracket = ((oldBracket && (oldBracket.length > 0)) ? oldBracket : brackets(capture, startOffset));\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (previousTokenStartOffset <= startOffset) {\n\t\t\t\t\t\taddCurrentTokenToArray(capture, startOffset, endOffset, withinTokenIndex);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\twithinTokenIndex--;\n\t\t\t\t\tpreviousTokenStartOffset = ((withinTokenIndex >= 1) ? endOffsetsAndScopes[withinTokenIndex - 1].endOffset : 0);\n\t\t\t\t\tpreviousTokenEndOffset = ((withinTokenIndex >= 0) ? endOffsetsAndScopes[withinTokenIndex].endOffset : 0);\n\t\t\t\t} while (previousTokenEndOffset > startOffset);\n\t\t\t} else {\n\t\t\t\t// Just add the token to the array\n\t\t\t\taddCurrentTokenToArray(capture, startOffset, endOffset);\n\t\t\t}\n\t\t}\n\n\t\t// Account for uncaptured characters at the end of the line\n\t\tif ((endOffsetsAndScopes[tokenIndex - 1].endOffset < rangeLength)) {\n\t\t\tif (rangeLength - endOffsetsAndScopes[tokenIndex - 1].endOffset > 0) {\n\t\t\t\tincreaseSizeOfTokensByOneToken();\n\t\t\t\tendOffsetsAndScopes[tokenIndex] = { endOffset: rangeLength, scopes: endOffsetsAndScopes[tokenIndex].scopes, encodedLanguageId: this._encodedLanguageId };\n\t\t\t\ttokenIndex++;\n\t\t\t}\n\t\t}\n\t\tfor (let i = 0; i < endOffsetsAndScopes.length; i++) {\n\t\t\tconst token = endOffsetsAndScopes[i];\n\t\t\tif (token.endOffset === 0 && i !== 0) {\n\t\t\t\tendOffsetsAndScopes.splice(i, endOffsetsAndScopes.length - i);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tconst captureTime = stopwatch.elapsed();\n\t\treturn { endOffsets: endOffsetsAndScopes as { endOffset: number; scopes: string[]; encodedLanguageId: LanguageId }[], captureTime };\n\t}\n\n\tprivate _getInjectionCaptures(parentCapture: QueryCapture, range: Range): QueryCapture[] {\n\t\t/*\n\t\t\t\tconst injection = textModelTreeSitter.getInjection(parentCapture.node.startIndex, this._treeSitterModel.languageId);\n\t\t\t\tif (!injection?.tree || injection.versionId !== textModelTreeSitter.parseResult?.versionId) {\n\t\t\t\t\treturn undefined;\n\t\t\t\t}\n\n\t\t\t\tconst feature = TreeSitterTokenizationRegistry.get(injection.languageId);\n\t\t\t\tif (!feature) {\n\t\t\t\t\treturn undefined;\n\t\t\t\t}\n\t\t\t\treturn feature.tokSupport_captureAtRangeTree(range, injection.tree, textModelTreeSitter);*/\n\t\treturn [];\n\t}\n\n\tprivate _tokenizeCapturesWithMetadata(captures: QueryCapture[], rangeStartOffset: number, rangeEndOffset: number): { endOffsetsAndMetadata: EndOffsetToken[]; captureTime: number; metadataTime: number } | undefined {\n\t\tconst stopwatch = StopWatch.create();\n\t\tconst emptyTokens = this._createTokensFromCaptures(captures, rangeStartOffset, rangeEndOffset);\n\t\tif (!emptyTokens) {\n\t\t\treturn undefined;\n\t\t}\n\t\tconst endOffsetsAndScopes: EndOffsetWithMeta[] = emptyTokens.endOffsets;\n\t\tfor (let i = 0; i < endOffsetsAndScopes.length; i++) {\n\t\t\tconst token = endOffsetsAndScopes[i];\n\t\t\ttoken.metadata = this._treeSitterThemeService.findMetadata(token.scopes, token.encodedLanguageId, !!token.bracket && (token.bracket.length > 0), undefined);\n\t\t}\n\n\t\tconst metadataTime = stopwatch.elapsed();\n\t\treturn { endOffsetsAndMetadata: endOffsetsAndScopes as { endOffset: number; scopes: string[]; metadata: number }[], captureTime: emptyTokens.captureTime, metadataTime };\n\t}\n\n\tprivate _tokenizeEncoded(lineNumber: number): { result: EndOffsetToken[]; captureTime: number; metadataTime: number; versionId: number } | undefined {\n\t\tconst lineOffset = this._textModel.getOffsetAt({ lineNumber: lineNumber, column: 1 });\n\t\tconst maxLine = this._textModel.getLineCount();\n\t\tconst lineEndOffset = (lineNumber + 1 <= maxLine) ? this._textModel.getOffsetAt({ lineNumber: lineNumber + 1, column: 1 }) : this._textModel.getValueLength();\n\t\tconst lineLength = lineEndOffset - lineOffset;\n\n\t\tconst result = this._tokenize(new Range(lineNumber, 1, lineNumber, lineLength + 1), lineOffset, lineEndOffset);\n\t\tif (!result) {\n\t\t\treturn undefined;\n\t\t}\n\t\treturn { result: result.endOffsetsAndMetadata, captureTime: result.captureTime, metadataTime: result.metadataTime, versionId: result.versionId };\n\t}\n\n\tprivate _endOffsetTokensToUint32Array(endOffsetsAndMetadata: EndOffsetToken[]): Uint32Array {\n\n\t\tconst uint32Array = new Uint32Array(endOffsetsAndMetadata.length * 2);\n\t\tfor (let i = 0; i < endOffsetsAndMetadata.length; i++) {\n\t\t\tuint32Array[i * 2] = endOffsetsAndMetadata[i].endOffset;\n\t\t\tuint32Array[i * 2 + 1] = endOffsetsAndMetadata[i].metadata;\n\t\t}\n\t\treturn uint32Array;\n\t}\n}\n\n\ninterface EndOffsetToken {\n\tendOffset: number;\n\tmetadata: number;\n}\n\ninterface EndOffsetAndScopes {\n\tendOffset: number;\n\tscopes: string[];\n\tbracket?: number[];\n\tencodedLanguageId: LanguageId;\n}\n\ninterface EndOffsetWithMeta extends EndOffsetAndScopes {\n\tmetadata?: number;\n}\nexport const TREESITTER_BASE_SCOPES: Record<string, string> = {\n\t'css': 'source.css',\n\t'typescript': 'source.ts',\n\t'ini': 'source.ini',\n\t'regex': 'source.regex',\n};\n\nconst BRACKETS = /[\\{\\}\\[\\]\\<\\>\\(\\)]/g;\n"]}