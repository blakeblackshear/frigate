{"version":3,"sources":["file:///mnt/vss/_work/1/s/dependencies/vscode/out-editor-src/vs/base/common/tfIdf.ts","vs/base/common/tfIdf.ts"],"names":[],"mappings":"AAAA;;;gGAGgG;AAQhG,SAAS,YAAY,CAAI,MAAmB;IAC3C,MAAM,GAAG,GAAG,IAAI,GAAG,EAAa,CAAC;IACjC,KAAK,MAAM,KAAK,IAAI,MAAM,EAAE,CAAC;QAC5B,GAAG,CAAC,GAAG,CAAC,KAAK,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;IAC3C,CAAC;IACD,OAAO,GAAG,CAAC;AACZ,CAAC;AA2BD;;;;;GAKG;AACH,MAAM,OAAO,eAAe;IAA5B;QAmDC;;WAEG;QACK,eAAU,GAAG,CAAC,CAAC;QAEN,qBAAgB,GAAwB,IAAI,GAAG,EAAqD,CAAC;QAErG,cAAS,GAAG,IAAI,GAAG,EAEhC,CAAC;IAwGN,CAAC;IAnKA,eAAe,CAAC,KAAa,EAAE,KAAwB;QACtD,MAAM,SAAS,GAAG,IAAI,CAAC,gBAAgB,CAAC,KAAK,CAAC,CAAC;QAC/C,MAAM,QAAQ,GAAG,IAAI,GAAG,EAAkB,CAAC;QAC3C,MAAM,MAAM,GAAiB,EAAE,CAAC;QAChC,wCAAwC;QACxC,KAAK,MAAM,CAAC,GAAG,EAAE,GAAG,CAAC,IAAI,IAAI,CAAC,SAAS,EAAE,CAAC;YACzC,IAAI,KAAK,CAAC,uBAAuB,EAAE,CAAC;gBACnC,OAAO,EAAE,CAAC;YACX,CAAC;YAED,KAAK,MAAM,KAAK,IAAI,GAAG,CAAC,MAAM,EAAE,CAAC;gBAChC,MAAM,KAAK,GAAG,IAAI,CAAC,sBAAsB,CAAC,KAAK,EAAE,SAAS,EAAE,QAAQ,CAAC,CAAC;gBACtE,IAAI,KAAK,GAAG,CAAC,EAAE,CAAC;oBACf,MAAM,CAAC,IAAI,CAAC,EAAE,GAAG,EAAE,KAAK,EAAE,CAAC,CAAC;gBAC7B,CAAC;YACF,CAAC;QACF,CAAC;QAED,OAAO,MAAM,CAAC;IACf,CAAC;IAED;;OAEG;IACK,MAAM,CAAC,eAAe,CAAC,KAAa;QAC3C,OAAO,YAAY,CAAC,eAAe,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC;IACxD,CAAC;IAED;;OAEG;IACK,MAAM,CAAC,CAAC,UAAU,CAAC,KAAa;QACvC,MAAM,SAAS,GAAG,CAAC,IAAY,EAAE,EAAE,CAAC,IAAI,CAAC,WAAW,EAAE,CAAC;QAEvD,kFAAkF;QAClF,KAAK,MAAM,CAAC,IAAI,CAAC,IAAI,KAAK,CAAC,QAAQ,CAAC,oCAAoC,CAAC,EAAE,CAAC;YAC3E,MAAM,SAAS,CAAC,IAAI,CAAC,CAAC;YAEtB,MAAM,UAAU,GAAG,IAAI,CAAC,OAAO,CAAC,iBAAiB,EAAE,OAAO,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;YAC1E,IAAI,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;gBAC3B,KAAK,MAAM,IAAI,IAAI,UAAU,EAAE,CAAC;oBAC/B,+DAA+D;oBAC/D,IAAI,IAAI,CAAC,MAAM,GAAG,CAAC,IAAI,kBAAkB,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC;wBACtD,MAAM,SAAS,CAAC,IAAI,CAAC,CAAC;oBACvB,CAAC;gBACF,CAAC;YACF,CAAC;QACF,CAAC;IACF,CAAC;IAaD,eAAe,CAAC,SAAuC;QACtD,KAAK,MAAM,EAAE,GAAG,EAAE,IAAI,SAAS,EAAE,CAAC;YACjC,IAAI,CAAC,cAAc,CAAC,GAAG,CAAC,CAAC;QAC1B,CAAC;QAED,KAAK,MAAM,GAAG,IAAI,SAAS,EAAE,CAAC;YAC7B,MAAM,MAAM,GAAiD,EAAE,CAAC;YAChE,KAAK,MAAM,IAAI,IAAI,GAAG,CAAC,UAAU,EAAE,CAAC;gBACnC,4CAA4C;gBAC5C,sEAAsE;gBACtE,yEAAyE;gBACzE,wBAAwB;gBACxB,MAAM,EAAE,GAAG,eAAe,CAAC,eAAe,CAAC,IAAI,CAAC,CAAC;gBAEjD,0BAA0B;gBAC1B,KAAK,MAAM,IAAI,IAAI,EAAE,CAAC,IAAI,EAAE,EAAE,CAAC;oBAC9B,IAAI,CAAC,gBAAgB,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,gBAAgB,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;gBAC7E,CAAC;gBAED,MAAM,CAAC,IAAI,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,CAAC,CAAC;YAC3B,CAAC;YAED,IAAI,CAAC,UAAU,IAAI,MAAM,CAAC,MAAM,CAAC;YACjC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,EAAE,EAAE,MAAM,EAAE,CAAC,CAAC;QACzC,CAAC;QACD,OAAO,IAAI,CAAC;IACb,CAAC;IAED,cAAc,CAAC,GAAW;QACzB,MAAM,GAAG,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;QACpC,IAAI,CAAC,GAAG,EAAE,CAAC;YACV,OAAO;QACR,CAAC;QAED,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QAC3B,IAAI,CAAC,UAAU,IAAI,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC;QAErC,2CAA2C;QAC3C,KAAK,MAAM,KAAK,IAAI,GAAG,CAAC,MAAM,EAAE,CAAC;YAChC,KAAK,MAAM,IAAI,IAAI,KAAK,CAAC,EAAE,CAAC,IAAI,EAAE,EAAE,CAAC;gBACpC,MAAM,kBAAkB,GAAG,IAAI,CAAC,gBAAgB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;gBAC3D,IAAI,OAAO,kBAAkB,KAAK,QAAQ,EAAE,CAAC;oBAC5C,MAAM,cAAc,GAAG,kBAAkB,GAAG,CAAC,CAAC;oBAC9C,IAAI,cAAc,IAAI,CAAC,EAAE,CAAC;wBACzB,IAAI,CAAC,gBAAgB,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;oBACpC,CAAC;yBAAM,CAAC;wBACP,IAAI,CAAC,gBAAgB,CAAC,GAAG,CAAC,IAAI,EAAE,cAAc,CAAC,CAAC;oBACjD,CAAC;gBACF,CAAC;YACF,CAAC;QACF,CAAC;IACF,CAAC;IAEO,sBAAsB,CAAC,KAAyB,EAAE,cAA+B,EAAE,QAA6B;QACvH,gFAAgF;QAEhF,wEAAwE;QACxE,wEAAwE;QACxE,mDAAmD;QAEnD,IAAI,GAAG,GAAG,CAAC,CAAC;QACZ,KAAK,MAAM,CAAC,IAAI,EAAE,SAAS,CAAC,IAAI,MAAM,CAAC,OAAO,CAAC,cAAc,CAAC,EAAE,CAAC;YAChE,MAAM,OAAO,GAAG,KAAK,CAAC,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;YACnC,IAAI,CAAC,OAAO,EAAE,CAAC;gBACd,0DAA0D;gBAC1D,SAAS;YACV,CAAC;YAED,IAAI,QAAQ,GAAG,QAAQ,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;YAClC,IAAI,OAAO,QAAQ,KAAK,QAAQ,EAAE,CAAC;gBAClC,QAAQ,GAAG,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;gBACjC,QAAQ,CAAC,GAAG,CAAC,IAAI,EAAE,QAAQ,CAAC,CAAC;YAC9B,CAAC;YAED,MAAM,UAAU,GAAG,OAAO,GAAG,QAAQ,CAAC;YACtC,GAAG,IAAI,UAAU,GAAG,SAAS,CAAC;QAC/B,CAAC;QACD,OAAO,GAAG,CAAC;IACZ,CAAC;IAEO,gBAAgB,CAAC,KAAa;QACrC,MAAM,EAAE,GAAG,eAAe,CAAC,eAAe,CAAC,KAAK,CAAC,CAAC;QAClD,OAAO,IAAI,CAAC,YAAY,CAAC,EAAE,CAAC,CAAC;IAC9B,CAAC;IAEO,UAAU,CAAC,IAAY;QAC9B,MAAM,gBAAgB,GAAG,IAAI,CAAC,gBAAgB,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC9D,OAAO,gBAAgB,GAAG,CAAC;YAC1B,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,UAAU,GAAG,CAAC,CAAC,GAAG,gBAAgB,CAAC;YACpD,CAAC,CAAC,CAAC,CAAC;IACN,CAAC;IAEO,YAAY,CAAC,eAAgC;QACpD,MAAM,SAAS,GAAG,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;QACtC,KAAK,MAAM,CAAC,IAAI,EAAE,WAAW,CAAC,IAAI,eAAe,EAAE,CAAC;YACnD,MAAM,GAAG,GAAG,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;YAClC,IAAI,GAAG,GAAG,CAAC,EAAE,CAAC;gBACb,SAAS,CAAC,IAAI,CAAC,GAAG,WAAW,GAAG,GAAG,CAAC;YACrC,CAAC;QACF,CAAC;QACD,OAAO,SAAS,CAAC;IAClB,CAAC;CACD;AAED;;;;GAIG;AACH,MAAM,UAAU,oBAAoB,CAAC,MAAoB;IAExD,iBAAiB;IACjB,MAAM,MAAM,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,CAAwB,CAAC;IAEtD,kBAAkB;IAClB,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC;IAEzC,YAAY;IACZ,MAAM,GAAG,GAAG,MAAM,CAAC,CAAC,CAAC,EAAE,KAAK,IAAI,CAAC,CAAC;IAClC,IAAI,GAAG,GAAG,CAAC,EAAE,CAAC;QACb,KAAK,MAAM,KAAK,IAAI,MAAM,EAAE,CAAC;YAC5B,KAAK,CAAC,KAAK,IAAI,GAAG,CAAC;QACpB,CAAC;IACF,CAAC;IAED,OAAO,MAAsB,CAAC;AAC/B,CAAC","file":"tfIdf.js","sourceRoot":"file:///mnt/vss/_work/1/s/dependencies/vscode/out-editor-src","sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport { CancellationToken } from './cancellation.js';\n\ntype SparseEmbedding = Record</* word */ string, /* weight */number>;\ntype TermFrequencies = Map</* word */ string, /*occurrences*/ number>;\ntype DocumentOccurrences = Map</* word */ string, /*documentOccurrences*/ number>;\n\nfunction countMapFrom<K>(values: Iterable<K>): Map<K, number> {\n\tconst map = new Map<K, number>();\n\tfor (const value of values) {\n\t\tmap.set(value, (map.get(value) ?? 0) + 1);\n\t}\n\treturn map;\n}\n\ninterface DocumentChunkEntry {\n\treadonly tf: TermFrequencies;\n}\n\nexport interface TfIdfDocument {\n\treadonly key: string;\n\treadonly textChunks: readonly string[];\n}\n\nexport interface TfIdfScore {\n\treadonly key: string;\n\t/**\n\t * An unbounded number.\n\t */\n\treadonly score: number;\n}\n\nexport interface NormalizedTfIdfScore {\n\treadonly key: string;\n\t/**\n\t * A number between 0 and 1.\n\t */\n\treadonly score: number;\n}\n\n/**\n * Implementation of tf-idf (term frequency-inverse document frequency) for a set of\n * documents where each document contains one or more chunks of text.\n * Each document is identified by a key, and the score for each document is computed\n * by taking the max score over all the chunks in the document.\n */\nexport class TfIdfCalculator {\n\tcalculateScores(query: string, token: CancellationToken): TfIdfScore[] {\n\t\tconst embedding = this.computeEmbedding(query);\n\t\tconst idfCache = new Map<string, number>();\n\t\tconst scores: TfIdfScore[] = [];\n\t\t// For each document, generate one score\n\t\tfor (const [key, doc] of this.documents) {\n\t\t\tif (token.isCancellationRequested) {\n\t\t\t\treturn [];\n\t\t\t}\n\n\t\t\tfor (const chunk of doc.chunks) {\n\t\t\t\tconst score = this.computeSimilarityScore(chunk, embedding, idfCache);\n\t\t\t\tif (score > 0) {\n\t\t\t\t\tscores.push({ key, score });\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn scores;\n\t}\n\n\t/**\n\t * Count how many times each term (word) appears in a string.\n\t */\n\tprivate static termFrequencies(input: string): TermFrequencies {\n\t\treturn countMapFrom(TfIdfCalculator.splitTerms(input));\n\t}\n\n\t/**\n\t * Break a string into terms (words).\n\t */\n\tprivate static *splitTerms(input: string): Iterable<string> {\n\t\tconst normalize = (word: string) => word.toLowerCase();\n\n\t\t// Only match on words that are at least 3 characters long and start with a letter\n\t\tfor (const [word] of input.matchAll(/\\b\\p{Letter}[\\p{Letter}\\d]{2,}\\b/gu)) {\n\t\t\tyield normalize(word);\n\n\t\t\tconst camelParts = word.replace(/([a-z])([A-Z])/g, '$1 $2').split(/\\s+/g);\n\t\t\tif (camelParts.length > 1) {\n\t\t\t\tfor (const part of camelParts) {\n\t\t\t\t\t// Require at least 3 letters in the parts of a camel case word\n\t\t\t\t\tif (part.length > 2 && /\\p{Letter}{3,}/gu.test(part)) {\n\t\t\t\t\t\tyield normalize(part);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Total number of chunks\n\t */\n\tprivate chunkCount = 0;\n\n\tprivate readonly chunkOccurrences: DocumentOccurrences = new Map</* word */ string, /*documentOccurrences*/ number>();\n\n\tprivate readonly documents = new Map</* key */ string, {\n\t\treadonly chunks: ReadonlyArray<DocumentChunkEntry>;\n\t}>();\n\n\tupdateDocuments(documents: ReadonlyArray<TfIdfDocument>): this {\n\t\tfor (const { key } of documents) {\n\t\t\tthis.deleteDocument(key);\n\t\t}\n\n\t\tfor (const doc of documents) {\n\t\t\tconst chunks: Array<{ text: string; tf: TermFrequencies }> = [];\n\t\t\tfor (const text of doc.textChunks) {\n\t\t\t\t// TODO: See if we can compute the tf lazily\n\t\t\t\t// The challenge is that we need to also update the `chunkOccurrences`\n\t\t\t\t// and all of those updates need to get flushed before the real TF-IDF of\n\t\t\t\t// anything is computed.\n\t\t\t\tconst tf = TfIdfCalculator.termFrequencies(text);\n\n\t\t\t\t// Update occurrences list\n\t\t\t\tfor (const term of tf.keys()) {\n\t\t\t\t\tthis.chunkOccurrences.set(term, (this.chunkOccurrences.get(term) ?? 0) + 1);\n\t\t\t\t}\n\n\t\t\t\tchunks.push({ text, tf });\n\t\t\t}\n\n\t\t\tthis.chunkCount += chunks.length;\n\t\t\tthis.documents.set(doc.key, { chunks });\n\t\t}\n\t\treturn this;\n\t}\n\n\tdeleteDocument(key: string) {\n\t\tconst doc = this.documents.get(key);\n\t\tif (!doc) {\n\t\t\treturn;\n\t\t}\n\n\t\tthis.documents.delete(key);\n\t\tthis.chunkCount -= doc.chunks.length;\n\n\t\t// Update term occurrences for the document\n\t\tfor (const chunk of doc.chunks) {\n\t\t\tfor (const term of chunk.tf.keys()) {\n\t\t\t\tconst currentOccurrences = this.chunkOccurrences.get(term);\n\t\t\t\tif (typeof currentOccurrences === 'number') {\n\t\t\t\t\tconst newOccurrences = currentOccurrences - 1;\n\t\t\t\t\tif (newOccurrences <= 0) {\n\t\t\t\t\t\tthis.chunkOccurrences.delete(term);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tthis.chunkOccurrences.set(term, newOccurrences);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate computeSimilarityScore(chunk: DocumentChunkEntry, queryEmbedding: SparseEmbedding, idfCache: Map<string, number>): number {\n\t\t// Compute the dot product between the chunk's embedding and the query embedding\n\n\t\t// Note that the chunk embedding is computed lazily on a per-term basis.\n\t\t// This lets us skip a large number of calculations because the majority\n\t\t// of chunks do not share any terms with the query.\n\n\t\tlet sum = 0;\n\t\tfor (const [term, termTfidf] of Object.entries(queryEmbedding)) {\n\t\t\tconst chunkTf = chunk.tf.get(term);\n\t\t\tif (!chunkTf) {\n\t\t\t\t// Term does not appear in chunk so it has no contribution\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tlet chunkIdf = idfCache.get(term);\n\t\t\tif (typeof chunkIdf !== 'number') {\n\t\t\t\tchunkIdf = this.computeIdf(term);\n\t\t\t\tidfCache.set(term, chunkIdf);\n\t\t\t}\n\n\t\t\tconst chunkTfidf = chunkTf * chunkIdf;\n\t\t\tsum += chunkTfidf * termTfidf;\n\t\t}\n\t\treturn sum;\n\t}\n\n\tprivate computeEmbedding(input: string): SparseEmbedding {\n\t\tconst tf = TfIdfCalculator.termFrequencies(input);\n\t\treturn this.computeTfidf(tf);\n\t}\n\n\tprivate computeIdf(term: string): number {\n\t\tconst chunkOccurrences = this.chunkOccurrences.get(term) ?? 0;\n\t\treturn chunkOccurrences > 0\n\t\t\t? Math.log((this.chunkCount + 1) / chunkOccurrences)\n\t\t\t: 0;\n\t}\n\n\tprivate computeTfidf(termFrequencies: TermFrequencies): SparseEmbedding {\n\t\tconst embedding = Object.create(null);\n\t\tfor (const [word, occurrences] of termFrequencies) {\n\t\t\tconst idf = this.computeIdf(word);\n\t\t\tif (idf > 0) {\n\t\t\t\tembedding[word] = occurrences * idf;\n\t\t\t}\n\t\t}\n\t\treturn embedding;\n\t}\n}\n\n/**\n * Normalize the scores to be between 0 and 1 and sort them decending.\n * @param scores array of scores from {@link TfIdfCalculator.calculateScores}\n * @returns normalized scores\n */\nexport function normalizeTfIdfScores(scores: TfIdfScore[]): NormalizedTfIdfScore[] {\n\n\t// copy of scores\n\tconst result = scores.slice(0) as { score: number }[];\n\n\t// sort descending\n\tresult.sort((a, b) => b.score - a.score);\n\n\t// normalize\n\tconst max = result[0]?.score ?? 0;\n\tif (max > 0) {\n\t\tfor (const score of result) {\n\t\t\tscore.score /= max;\n\t\t}\n\t}\n\n\treturn result as TfIdfScore[];\n}\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport { CancellationToken } from './cancellation.js';\n\ntype SparseEmbedding = Record</* word */ string, /* weight */number>;\ntype TermFrequencies = Map</* word */ string, /*occurrences*/ number>;\ntype DocumentOccurrences = Map</* word */ string, /*documentOccurrences*/ number>;\n\nfunction countMapFrom<K>(values: Iterable<K>): Map<K, number> {\n\tconst map = new Map<K, number>();\n\tfor (const value of values) {\n\t\tmap.set(value, (map.get(value) ?? 0) + 1);\n\t}\n\treturn map;\n}\n\ninterface DocumentChunkEntry {\n\treadonly tf: TermFrequencies;\n}\n\nexport interface TfIdfDocument {\n\treadonly key: string;\n\treadonly textChunks: readonly string[];\n}\n\nexport interface TfIdfScore {\n\treadonly key: string;\n\t/**\n\t * An unbounded number.\n\t */\n\treadonly score: number;\n}\n\nexport interface NormalizedTfIdfScore {\n\treadonly key: string;\n\t/**\n\t * A number between 0 and 1.\n\t */\n\treadonly score: number;\n}\n\n/**\n * Implementation of tf-idf (term frequency-inverse document frequency) for a set of\n * documents where each document contains one or more chunks of text.\n * Each document is identified by a key, and the score for each document is computed\n * by taking the max score over all the chunks in the document.\n */\nexport class TfIdfCalculator {\n\tcalculateScores(query: string, token: CancellationToken): TfIdfScore[] {\n\t\tconst embedding = this.computeEmbedding(query);\n\t\tconst idfCache = new Map<string, number>();\n\t\tconst scores: TfIdfScore[] = [];\n\t\t// For each document, generate one score\n\t\tfor (const [key, doc] of this.documents) {\n\t\t\tif (token.isCancellationRequested) {\n\t\t\t\treturn [];\n\t\t\t}\n\n\t\t\tfor (const chunk of doc.chunks) {\n\t\t\t\tconst score = this.computeSimilarityScore(chunk, embedding, idfCache);\n\t\t\t\tif (score > 0) {\n\t\t\t\t\tscores.push({ key, score });\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn scores;\n\t}\n\n\t/**\n\t * Count how many times each term (word) appears in a string.\n\t */\n\tprivate static termFrequencies(input: string): TermFrequencies {\n\t\treturn countMapFrom(TfIdfCalculator.splitTerms(input));\n\t}\n\n\t/**\n\t * Break a string into terms (words).\n\t */\n\tprivate static *splitTerms(input: string): Iterable<string> {\n\t\tconst normalize = (word: string) => word.toLowerCase();\n\n\t\t// Only match on words that are at least 3 characters long and start with a letter\n\t\tfor (const [word] of input.matchAll(/\\b\\p{Letter}[\\p{Letter}\\d]{2,}\\b/gu)) {\n\t\t\tyield normalize(word);\n\n\t\t\tconst camelParts = word.replace(/([a-z])([A-Z])/g, '$1 $2').split(/\\s+/g);\n\t\t\tif (camelParts.length > 1) {\n\t\t\t\tfor (const part of camelParts) {\n\t\t\t\t\t// Require at least 3 letters in the parts of a camel case word\n\t\t\t\t\tif (part.length > 2 && /\\p{Letter}{3,}/gu.test(part)) {\n\t\t\t\t\t\tyield normalize(part);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Total number of chunks\n\t */\n\tprivate chunkCount = 0;\n\n\tprivate readonly chunkOccurrences: DocumentOccurrences = new Map</* word */ string, /*documentOccurrences*/ number>();\n\n\tprivate readonly documents = new Map</* key */ string, {\n\t\treadonly chunks: ReadonlyArray<DocumentChunkEntry>;\n\t}>();\n\n\tupdateDocuments(documents: ReadonlyArray<TfIdfDocument>): this {\n\t\tfor (const { key } of documents) {\n\t\t\tthis.deleteDocument(key);\n\t\t}\n\n\t\tfor (const doc of documents) {\n\t\t\tconst chunks: Array<{ text: string; tf: TermFrequencies }> = [];\n\t\t\tfor (const text of doc.textChunks) {\n\t\t\t\t// TODO: See if we can compute the tf lazily\n\t\t\t\t// The challenge is that we need to also update the `chunkOccurrences`\n\t\t\t\t// and all of those updates need to get flushed before the real TF-IDF of\n\t\t\t\t// anything is computed.\n\t\t\t\tconst tf = TfIdfCalculator.termFrequencies(text);\n\n\t\t\t\t// Update occurrences list\n\t\t\t\tfor (const term of tf.keys()) {\n\t\t\t\t\tthis.chunkOccurrences.set(term, (this.chunkOccurrences.get(term) ?? 0) + 1);\n\t\t\t\t}\n\n\t\t\t\tchunks.push({ text, tf });\n\t\t\t}\n\n\t\t\tthis.chunkCount += chunks.length;\n\t\t\tthis.documents.set(doc.key, { chunks });\n\t\t}\n\t\treturn this;\n\t}\n\n\tdeleteDocument(key: string) {\n\t\tconst doc = this.documents.get(key);\n\t\tif (!doc) {\n\t\t\treturn;\n\t\t}\n\n\t\tthis.documents.delete(key);\n\t\tthis.chunkCount -= doc.chunks.length;\n\n\t\t// Update term occurrences for the document\n\t\tfor (const chunk of doc.chunks) {\n\t\t\tfor (const term of chunk.tf.keys()) {\n\t\t\t\tconst currentOccurrences = this.chunkOccurrences.get(term);\n\t\t\t\tif (typeof currentOccurrences === 'number') {\n\t\t\t\t\tconst newOccurrences = currentOccurrences - 1;\n\t\t\t\t\tif (newOccurrences <= 0) {\n\t\t\t\t\t\tthis.chunkOccurrences.delete(term);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tthis.chunkOccurrences.set(term, newOccurrences);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate computeSimilarityScore(chunk: DocumentChunkEntry, queryEmbedding: SparseEmbedding, idfCache: Map<string, number>): number {\n\t\t// Compute the dot product between the chunk's embedding and the query embedding\n\n\t\t// Note that the chunk embedding is computed lazily on a per-term basis.\n\t\t// This lets us skip a large number of calculations because the majority\n\t\t// of chunks do not share any terms with the query.\n\n\t\tlet sum = 0;\n\t\tfor (const [term, termTfidf] of Object.entries(queryEmbedding)) {\n\t\t\tconst chunkTf = chunk.tf.get(term);\n\t\t\tif (!chunkTf) {\n\t\t\t\t// Term does not appear in chunk so it has no contribution\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tlet chunkIdf = idfCache.get(term);\n\t\t\tif (typeof chunkIdf !== 'number') {\n\t\t\t\tchunkIdf = this.computeIdf(term);\n\t\t\t\tidfCache.set(term, chunkIdf);\n\t\t\t}\n\n\t\t\tconst chunkTfidf = chunkTf * chunkIdf;\n\t\t\tsum += chunkTfidf * termTfidf;\n\t\t}\n\t\treturn sum;\n\t}\n\n\tprivate computeEmbedding(input: string): SparseEmbedding {\n\t\tconst tf = TfIdfCalculator.termFrequencies(input);\n\t\treturn this.computeTfidf(tf);\n\t}\n\n\tprivate computeIdf(term: string): number {\n\t\tconst chunkOccurrences = this.chunkOccurrences.get(term) ?? 0;\n\t\treturn chunkOccurrences > 0\n\t\t\t? Math.log((this.chunkCount + 1) / chunkOccurrences)\n\t\t\t: 0;\n\t}\n\n\tprivate computeTfidf(termFrequencies: TermFrequencies): SparseEmbedding {\n\t\tconst embedding = Object.create(null);\n\t\tfor (const [word, occurrences] of termFrequencies) {\n\t\t\tconst idf = this.computeIdf(word);\n\t\t\tif (idf > 0) {\n\t\t\t\tembedding[word] = occurrences * idf;\n\t\t\t}\n\t\t}\n\t\treturn embedding;\n\t}\n}\n\n/**\n * Normalize the scores to be between 0 and 1 and sort them decending.\n * @param scores array of scores from {@link TfIdfCalculator.calculateScores}\n * @returns normalized scores\n */\nexport function normalizeTfIdfScores(scores: TfIdfScore[]): NormalizedTfIdfScore[] {\n\n\t// copy of scores\n\tconst result = scores.slice(0) as { score: number }[];\n\n\t// sort descending\n\tresult.sort((a, b) => b.score - a.score);\n\n\t// normalize\n\tconst max = result[0]?.score ?? 0;\n\tif (max > 0) {\n\t\tfor (const score of result) {\n\t\t\tscore.score /= max;\n\t\t}\n\t}\n\n\treturn result as TfIdfScore[];\n}\n"]}