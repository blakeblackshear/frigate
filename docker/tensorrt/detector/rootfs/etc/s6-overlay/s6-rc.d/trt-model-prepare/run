#!/command/with-contenv bash
# shellcheck shell=bash
# Generate models for the TensorRT detector

set -o errexit -o nounset -o pipefail

MODEL_CACHE_DIR=${MODEL_CACHE_DIR:-"/config/model_cache/tensorrt"}
OUTPUT_FOLDER="${MODEL_CACHE_DIR}/${TRT_VER}"

# Create output folder
mkdir -p ${OUTPUT_FOLDER}

FIRST_MODEL=true
MODEL_CONVERT=""

for model in ${YOLO_MODELS//,/ }
do
    # Remove old link in case path/version changed
    rm -f ${MODEL_CACHE_DIR}/${model}.trt

    if [[ ! -f ${OUTPUT_FOLDER}/${model}.trt ]]; then
        if [[ ${FIRST_MODEL} = true ]]; then
            MODEL_CONVERT="${model}"
            FIRST_MODEL=false;
        else
            MODEL_CONVERT+=",${model}";
        fi
    else
        ln -s ${OUTPUT_FOLDER}/${model}.trt ${MODEL_CACHE_DIR}/${model}.trt
    fi
done

if [[ -z ${MODEL_CONVERT} ]]; then
    echo "No models to convert."
    exit 0
fi

echo "Generating the following TRT Models: ${MODEL_CONVERT}"

# Build trt engine
cd /usr/local/src/tensorrt_demos/yolo

echo "Downloading yolo weights"
./download_yolo.sh $MODEL_DOWNLOAD 2> /dev/null

for model in ${MODEL_CONVERT//,/ }
do
    python3 yolo_to_onnx.py -m ${model} > /dev/null

    echo -e "\nGenerating ${model}.trt. This may take a few minutes.\n"; start=$(date +%s)
    cmd="python3 onnx_to_tensorrt.py -m ${model}"
    $cmd > /tmp/onnx_to_tensorrt.log || { cat /tmp/onnx_to_tensorrt.log && continue; }

    mv ${model%-dla}.trt ${OUTPUT_FOLDER}/${model}.trt;
    ln -s ${OUTPUT_FOLDER}/${model}.trt ${MODEL_CACHE_DIR}/${model}.trt
    echo "Generated ${model}.trt in $(($(date +%s)-start)) seconds"
done

echo "Available tensorrt models:"
cd ${OUTPUT_FOLDER} && ls *.trt;
