{"version":3,"sources":["file:///mnt/vss/_work/1/s/dependencies/vscode/out-editor-src/vs/editor/common/services/semanticTokensProviderStyling.ts","vs/editor/common/services/semanticTokensProviderStyling.ts"],"names":[],"mappings":"AAAA;;;gGAGgG;;;;;;;;;;AAGhG,OAAO,EAA6B,aAAa,EAAE,MAAM,8BAA8B,CAAC;AACxF,OAAO,EAAE,aAAa,EAAE,MAAM,gDAAgD,CAAC;AAC/E,OAAO,EAAE,WAAW,EAAE,QAAQ,EAAE,MAAM,qCAAqC,CAAC;AAC5E,OAAO,EAAE,qBAAqB,EAAE,MAAM,oCAAoC,CAAC;AAC3E,OAAO,EAAE,gBAAgB,EAAE,MAAM,0BAA0B,CAAC;AAM5D,MAAM,YAAY,GAAG,KAAK,CAAC;AAEpB,IAAM,6BAA6B,GAAnC,MAAM,6BAA6B;IAOzC,YACkB,OAA6B,EAC/B,aAA6C,EAC1C,gBAAmD,EACxD,WAAyC;QAHrC,YAAO,GAAP,OAAO,CAAsB;QACd,kBAAa,GAAb,aAAa,CAAe;QACzB,qBAAgB,GAAhB,gBAAgB,CAAkB;QACvC,gBAAW,GAAX,WAAW,CAAa;QAR/C,gCAA2B,GAAG,KAAK,CAAC;QACpC,kCAA6B,GAAG,KAAK,CAAC;QACtC,+BAA0B,GAAG,KAAK,CAAC;QAQ1C,IAAI,CAAC,UAAU,GAAG,IAAI,SAAS,EAAE,CAAC;IACnC,CAAC;IAEM,WAAW,CAAC,cAAsB,EAAE,gBAAwB,EAAE,UAAkB;QACtF,MAAM,iBAAiB,GAAG,IAAI,CAAC,gBAAgB,CAAC,eAAe,CAAC,gBAAgB,CAAC,UAAU,CAAC,CAAC;QAC7F,MAAM,KAAK,GAAG,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC,cAAc,EAAE,gBAAgB,EAAE,iBAAiB,CAAC,CAAC;QACvF,IAAI,QAAgB,CAAC;QACrB,IAAI,KAAK,EAAE,CAAC;YACX,QAAQ,GAAG,KAAK,CAAC,QAAQ,CAAC;YAC1B,IAAI,YAAY,IAAI,IAAI,CAAC,WAAW,CAAC,QAAQ,EAAE,KAAK,QAAQ,CAAC,KAAK,EAAE,CAAC;gBACpE,IAAI,CAAC,WAAW,CAAC,KAAK,CAAC,0CAA0C,cAAc,MAAM,gBAAgB,gBAAgB,aAAa,CAAC,aAAa,CAAC,QAAQ,CAAC,eAAe,aAAa,CAAC,YAAY,CAAC,QAAQ,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;YAC9N,CAAC;QACF,CAAC;aAAM,CAAC;YACP,IAAI,SAAS,GAAG,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,cAAc,CAAC,CAAC;YACxD,MAAM,cAAc,GAAa,EAAE,CAAC;YACpC,IAAI,SAAS,EAAE,CAAC;gBACf,IAAI,WAAW,GAAG,gBAAgB,CAAC;gBACnC,KAAK,IAAI,aAAa,GAAG,CAAC,EAAE,WAAW,GAAG,CAAC,IAAI,aAAa,GAAG,IAAI,CAAC,OAAO,CAAC,cAAc,CAAC,MAAM,EAAE,aAAa,EAAE,EAAE,CAAC;oBACpH,IAAI,WAAW,GAAG,CAAC,EAAE,CAAC;wBACrB,cAAc,CAAC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,cAAc,CAAC,aAAa,CAAC,CAAC,CAAC;oBACjE,CAAC;oBACD,WAAW,GAAG,WAAW,IAAI,CAAC,CAAC;gBAChC,CAAC;gBACD,IAAI,YAAY,IAAI,WAAW,GAAG,CAAC,IAAI,IAAI,CAAC,WAAW,CAAC,QAAQ,EAAE,KAAK,QAAQ,CAAC,KAAK,EAAE,CAAC;oBACvF,IAAI,CAAC,WAAW,CAAC,KAAK,CAAC,gEAAgE,gBAAgB,CAAC,QAAQ,CAAC,CAAC,CAAC,gBAAgB,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,OAAO,CAAC,cAAc,CAAC,EAAE,CAAC,CAAC;oBAClL,cAAc,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;gBACtC,CAAC;gBAED,MAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,aAAa,EAAE,CAAC,qBAAqB,CAAC,SAAS,EAAE,cAAc,EAAE,UAAU,CAAC,CAAC;gBACnH,IAAI,OAAO,UAAU,KAAK,WAAW,EAAE,CAAC;oBACvC,QAAQ,qEAAoD,CAAC;gBAC9D,CAAC;qBAAM,CAAC;oBACP,QAAQ,GAAG,CAAC,CAAC;oBACb,IAAI,OAAO,UAAU,CAAC,MAAM,KAAK,WAAW,EAAE,CAAC;wBAC9C,MAAM,SAAS,GAAG,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC,0BAAkB,CAAC,CAAC,CAAC,CAAC,6CAAoC,CAAC;wBACjG,QAAQ,IAAI,SAAS,6CAAqC,CAAC;oBAC5D,CAAC;oBACD,IAAI,OAAO,UAAU,CAAC,IAAI,KAAK,WAAW,EAAE,CAAC;wBAC5C,MAAM,OAAO,GAAG,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC,wBAAgB,CAAC,CAAC,CAAC,CAAC,6CAAoC,CAAC;wBAC3F,QAAQ,IAAI,OAAO,2CAAmC,CAAC;oBACxD,CAAC;oBACD,IAAI,OAAO,UAAU,CAAC,SAAS,KAAK,WAAW,EAAE,CAAC;wBACjD,MAAM,YAAY,GAAG,CAAC,UAAU,CAAC,SAAS,CAAC,CAAC,6BAAqB,CAAC,CAAC,CAAC,CAAC,6CAAoC,CAAC;wBAC1G,QAAQ,IAAI,YAAY,gDAAwC,CAAC;oBAClE,CAAC;oBACD,IAAI,OAAO,UAAU,CAAC,aAAa,KAAK,WAAW,EAAE,CAAC;wBACrD,MAAM,gBAAgB,GAAG,CAAC,UAAU,CAAC,aAAa,CAAC,CAAC,iCAAyB,CAAC,CAAC,CAAC,CAAC,6CAAoC,CAAC;wBACtH,QAAQ,IAAI,gBAAgB,oDAA4C,CAAC;oBAC1E,CAAC;oBACD,IAAI,UAAU,CAAC,UAAU,EAAE,CAAC;wBAC3B,MAAM,cAAc,GAAG,CAAC,UAAU,CAAC,UAAU,CAAC,6CAAoC,CAAC;wBACnF,QAAQ,IAAI,cAAc,kDAAyC,CAAC;oBACrE,CAAC;oBACD,IAAI,QAAQ,KAAK,CAAC,EAAE,CAAC;wBACpB,WAAW;wBACX,QAAQ,qEAAoD,CAAC;oBAC9D,CAAC;gBACF,CAAC;YACF,CAAC;iBAAM,CAAC;gBACP,IAAI,YAAY,IAAI,IAAI,CAAC,WAAW,CAAC,QAAQ,EAAE,KAAK,QAAQ,CAAC,KAAK,EAAE,CAAC;oBACpE,IAAI,CAAC,WAAW,CAAC,KAAK,CAAC,4DAA4D,cAAc,gBAAgB,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,EAAE,CAAC,CAAC;gBAC7J,CAAC;gBACD,QAAQ,qEAAoD,CAAC;gBAC7D,SAAS,GAAG,eAAe,CAAC;YAC7B,CAAC;YACD,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC,cAAc,EAAE,gBAAgB,EAAE,iBAAiB,EAAE,QAAQ,CAAC,CAAC;YAEnF,IAAI,YAAY,IAAI,IAAI,CAAC,WAAW,CAAC,QAAQ,EAAE,KAAK,QAAQ,CAAC,KAAK,EAAE,CAAC;gBACpE,IAAI,CAAC,WAAW,CAAC,KAAK,CAAC,iCAAiC,cAAc,KAAK,SAAS,OAAO,gBAAgB,KAAK,cAAc,CAAC,IAAI,CAAC,GAAG,CAAC,iBAAiB,aAAa,CAAC,aAAa,CAAC,QAAQ,CAAC,eAAe,aAAa,CAAC,YAAY,CAAC,QAAQ,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;YAClQ,CAAC;QACF,CAAC;QAED,OAAO,QAAQ,CAAC;IACjB,CAAC;IAEM,6BAA6B,CAAC,UAAkB,EAAE,WAAmB;QAC3E,IAAI,CAAC,IAAI,CAAC,2BAA2B,EAAE,CAAC;YACvC,IAAI,CAAC,2BAA2B,GAAG,IAAI,CAAC;YACxC,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,sDAAsD,UAAU,YAAY,WAAW,EAAE,CAAC,CAAC;QAClH,CAAC;IACF,CAAC;IAEM,+BAA+B,CAAC,UAAkB,EAAE,WAAmB;QAC7E,IAAI,CAAC,IAAI,CAAC,6BAA6B,EAAE,CAAC;YACzC,IAAI,CAAC,6BAA6B,GAAG,IAAI,CAAC;YAC1C,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,6DAA6D,UAAU,YAAY,WAAW,EAAE,CAAC,CAAC;QACzH,CAAC;IACF,CAAC;IAEM,oBAAoB,CAAC,gBAAoC,EAAE,QAA4B,EAAE,SAAiB,EAAE,SAAiB,EAAE,gBAAwB;QAC7J,IAAI,CAAC,IAAI,CAAC,0BAA0B,EAAE,CAAC;YACtC,IAAI,CAAC,0BAA0B,GAAG,IAAI,CAAC;YACvC,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,4DAA4D,gBAAgB,eAAe,QAAQ,cAAc,SAAS,+BAA+B,SAAS,yCAAyC,gBAAgB,IAAI,CAAC,CAAC;QACxP,CAAC;IACF,CAAC;CAED,CAAA;AA7GY,6BAA6B;IASvC,WAAA,aAAa,CAAA;IACb,WAAA,gBAAgB,CAAA;IAChB,WAAA,WAAW,CAAA;GAXD,6BAA6B,CA6GzC;;AAgBD,MAAM,UAAU,kBAAkB,CAAC,MAAsB,EAAE,OAAsC,EAAE,UAAkB;IACpH,MAAM,OAAO,GAAG,MAAM,CAAC,IAAI,CAAC;IAC5B,MAAM,UAAU,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;IAChD,MAAM,aAAa,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,UAAU,uDAA4C,CAAC,2DAAiD,CAAC;IAClJ,MAAM,MAAM,GAA4B,EAAE,CAAC;IAE3C,IAAI,UAAU,GAAG,CAAC,CAAC;IACnB,IAAI,cAAc,GAAG,CAAC,CAAC;IACvB,IAAI,kBAAkB,GAAG,CAAC,CAAC;IAC3B,OAAO,UAAU,GAAG,UAAU,EAAE,CAAC;QAChC,MAAM,eAAe,GAAG,UAAU,CAAC;QACnC,IAAI,aAAa,GAAG,IAAI,CAAC,GAAG,CAAC,eAAe,GAAG,aAAa,EAAE,UAAU,CAAC,CAAC;QAE1E,mDAAmD;QACnD,IAAI,aAAa,GAAG,UAAU,EAAE,CAAC;YAEhC,IAAI,kBAAkB,GAAG,aAAa,CAAC;YACvC,OAAO,kBAAkB,GAAG,CAAC,GAAG,eAAe,IAAI,OAAO,CAAC,CAAC,GAAG,kBAAkB,CAAC,KAAK,CAAC,EAAE,CAAC;gBAC1F,kBAAkB,EAAE,CAAC;YACtB,CAAC;YAED,IAAI,kBAAkB,GAAG,CAAC,KAAK,eAAe,EAAE,CAAC;gBAChD,2FAA2F;gBAC3F,IAAI,gBAAgB,GAAG,aAAa,CAAC;gBACrC,OAAO,gBAAgB,GAAG,CAAC,GAAG,UAAU,IAAI,OAAO,CAAC,CAAC,GAAG,gBAAgB,CAAC,KAAK,CAAC,EAAE,CAAC;oBACjF,gBAAgB,EAAE,CAAC;gBACpB,CAAC;gBACD,aAAa,GAAG,gBAAgB,CAAC;YAClC,CAAC;iBAAM,CAAC;gBACP,aAAa,GAAG,kBAAkB,CAAC;YACpC,CAAC;QACF,CAAC;QAED,IAAI,QAAQ,GAAG,IAAI,WAAW,CAAC,CAAC,aAAa,GAAG,eAAe,CAAC,GAAG,CAAC,CAAC,CAAC;QACtE,IAAI,UAAU,GAAG,CAAC,CAAC;QACnB,IAAI,QAAQ,GAAG,CAAC,CAAC;QACjB,IAAI,cAAc,GAAG,CAAC,CAAC;QACvB,IAAI,gBAAgB,GAAG,CAAC,CAAC;QACzB,OAAO,UAAU,GAAG,aAAa,EAAE,CAAC;YACnC,MAAM,SAAS,GAAG,CAAC,GAAG,UAAU,CAAC;YACjC,MAAM,SAAS,GAAG,OAAO,CAAC,SAAS,CAAC,CAAC;YACrC,MAAM,cAAc,GAAG,OAAO,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;YAC9C,2FAA2F;YAC3F,2FAA2F;YAC3F,MAAM,UAAU,GAAG,CAAC,cAAc,GAAG,SAAS,CAAC,GAAG,CAAC,CAAC;YACpD,MAAM,cAAc,GAAG,CAAC,SAAS,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,kBAAkB,GAAG,cAAc,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,cAAc,CAAC,CAAC;YACtG,MAAM,MAAM,GAAG,OAAO,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;YACtC,MAAM,YAAY,GAAG,CAAC,cAAc,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC;YACnD,MAAM,cAAc,GAAG,OAAO,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;YAC9C,MAAM,gBAAgB,GAAG,OAAO,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;YAEhD,IAAI,YAAY,IAAI,cAAc,EAAE,CAAC;gBACpC,yEAAyE;gBACzE,OAAO,CAAC,+BAA+B,CAAC,UAAU,EAAE,cAAc,GAAG,CAAC,CAAC,CAAC;YACzE,CAAC;iBAAM,IAAI,cAAc,KAAK,UAAU,IAAI,gBAAgB,GAAG,cAAc,EAAE,CAAC;gBAC/E,8CAA8C;gBAC9C,OAAO,CAAC,6BAA6B,CAAC,UAAU,EAAE,cAAc,GAAG,CAAC,CAAC,CAAC;YACvE,CAAC;iBAAM,CAAC;gBACP,MAAM,QAAQ,GAAG,OAAO,CAAC,WAAW,CAAC,cAAc,EAAE,gBAAgB,EAAE,UAAU,CAAC,CAAC;gBAEnF,IAAI,QAAQ,uEAAsD,EAAE,CAAC;oBACpE,IAAI,QAAQ,KAAK,CAAC,EAAE,CAAC;wBACpB,QAAQ,GAAG,UAAU,CAAC;oBACvB,CAAC;oBACD,QAAQ,CAAC,UAAU,CAAC,GAAG,UAAU,GAAG,QAAQ,CAAC;oBAC7C,QAAQ,CAAC,UAAU,GAAG,CAAC,CAAC,GAAG,cAAc,CAAC;oBAC1C,QAAQ,CAAC,UAAU,GAAG,CAAC,CAAC,GAAG,YAAY,CAAC;oBACxC,QAAQ,CAAC,UAAU,GAAG,CAAC,CAAC,GAAG,QAAQ,CAAC;oBACpC,UAAU,IAAI,CAAC,CAAC;oBAEhB,cAAc,GAAG,UAAU,CAAC;oBAC5B,gBAAgB,GAAG,YAAY,CAAC;gBACjC,CAAC;YACF,CAAC;YAED,cAAc,GAAG,UAAU,CAAC;YAC5B,kBAAkB,GAAG,cAAc,CAAC;YACpC,UAAU,EAAE,CAAC;QACd,CAAC;QAED,IAAI,UAAU,KAAK,QAAQ,CAAC,MAAM,EAAE,CAAC;YACpC,QAAQ,GAAG,QAAQ,CAAC,QAAQ,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC;QAC7C,CAAC;QAED,MAAM,MAAM,GAAG,qBAAqB,CAAC,MAAM,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC;QAChE,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;IACrB,CAAC;IAED,OAAO,MAAM,CAAC;AACf,CAAC;AAED,MAAM,cAAc;IAOnB,YAAY,cAAsB,EAAE,gBAAwB,EAAE,UAAkB,EAAE,QAAgB;QACjG,IAAI,CAAC,cAAc,GAAG,cAAc,CAAC;QACrC,IAAI,CAAC,gBAAgB,GAAG,gBAAgB,CAAC;QACzC,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;QAC7B,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;QACzB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;IAClB,CAAC;CACD;AAED,MAAM,SAAS;aAEC,WAAM,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,MAAM,EAAE,MAAM,EAAE,MAAM,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC;IAQjJ;QACC,IAAI,CAAC,cAAc,GAAG,CAAC,CAAC;QACxB,IAAI,CAAC,mBAAmB,GAAG,CAAC,CAAC;QAC7B,IAAI,CAAC,cAAc,GAAG,SAAS,CAAC,MAAM,CAAC,IAAI,CAAC,mBAAmB,CAAC,CAAC;QACjE,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,mBAAmB,GAAG,CAAC,GAAG,SAAS,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACvH,IAAI,CAAC,SAAS,GAAG,EAAE,CAAC;QACpB,SAAS,CAAC,eAAe,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,cAAc,CAAC,CAAC;IAChE,CAAC;IAEO,MAAM,CAAC,eAAe,CAAC,OAAkC,EAAE,MAAc;QAChF,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YACjC,OAAO,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC;QACnB,CAAC;IACF,CAAC;IAEO,MAAM,CAAC,EAAU,EAAE,EAAU;QACpC,OAAO,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAE,8BAA8B;IACpE,CAAC;IAEO,SAAS,CAAC,cAAsB,EAAE,gBAAwB,EAAE,UAAkB;QACrF,OAAO,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,cAAc,EAAE,gBAAgB,CAAC,EAAE,UAAU,CAAC,GAAG,IAAI,CAAC,cAAc,CAAC;IACrG,CAAC;IAEM,GAAG,CAAC,cAAsB,EAAE,gBAAwB,EAAE,UAAkB;QAC9E,MAAM,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,cAAc,EAAE,gBAAgB,EAAE,UAAU,CAAC,CAAC;QAE1E,IAAI,CAAC,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAC7B,OAAO,CAAC,EAAE,CAAC;YACV,IAAI,CAAC,CAAC,cAAc,KAAK,cAAc,IAAI,CAAC,CAAC,gBAAgB,KAAK,gBAAgB,IAAI,CAAC,CAAC,UAAU,KAAK,UAAU,EAAE,CAAC;gBACnH,OAAO,CAAC,CAAC;YACV,CAAC;YACD,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC;QACZ,CAAC;QAED,OAAO,IAAI,CAAC;IACb,CAAC;IAEM,GAAG,CAAC,cAAsB,EAAE,gBAAwB,EAAE,UAAkB,EAAE,QAAgB;QAChG,IAAI,CAAC,cAAc,EAAE,CAAC;QACtB,IAAI,IAAI,CAAC,UAAU,KAAK,CAAC,IAAI,IAAI,CAAC,cAAc,IAAI,IAAI,CAAC,UAAU,EAAE,CAAC;YACrE,UAAU;YACV,MAAM,WAAW,GAAG,IAAI,CAAC,SAAS,CAAC;YAEnC,IAAI,CAAC,mBAAmB,EAAE,CAAC;YAC3B,IAAI,CAAC,cAAc,GAAG,SAAS,CAAC,MAAM,CAAC,IAAI,CAAC,mBAAmB,CAAC,CAAC;YACjE,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,mBAAmB,GAAG,CAAC,GAAG,SAAS,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YACvH,IAAI,CAAC,SAAS,GAAG,EAAE,CAAC;YACpB,SAAS,CAAC,eAAe,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,cAAc,CAAC,CAAC;YAE/D,KAAK,MAAM,KAAK,IAAI,WAAW,EAAE,CAAC;gBACjC,IAAI,CAAC,GAAG,KAAK,CAAC;gBACd,OAAO,CAAC,EAAE,CAAC;oBACV,MAAM,OAAO,GAAG,CAAC,CAAC,IAAI,CAAC;oBACvB,CAAC,CAAC,IAAI,GAAG,IAAI,CAAC;oBACd,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;oBACb,CAAC,GAAG,OAAO,CAAC;gBACb,CAAC;YACF,CAAC;QACF,CAAC;QACD,IAAI,CAAC,IAAI,CAAC,IAAI,cAAc,CAAC,cAAc,EAAE,gBAAgB,EAAE,UAAU,EAAE,QAAQ,CAAC,CAAC,CAAC;IACvF,CAAC;IAEO,IAAI,CAAC,OAAuB;QACnC,MAAM,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,cAAc,EAAE,OAAO,CAAC,gBAAgB,EAAE,OAAO,CAAC,UAAU,CAAC,CAAC;QAClG,OAAO,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QACpC,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,GAAG,OAAO,CAAC;IAChC,CAAC","file":"semanticTokensProviderStyling.js","sourceRoot":"file:///mnt/vss/_work/1/s/dependencies/vscode/out-editor-src","sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport { SemanticTokensLegend, SemanticTokens } from '../languages.js';\nimport { FontStyle, MetadataConsts, TokenMetadata } from '../encodedTokenAttributes.js';\nimport { IThemeService } from '../../../platform/theme/common/themeService.js';\nimport { ILogService, LogLevel } from '../../../platform/log/common/log.js';\nimport { SparseMultilineTokens } from '../tokens/sparseMultilineTokens.js';\nimport { ILanguageService } from '../languages/language.js';\n\nconst enum SemanticTokensProviderStylingConstants {\n\tNO_STYLING = 0b01111111111111111111111111111111\n}\n\nconst ENABLE_TRACE = false;\n\nexport class SemanticTokensProviderStyling {\n\n\tprivate readonly _hashTable: HashTable;\n\tprivate _hasWarnedOverlappingTokens = false;\n\tprivate _hasWarnedInvalidLengthTokens = false;\n\tprivate _hasWarnedInvalidEditStart = false;\n\n\tconstructor(\n\t\tprivate readonly _legend: SemanticTokensLegend,\n\t\t@IThemeService private readonly _themeService: IThemeService,\n\t\t@ILanguageService private readonly _languageService: ILanguageService,\n\t\t@ILogService private readonly _logService: ILogService\n\t) {\n\t\tthis._hashTable = new HashTable();\n\t}\n\n\tpublic getMetadata(tokenTypeIndex: number, tokenModifierSet: number, languageId: string): number {\n\t\tconst encodedLanguageId = this._languageService.languageIdCodec.encodeLanguageId(languageId);\n\t\tconst entry = this._hashTable.get(tokenTypeIndex, tokenModifierSet, encodedLanguageId);\n\t\tlet metadata: number;\n\t\tif (entry) {\n\t\t\tmetadata = entry.metadata;\n\t\t\tif (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling [CACHED] ${tokenTypeIndex} / ${tokenModifierSet}: foreground ${TokenMetadata.getForeground(metadata)}, fontStyle ${TokenMetadata.getFontStyle(metadata).toString(2)}`);\n\t\t\t}\n\t\t} else {\n\t\t\tlet tokenType = this._legend.tokenTypes[tokenTypeIndex];\n\t\t\tconst tokenModifiers: string[] = [];\n\t\t\tif (tokenType) {\n\t\t\t\tlet modifierSet = tokenModifierSet;\n\t\t\t\tfor (let modifierIndex = 0; modifierSet > 0 && modifierIndex < this._legend.tokenModifiers.length; modifierIndex++) {\n\t\t\t\t\tif (modifierSet & 1) {\n\t\t\t\t\t\ttokenModifiers.push(this._legend.tokenModifiers[modifierIndex]);\n\t\t\t\t\t}\n\t\t\t\t\tmodifierSet = modifierSet >> 1;\n\t\t\t\t}\n\t\t\t\tif (ENABLE_TRACE && modifierSet > 0 && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling: unknown token modifier index: ${tokenModifierSet.toString(2)} for legend: ${JSON.stringify(this._legend.tokenModifiers)}`);\n\t\t\t\t\ttokenModifiers.push('not-in-legend');\n\t\t\t\t}\n\n\t\t\t\tconst tokenStyle = this._themeService.getColorTheme().getTokenStyleMetadata(tokenType, tokenModifiers, languageId);\n\t\t\t\tif (typeof tokenStyle === 'undefined') {\n\t\t\t\t\tmetadata = SemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\t} else {\n\t\t\t\t\tmetadata = 0;\n\t\t\t\t\tif (typeof tokenStyle.italic !== 'undefined') {\n\t\t\t\t\t\tconst italicBit = (tokenStyle.italic ? FontStyle.Italic : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= italicBit | MetadataConsts.SEMANTIC_USE_ITALIC;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.bold !== 'undefined') {\n\t\t\t\t\t\tconst boldBit = (tokenStyle.bold ? FontStyle.Bold : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= boldBit | MetadataConsts.SEMANTIC_USE_BOLD;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.underline !== 'undefined') {\n\t\t\t\t\t\tconst underlineBit = (tokenStyle.underline ? FontStyle.Underline : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= underlineBit | MetadataConsts.SEMANTIC_USE_UNDERLINE;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.strikethrough !== 'undefined') {\n\t\t\t\t\t\tconst strikethroughBit = (tokenStyle.strikethrough ? FontStyle.Strikethrough : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= strikethroughBit | MetadataConsts.SEMANTIC_USE_STRIKETHROUGH;\n\t\t\t\t\t}\n\t\t\t\t\tif (tokenStyle.foreground) {\n\t\t\t\t\t\tconst foregroundBits = (tokenStyle.foreground) << MetadataConsts.FOREGROUND_OFFSET;\n\t\t\t\t\t\tmetadata |= foregroundBits | MetadataConsts.SEMANTIC_USE_FOREGROUND;\n\t\t\t\t\t}\n\t\t\t\t\tif (metadata === 0) {\n\t\t\t\t\t\t// Nothing!\n\t\t\t\t\t\tmetadata = SemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling: unknown token type index: ${tokenTypeIndex} for legend: ${JSON.stringify(this._legend.tokenTypes)}`);\n\t\t\t\t}\n\t\t\t\tmetadata = SemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\ttokenType = 'not-in-legend';\n\t\t\t}\n\t\t\tthis._hashTable.add(tokenTypeIndex, tokenModifierSet, encodedLanguageId, metadata);\n\n\t\t\tif (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling ${tokenTypeIndex} (${tokenType}) / ${tokenModifierSet} (${tokenModifiers.join(' ')}): foreground ${TokenMetadata.getForeground(metadata)}, fontStyle ${TokenMetadata.getFontStyle(metadata).toString(2)}`);\n\t\t\t}\n\t\t}\n\n\t\treturn metadata;\n\t}\n\n\tpublic warnOverlappingSemanticTokens(lineNumber: number, startColumn: number): void {\n\t\tif (!this._hasWarnedOverlappingTokens) {\n\t\t\tthis._hasWarnedOverlappingTokens = true;\n\t\t\tthis._logService.warn(`Overlapping semantic tokens detected at lineNumber ${lineNumber}, column ${startColumn}`);\n\t\t}\n\t}\n\n\tpublic warnInvalidLengthSemanticTokens(lineNumber: number, startColumn: number): void {\n\t\tif (!this._hasWarnedInvalidLengthTokens) {\n\t\t\tthis._hasWarnedInvalidLengthTokens = true;\n\t\t\tthis._logService.warn(`Semantic token with invalid length detected at lineNumber ${lineNumber}, column ${startColumn}`);\n\t\t}\n\t}\n\n\tpublic warnInvalidEditStart(previousResultId: string | undefined, resultId: string | undefined, editIndex: number, editStart: number, maxExpectedStart: number): void {\n\t\tif (!this._hasWarnedInvalidEditStart) {\n\t\t\tthis._hasWarnedInvalidEditStart = true;\n\t\t\tthis._logService.warn(`Invalid semantic tokens edit detected (previousResultId: ${previousResultId}, resultId: ${resultId}) at edit #${editIndex}: The provided start offset ${editStart} is outside the previous data (length ${maxExpectedStart}).`);\n\t\t}\n\t}\n\n}\n\nconst enum SemanticColoringConstants {\n\t/**\n\t * Let's aim at having 8KB buffers if possible...\n\t * So that would be 8192 / (5 * 4) = 409.6 tokens per area\n\t */\n\tDesiredTokensPerArea = 400,\n\n\t/**\n\t * Try to keep the total number of areas under 1024 if possible,\n\t * simply compensate by having more tokens per area...\n\t */\n\tDesiredMaxAreas = 1024,\n}\n\nexport function toMultilineTokens2(tokens: SemanticTokens, styling: SemanticTokensProviderStyling, languageId: string): SparseMultilineTokens[] {\n\tconst srcData = tokens.data;\n\tconst tokenCount = (tokens.data.length / 5) | 0;\n\tconst tokensPerArea = Math.max(Math.ceil(tokenCount / SemanticColoringConstants.DesiredMaxAreas), SemanticColoringConstants.DesiredTokensPerArea);\n\tconst result: SparseMultilineTokens[] = [];\n\n\tlet tokenIndex = 0;\n\tlet lastLineNumber = 1;\n\tlet lastStartCharacter = 0;\n\twhile (tokenIndex < tokenCount) {\n\t\tconst tokenStartIndex = tokenIndex;\n\t\tlet tokenEndIndex = Math.min(tokenStartIndex + tokensPerArea, tokenCount);\n\n\t\t// Keep tokens on the same line in the same area...\n\t\tif (tokenEndIndex < tokenCount) {\n\n\t\t\tlet smallTokenEndIndex = tokenEndIndex;\n\t\t\twhile (smallTokenEndIndex - 1 > tokenStartIndex && srcData[5 * smallTokenEndIndex] === 0) {\n\t\t\t\tsmallTokenEndIndex--;\n\t\t\t}\n\n\t\t\tif (smallTokenEndIndex - 1 === tokenStartIndex) {\n\t\t\t\t// there are so many tokens on this line that our area would be empty, we must now go right\n\t\t\t\tlet bigTokenEndIndex = tokenEndIndex;\n\t\t\t\twhile (bigTokenEndIndex + 1 < tokenCount && srcData[5 * bigTokenEndIndex] === 0) {\n\t\t\t\t\tbigTokenEndIndex++;\n\t\t\t\t}\n\t\t\t\ttokenEndIndex = bigTokenEndIndex;\n\t\t\t} else {\n\t\t\t\ttokenEndIndex = smallTokenEndIndex;\n\t\t\t}\n\t\t}\n\n\t\tlet destData = new Uint32Array((tokenEndIndex - tokenStartIndex) * 4);\n\t\tlet destOffset = 0;\n\t\tlet areaLine = 0;\n\t\tlet prevLineNumber = 0;\n\t\tlet prevEndCharacter = 0;\n\t\twhile (tokenIndex < tokenEndIndex) {\n\t\t\tconst srcOffset = 5 * tokenIndex;\n\t\t\tconst deltaLine = srcData[srcOffset];\n\t\t\tconst deltaCharacter = srcData[srcOffset + 1];\n\t\t\t// Casting both `lineNumber`, `startCharacter` and `endCharacter` here to uint32 using `|0`\n\t\t\t// to validate below with the actual values that will be inserted in the Uint32Array result\n\t\t\tconst lineNumber = (lastLineNumber + deltaLine) | 0;\n\t\t\tconst startCharacter = (deltaLine === 0 ? (lastStartCharacter + deltaCharacter) | 0 : deltaCharacter);\n\t\t\tconst length = srcData[srcOffset + 2];\n\t\t\tconst endCharacter = (startCharacter + length) | 0;\n\t\t\tconst tokenTypeIndex = srcData[srcOffset + 3];\n\t\t\tconst tokenModifierSet = srcData[srcOffset + 4];\n\n\t\t\tif (endCharacter <= startCharacter) {\n\t\t\t\t// this token is invalid (most likely a negative length casted to uint32)\n\t\t\t\tstyling.warnInvalidLengthSemanticTokens(lineNumber, startCharacter + 1);\n\t\t\t} else if (prevLineNumber === lineNumber && prevEndCharacter > startCharacter) {\n\t\t\t\t// this token overlaps with the previous token\n\t\t\t\tstyling.warnOverlappingSemanticTokens(lineNumber, startCharacter + 1);\n\t\t\t} else {\n\t\t\t\tconst metadata = styling.getMetadata(tokenTypeIndex, tokenModifierSet, languageId);\n\n\t\t\t\tif (metadata !== SemanticTokensProviderStylingConstants.NO_STYLING) {\n\t\t\t\t\tif (areaLine === 0) {\n\t\t\t\t\t\tareaLine = lineNumber;\n\t\t\t\t\t}\n\t\t\t\t\tdestData[destOffset] = lineNumber - areaLine;\n\t\t\t\t\tdestData[destOffset + 1] = startCharacter;\n\t\t\t\t\tdestData[destOffset + 2] = endCharacter;\n\t\t\t\t\tdestData[destOffset + 3] = metadata;\n\t\t\t\t\tdestOffset += 4;\n\n\t\t\t\t\tprevLineNumber = lineNumber;\n\t\t\t\t\tprevEndCharacter = endCharacter;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tlastLineNumber = lineNumber;\n\t\t\tlastStartCharacter = startCharacter;\n\t\t\ttokenIndex++;\n\t\t}\n\n\t\tif (destOffset !== destData.length) {\n\t\t\tdestData = destData.subarray(0, destOffset);\n\t\t}\n\n\t\tconst tokens = SparseMultilineTokens.create(areaLine, destData);\n\t\tresult.push(tokens);\n\t}\n\n\treturn result;\n}\n\nclass HashTableEntry {\n\tpublic readonly tokenTypeIndex: number;\n\tpublic readonly tokenModifierSet: number;\n\tpublic readonly languageId: number;\n\tpublic readonly metadata: number;\n\tpublic next: HashTableEntry | null;\n\n\tconstructor(tokenTypeIndex: number, tokenModifierSet: number, languageId: number, metadata: number) {\n\t\tthis.tokenTypeIndex = tokenTypeIndex;\n\t\tthis.tokenModifierSet = tokenModifierSet;\n\t\tthis.languageId = languageId;\n\t\tthis.metadata = metadata;\n\t\tthis.next = null;\n\t}\n}\n\nclass HashTable {\n\n\tprivate static _SIZES = [3, 7, 13, 31, 61, 127, 251, 509, 1021, 2039, 4093, 8191, 16381, 32749, 65521, 131071, 262139, 524287, 1048573, 2097143];\n\n\tprivate _elementsCount: number;\n\tprivate _currentLengthIndex: number;\n\tprivate _currentLength: number;\n\tprivate _growCount: number;\n\tprivate _elements: (HashTableEntry | null)[];\n\n\tconstructor() {\n\t\tthis._elementsCount = 0;\n\t\tthis._currentLengthIndex = 0;\n\t\tthis._currentLength = HashTable._SIZES[this._currentLengthIndex];\n\t\tthis._growCount = Math.round(this._currentLengthIndex + 1 < HashTable._SIZES.length ? 2 / 3 * this._currentLength : 0);\n\t\tthis._elements = [];\n\t\tHashTable._nullOutEntries(this._elements, this._currentLength);\n\t}\n\n\tprivate static _nullOutEntries(entries: (HashTableEntry | null)[], length: number): void {\n\t\tfor (let i = 0; i < length; i++) {\n\t\t\tentries[i] = null;\n\t\t}\n\t}\n\n\tprivate _hash2(n1: number, n2: number): number {\n\t\treturn (((n1 << 5) - n1) + n2) | 0;  // n1 * 31 + n2, keep as int32\n\t}\n\n\tprivate _hashFunc(tokenTypeIndex: number, tokenModifierSet: number, languageId: number): number {\n\t\treturn this._hash2(this._hash2(tokenTypeIndex, tokenModifierSet), languageId) % this._currentLength;\n\t}\n\n\tpublic get(tokenTypeIndex: number, tokenModifierSet: number, languageId: number): HashTableEntry | null {\n\t\tconst hash = this._hashFunc(tokenTypeIndex, tokenModifierSet, languageId);\n\n\t\tlet p = this._elements[hash];\n\t\twhile (p) {\n\t\t\tif (p.tokenTypeIndex === tokenTypeIndex && p.tokenModifierSet === tokenModifierSet && p.languageId === languageId) {\n\t\t\t\treturn p;\n\t\t\t}\n\t\t\tp = p.next;\n\t\t}\n\n\t\treturn null;\n\t}\n\n\tpublic add(tokenTypeIndex: number, tokenModifierSet: number, languageId: number, metadata: number): void {\n\t\tthis._elementsCount++;\n\t\tif (this._growCount !== 0 && this._elementsCount >= this._growCount) {\n\t\t\t// expand!\n\t\t\tconst oldElements = this._elements;\n\n\t\t\tthis._currentLengthIndex++;\n\t\t\tthis._currentLength = HashTable._SIZES[this._currentLengthIndex];\n\t\t\tthis._growCount = Math.round(this._currentLengthIndex + 1 < HashTable._SIZES.length ? 2 / 3 * this._currentLength : 0);\n\t\t\tthis._elements = [];\n\t\t\tHashTable._nullOutEntries(this._elements, this._currentLength);\n\n\t\t\tfor (const first of oldElements) {\n\t\t\t\tlet p = first;\n\t\t\t\twhile (p) {\n\t\t\t\t\tconst oldNext = p.next;\n\t\t\t\t\tp.next = null;\n\t\t\t\t\tthis._add(p);\n\t\t\t\t\tp = oldNext;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tthis._add(new HashTableEntry(tokenTypeIndex, tokenModifierSet, languageId, metadata));\n\t}\n\n\tprivate _add(element: HashTableEntry): void {\n\t\tconst hash = this._hashFunc(element.tokenTypeIndex, element.tokenModifierSet, element.languageId);\n\t\telement.next = this._elements[hash];\n\t\tthis._elements[hash] = element;\n\t}\n}\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport { SemanticTokensLegend, SemanticTokens } from '../languages.js';\nimport { FontStyle, MetadataConsts, TokenMetadata } from '../encodedTokenAttributes.js';\nimport { IThemeService } from '../../../platform/theme/common/themeService.js';\nimport { ILogService, LogLevel } from '../../../platform/log/common/log.js';\nimport { SparseMultilineTokens } from '../tokens/sparseMultilineTokens.js';\nimport { ILanguageService } from '../languages/language.js';\n\nconst enum SemanticTokensProviderStylingConstants {\n\tNO_STYLING = 0b01111111111111111111111111111111\n}\n\nconst ENABLE_TRACE = false;\n\nexport class SemanticTokensProviderStyling {\n\n\tprivate readonly _hashTable: HashTable;\n\tprivate _hasWarnedOverlappingTokens = false;\n\tprivate _hasWarnedInvalidLengthTokens = false;\n\tprivate _hasWarnedInvalidEditStart = false;\n\n\tconstructor(\n\t\tprivate readonly _legend: SemanticTokensLegend,\n\t\t@IThemeService private readonly _themeService: IThemeService,\n\t\t@ILanguageService private readonly _languageService: ILanguageService,\n\t\t@ILogService private readonly _logService: ILogService\n\t) {\n\t\tthis._hashTable = new HashTable();\n\t}\n\n\tpublic getMetadata(tokenTypeIndex: number, tokenModifierSet: number, languageId: string): number {\n\t\tconst encodedLanguageId = this._languageService.languageIdCodec.encodeLanguageId(languageId);\n\t\tconst entry = this._hashTable.get(tokenTypeIndex, tokenModifierSet, encodedLanguageId);\n\t\tlet metadata: number;\n\t\tif (entry) {\n\t\t\tmetadata = entry.metadata;\n\t\t\tif (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling [CACHED] ${tokenTypeIndex} / ${tokenModifierSet}: foreground ${TokenMetadata.getForeground(metadata)}, fontStyle ${TokenMetadata.getFontStyle(metadata).toString(2)}`);\n\t\t\t}\n\t\t} else {\n\t\t\tlet tokenType = this._legend.tokenTypes[tokenTypeIndex];\n\t\t\tconst tokenModifiers: string[] = [];\n\t\t\tif (tokenType) {\n\t\t\t\tlet modifierSet = tokenModifierSet;\n\t\t\t\tfor (let modifierIndex = 0; modifierSet > 0 && modifierIndex < this._legend.tokenModifiers.length; modifierIndex++) {\n\t\t\t\t\tif (modifierSet & 1) {\n\t\t\t\t\t\ttokenModifiers.push(this._legend.tokenModifiers[modifierIndex]);\n\t\t\t\t\t}\n\t\t\t\t\tmodifierSet = modifierSet >> 1;\n\t\t\t\t}\n\t\t\t\tif (ENABLE_TRACE && modifierSet > 0 && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling: unknown token modifier index: ${tokenModifierSet.toString(2)} for legend: ${JSON.stringify(this._legend.tokenModifiers)}`);\n\t\t\t\t\ttokenModifiers.push('not-in-legend');\n\t\t\t\t}\n\n\t\t\t\tconst tokenStyle = this._themeService.getColorTheme().getTokenStyleMetadata(tokenType, tokenModifiers, languageId);\n\t\t\t\tif (typeof tokenStyle === 'undefined') {\n\t\t\t\t\tmetadata = SemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\t} else {\n\t\t\t\t\tmetadata = 0;\n\t\t\t\t\tif (typeof tokenStyle.italic !== 'undefined') {\n\t\t\t\t\t\tconst italicBit = (tokenStyle.italic ? FontStyle.Italic : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= italicBit | MetadataConsts.SEMANTIC_USE_ITALIC;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.bold !== 'undefined') {\n\t\t\t\t\t\tconst boldBit = (tokenStyle.bold ? FontStyle.Bold : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= boldBit | MetadataConsts.SEMANTIC_USE_BOLD;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.underline !== 'undefined') {\n\t\t\t\t\t\tconst underlineBit = (tokenStyle.underline ? FontStyle.Underline : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= underlineBit | MetadataConsts.SEMANTIC_USE_UNDERLINE;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.strikethrough !== 'undefined') {\n\t\t\t\t\t\tconst strikethroughBit = (tokenStyle.strikethrough ? FontStyle.Strikethrough : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= strikethroughBit | MetadataConsts.SEMANTIC_USE_STRIKETHROUGH;\n\t\t\t\t\t}\n\t\t\t\t\tif (tokenStyle.foreground) {\n\t\t\t\t\t\tconst foregroundBits = (tokenStyle.foreground) << MetadataConsts.FOREGROUND_OFFSET;\n\t\t\t\t\t\tmetadata |= foregroundBits | MetadataConsts.SEMANTIC_USE_FOREGROUND;\n\t\t\t\t\t}\n\t\t\t\t\tif (metadata === 0) {\n\t\t\t\t\t\t// Nothing!\n\t\t\t\t\t\tmetadata = SemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling: unknown token type index: ${tokenTypeIndex} for legend: ${JSON.stringify(this._legend.tokenTypes)}`);\n\t\t\t\t}\n\t\t\t\tmetadata = SemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\ttokenType = 'not-in-legend';\n\t\t\t}\n\t\t\tthis._hashTable.add(tokenTypeIndex, tokenModifierSet, encodedLanguageId, metadata);\n\n\t\t\tif (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling ${tokenTypeIndex} (${tokenType}) / ${tokenModifierSet} (${tokenModifiers.join(' ')}): foreground ${TokenMetadata.getForeground(metadata)}, fontStyle ${TokenMetadata.getFontStyle(metadata).toString(2)}`);\n\t\t\t}\n\t\t}\n\n\t\treturn metadata;\n\t}\n\n\tpublic warnOverlappingSemanticTokens(lineNumber: number, startColumn: number): void {\n\t\tif (!this._hasWarnedOverlappingTokens) {\n\t\t\tthis._hasWarnedOverlappingTokens = true;\n\t\t\tthis._logService.warn(`Overlapping semantic tokens detected at lineNumber ${lineNumber}, column ${startColumn}`);\n\t\t}\n\t}\n\n\tpublic warnInvalidLengthSemanticTokens(lineNumber: number, startColumn: number): void {\n\t\tif (!this._hasWarnedInvalidLengthTokens) {\n\t\t\tthis._hasWarnedInvalidLengthTokens = true;\n\t\t\tthis._logService.warn(`Semantic token with invalid length detected at lineNumber ${lineNumber}, column ${startColumn}`);\n\t\t}\n\t}\n\n\tpublic warnInvalidEditStart(previousResultId: string | undefined, resultId: string | undefined, editIndex: number, editStart: number, maxExpectedStart: number): void {\n\t\tif (!this._hasWarnedInvalidEditStart) {\n\t\t\tthis._hasWarnedInvalidEditStart = true;\n\t\t\tthis._logService.warn(`Invalid semantic tokens edit detected (previousResultId: ${previousResultId}, resultId: ${resultId}) at edit #${editIndex}: The provided start offset ${editStart} is outside the previous data (length ${maxExpectedStart}).`);\n\t\t}\n\t}\n\n}\n\nconst enum SemanticColoringConstants {\n\t/**\n\t * Let's aim at having 8KB buffers if possible...\n\t * So that would be 8192 / (5 * 4) = 409.6 tokens per area\n\t */\n\tDesiredTokensPerArea = 400,\n\n\t/**\n\t * Try to keep the total number of areas under 1024 if possible,\n\t * simply compensate by having more tokens per area...\n\t */\n\tDesiredMaxAreas = 1024,\n}\n\nexport function toMultilineTokens2(tokens: SemanticTokens, styling: SemanticTokensProviderStyling, languageId: string): SparseMultilineTokens[] {\n\tconst srcData = tokens.data;\n\tconst tokenCount = (tokens.data.length / 5) | 0;\n\tconst tokensPerArea = Math.max(Math.ceil(tokenCount / SemanticColoringConstants.DesiredMaxAreas), SemanticColoringConstants.DesiredTokensPerArea);\n\tconst result: SparseMultilineTokens[] = [];\n\n\tlet tokenIndex = 0;\n\tlet lastLineNumber = 1;\n\tlet lastStartCharacter = 0;\n\twhile (tokenIndex < tokenCount) {\n\t\tconst tokenStartIndex = tokenIndex;\n\t\tlet tokenEndIndex = Math.min(tokenStartIndex + tokensPerArea, tokenCount);\n\n\t\t// Keep tokens on the same line in the same area...\n\t\tif (tokenEndIndex < tokenCount) {\n\n\t\t\tlet smallTokenEndIndex = tokenEndIndex;\n\t\t\twhile (smallTokenEndIndex - 1 > tokenStartIndex && srcData[5 * smallTokenEndIndex] === 0) {\n\t\t\t\tsmallTokenEndIndex--;\n\t\t\t}\n\n\t\t\tif (smallTokenEndIndex - 1 === tokenStartIndex) {\n\t\t\t\t// there are so many tokens on this line that our area would be empty, we must now go right\n\t\t\t\tlet bigTokenEndIndex = tokenEndIndex;\n\t\t\t\twhile (bigTokenEndIndex + 1 < tokenCount && srcData[5 * bigTokenEndIndex] === 0) {\n\t\t\t\t\tbigTokenEndIndex++;\n\t\t\t\t}\n\t\t\t\ttokenEndIndex = bigTokenEndIndex;\n\t\t\t} else {\n\t\t\t\ttokenEndIndex = smallTokenEndIndex;\n\t\t\t}\n\t\t}\n\n\t\tlet destData = new Uint32Array((tokenEndIndex - tokenStartIndex) * 4);\n\t\tlet destOffset = 0;\n\t\tlet areaLine = 0;\n\t\tlet prevLineNumber = 0;\n\t\tlet prevEndCharacter = 0;\n\t\twhile (tokenIndex < tokenEndIndex) {\n\t\t\tconst srcOffset = 5 * tokenIndex;\n\t\t\tconst deltaLine = srcData[srcOffset];\n\t\t\tconst deltaCharacter = srcData[srcOffset + 1];\n\t\t\t// Casting both `lineNumber`, `startCharacter` and `endCharacter` here to uint32 using `|0`\n\t\t\t// to validate below with the actual values that will be inserted in the Uint32Array result\n\t\t\tconst lineNumber = (lastLineNumber + deltaLine) | 0;\n\t\t\tconst startCharacter = (deltaLine === 0 ? (lastStartCharacter + deltaCharacter) | 0 : deltaCharacter);\n\t\t\tconst length = srcData[srcOffset + 2];\n\t\t\tconst endCharacter = (startCharacter + length) | 0;\n\t\t\tconst tokenTypeIndex = srcData[srcOffset + 3];\n\t\t\tconst tokenModifierSet = srcData[srcOffset + 4];\n\n\t\t\tif (endCharacter <= startCharacter) {\n\t\t\t\t// this token is invalid (most likely a negative length casted to uint32)\n\t\t\t\tstyling.warnInvalidLengthSemanticTokens(lineNumber, startCharacter + 1);\n\t\t\t} else if (prevLineNumber === lineNumber && prevEndCharacter > startCharacter) {\n\t\t\t\t// this token overlaps with the previous token\n\t\t\t\tstyling.warnOverlappingSemanticTokens(lineNumber, startCharacter + 1);\n\t\t\t} else {\n\t\t\t\tconst metadata = styling.getMetadata(tokenTypeIndex, tokenModifierSet, languageId);\n\n\t\t\t\tif (metadata !== SemanticTokensProviderStylingConstants.NO_STYLING) {\n\t\t\t\t\tif (areaLine === 0) {\n\t\t\t\t\t\tareaLine = lineNumber;\n\t\t\t\t\t}\n\t\t\t\t\tdestData[destOffset] = lineNumber - areaLine;\n\t\t\t\t\tdestData[destOffset + 1] = startCharacter;\n\t\t\t\t\tdestData[destOffset + 2] = endCharacter;\n\t\t\t\t\tdestData[destOffset + 3] = metadata;\n\t\t\t\t\tdestOffset += 4;\n\n\t\t\t\t\tprevLineNumber = lineNumber;\n\t\t\t\t\tprevEndCharacter = endCharacter;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tlastLineNumber = lineNumber;\n\t\t\tlastStartCharacter = startCharacter;\n\t\t\ttokenIndex++;\n\t\t}\n\n\t\tif (destOffset !== destData.length) {\n\t\t\tdestData = destData.subarray(0, destOffset);\n\t\t}\n\n\t\tconst tokens = SparseMultilineTokens.create(areaLine, destData);\n\t\tresult.push(tokens);\n\t}\n\n\treturn result;\n}\n\nclass HashTableEntry {\n\tpublic readonly tokenTypeIndex: number;\n\tpublic readonly tokenModifierSet: number;\n\tpublic readonly languageId: number;\n\tpublic readonly metadata: number;\n\tpublic next: HashTableEntry | null;\n\n\tconstructor(tokenTypeIndex: number, tokenModifierSet: number, languageId: number, metadata: number) {\n\t\tthis.tokenTypeIndex = tokenTypeIndex;\n\t\tthis.tokenModifierSet = tokenModifierSet;\n\t\tthis.languageId = languageId;\n\t\tthis.metadata = metadata;\n\t\tthis.next = null;\n\t}\n}\n\nclass HashTable {\n\n\tprivate static _SIZES = [3, 7, 13, 31, 61, 127, 251, 509, 1021, 2039, 4093, 8191, 16381, 32749, 65521, 131071, 262139, 524287, 1048573, 2097143];\n\n\tprivate _elementsCount: number;\n\tprivate _currentLengthIndex: number;\n\tprivate _currentLength: number;\n\tprivate _growCount: number;\n\tprivate _elements: (HashTableEntry | null)[];\n\n\tconstructor() {\n\t\tthis._elementsCount = 0;\n\t\tthis._currentLengthIndex = 0;\n\t\tthis._currentLength = HashTable._SIZES[this._currentLengthIndex];\n\t\tthis._growCount = Math.round(this._currentLengthIndex + 1 < HashTable._SIZES.length ? 2 / 3 * this._currentLength : 0);\n\t\tthis._elements = [];\n\t\tHashTable._nullOutEntries(this._elements, this._currentLength);\n\t}\n\n\tprivate static _nullOutEntries(entries: (HashTableEntry | null)[], length: number): void {\n\t\tfor (let i = 0; i < length; i++) {\n\t\t\tentries[i] = null;\n\t\t}\n\t}\n\n\tprivate _hash2(n1: number, n2: number): number {\n\t\treturn (((n1 << 5) - n1) + n2) | 0;  // n1 * 31 + n2, keep as int32\n\t}\n\n\tprivate _hashFunc(tokenTypeIndex: number, tokenModifierSet: number, languageId: number): number {\n\t\treturn this._hash2(this._hash2(tokenTypeIndex, tokenModifierSet), languageId) % this._currentLength;\n\t}\n\n\tpublic get(tokenTypeIndex: number, tokenModifierSet: number, languageId: number): HashTableEntry | null {\n\t\tconst hash = this._hashFunc(tokenTypeIndex, tokenModifierSet, languageId);\n\n\t\tlet p = this._elements[hash];\n\t\twhile (p) {\n\t\t\tif (p.tokenTypeIndex === tokenTypeIndex && p.tokenModifierSet === tokenModifierSet && p.languageId === languageId) {\n\t\t\t\treturn p;\n\t\t\t}\n\t\t\tp = p.next;\n\t\t}\n\n\t\treturn null;\n\t}\n\n\tpublic add(tokenTypeIndex: number, tokenModifierSet: number, languageId: number, metadata: number): void {\n\t\tthis._elementsCount++;\n\t\tif (this._growCount !== 0 && this._elementsCount >= this._growCount) {\n\t\t\t// expand!\n\t\t\tconst oldElements = this._elements;\n\n\t\t\tthis._currentLengthIndex++;\n\t\t\tthis._currentLength = HashTable._SIZES[this._currentLengthIndex];\n\t\t\tthis._growCount = Math.round(this._currentLengthIndex + 1 < HashTable._SIZES.length ? 2 / 3 * this._currentLength : 0);\n\t\t\tthis._elements = [];\n\t\t\tHashTable._nullOutEntries(this._elements, this._currentLength);\n\n\t\t\tfor (const first of oldElements) {\n\t\t\t\tlet p = first;\n\t\t\t\twhile (p) {\n\t\t\t\t\tconst oldNext = p.next;\n\t\t\t\t\tp.next = null;\n\t\t\t\t\tthis._add(p);\n\t\t\t\t\tp = oldNext;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tthis._add(new HashTableEntry(tokenTypeIndex, tokenModifierSet, languageId, metadata));\n\t}\n\n\tprivate _add(element: HashTableEntry): void {\n\t\tconst hash = this._hashFunc(element.tokenTypeIndex, element.tokenModifierSet, element.languageId);\n\t\telement.next = this._elements[hash];\n\t\tthis._elements[hash] = element;\n\t}\n}\n"]}